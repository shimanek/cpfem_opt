{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p><code>matmdl</code> is a package implementing a Bayesian optimization framework using Gaussian process regression to parameterize the hardening models within crystal plasticity finite element method calculations, which are run through a user material subroutine integrated with Abaqus.  Its main features are that it:</p> <ul> <li>Handles multiple input data sets simultaneously, e.g. mutliple orientations in single crystal deformation or multiple grain sizes</li> <li>Uses gradient-free optimization for the multi-dimensional parameter space describing slip system level material properties</li> <li>Wraps around an existing crystal plasticity implementation using Abaqus as the finite element solver</li> <li>Considers slight offset orientations in the case of single crystal plasticity, which may go unquantified and unreported in most experimental data sets in the literature</li> </ul>"},{"location":"#basic-usage","title":"Basic Usage","text":"<p>Each run requires an <code>input.toml</code> file to specify the most common input options.  The runnable modes are each modules:</p> <ul> <li><code>matmdl.run</code> starts an optimization run</li> <li><code>matmdl.plot</code> plots the results of a complete or incomplete optimization run</li> </ul> <p>The input options are detailed in input.</p>"},{"location":"input/","title":"Input Details","text":""},{"location":"input/#experimental-data","title":"Experimental Data","text":"<p><code>matmdl</code> expects experimental data as a file of comma separated values, with the first column being engineering strain as a fraction (not percent) and the second column being engineering stress. Stress units should be consistent with those expected of the simulation. In the examples here, those are MPa.</p>"},{"location":"input/#input-options","title":"Input Options","text":"<p>The <code>input.toml</code> file contains all of the most common user options for runs. However, several details are not described by this file. For example, the surrogate model details are specified in <code>optimizer.py</code> and not at all in the input file. This may change in future iterations if needed, but since the repo is installed in editable mode, changes in the source code are straightforward.</p> <p>Also note that some common options have default values, defined in <code>parser.py</code> in the <code>input_reqs</code> dictionary.</p> <p>Below are details of setting, grouped by toml heading.</p>"},{"location":"input/#params","title":"params","text":"<p>Contains hardening parameter names as keys.  Values having these names in the file specified as the <code>param_file</code> variable will be found and modified during optimization.  Values are lower and upper bounds on each parameter, in a tuple. If the dictionary value is a single number, that parameter value is written to the <code>param_file</code> and not cosidered during optimization, as in the first value in the following example. If all parameters are fixed (here and within the orientation structure), then a single run with fixed parameters will be run.</p> <pre><code>[params]\nTau0 = 1.5 # (1)\nH0 = [200, 500]\nTauS = [10, 100]\n</code></pre> <ol> <li>This value is written to the input files but is not part of the optimization.</li> </ol>"},{"location":"input/#orientations","title":"orientations","text":"<p>Structure giving orientation information that allows the optimization scheme to consider offset angles and magnitudes for each loading separately. For example, optimization of [001] orientation single crystal, in comparison to experimental data in the file <code>exp_Cu-mX-001.csv</code>, the input settings might look like this:</p> <pre><code>[[orientations]]\nname = '001' # (1)\nexp = 'exp_Cu-mX-001.csv'\ninp = 'mat_orient_100.inp'\n[orientations.offset]\ndir_load = [0,0,1]\ndir_0deg = [0,1,1]\nmag_bounds = [0,1]\ndeg_bounds = 0\n</code></pre> <ol> <li>This is a string used for internal identification of the sample.</li> </ol> <p>Note that when <code>[orientations.offset]</code> is populated, the <code>inp</code> file option is not needed since it will be overwritten. Alternatively, if you have a fixed input file, then none of the <code>[orientations.offset]</code> is needed. </p> <p>Offset information:</p> <ul> <li> <p>dir_load: Loading direction in 3-tuple Miller indices.</p> </li> <li> <p>dir_0deg: Non-collinear direction used to define a zero of the rotation about the loading direction.</p> </li> <li> <p>mag_bounds: Degree range for allowable tilt of <code>dir_load</code>.</p> </li> <li> <p>deg_bounds: Degree range for allowable twist about <code>dir_load</code>.</p> </li> </ul>"},{"location":"input/#run","title":"run","text":"<ul> <li> <p>param_file: Name of the file containing the parameters, in Abaqus <code>parameter</code> format, for the CPFEM run. The values in this file will be modified if listed in :ref:<code>params</code>. </p> </li> <li> <p>loop_len: Total number of iterations for the optimization scheme. Includes <code>n_initial_points</code> in the count.</p> </li> <li> <p>n_initial_points: Number of iterations to be sampled before the optimization's acquisition function takes over determining which areas of parameter space to sample next. Worth experimenting with, but reasonable convergence has been seen with <code>n_initial_points</code> set to about half or a third of total iterations when <code>loop_len</code>\\~100 and :py:<code>len(param_list)=5</code>.</p> </li> <li> <p>large_error: Backup error value to send to the optimizer for the case of runs which don't finish. The first choice is set in <code>opt_fea.py</code> as 1.5 * IQR(first few RMSE), where IQR is the interquartile range. This is preferrable since the error returned should be large enough to dissuade the acquisition function from exploring that area of parameter space without being so large as to cause a discontinuity that affects the surrogate model's predictions in other areas of parameter space.</p> </li> <li> <p>length: Axial length along uniaxial loading direction (y-direction by default) to convert displacements into engineering strains. ToDo: find automatically from mesh.</p> </li> <li> <p>area: Model area normal to the uniaxial loading direction to convert forces to engineering strains. ToDo: find automatically from mesh.</p> </li> <li> <p>jobname: Main input file name for the Abaqus job.</p> </li> <li> <p>recursion_depth: Maximum number of times that the Abaqus run is restarted with a smaller maximum increment. The factor by which the Abaqus increment is set is given in <code>opt_fea.refine_run()</code> and is currently 5. If <code>recursion_depth=2</code> then an initial increment of 1E-2 will be cut to 2E-3 and then to 4E-3 in an attempt to get a converging Abaqus solution before returning to 1E-2 for the next parameter set.</p> </li> <li> <p>max_strain: Maximum strain to consider from the experimental data and therefore a maximum strain to run the CPFEM calculations until. Set 0 for max experimental value, or use fractional strain (0.01=1%) otherwise.</p> </li> <li> <p>i_powerlaw: Specifies the interpolation type. Default is linear (<code>0</code>), good for fine resolution experimental data. Also available is power-law (<code>1</code>), which is useful for polycrystal data with low resolution (\\~ 8 data points per curve).</p> </li> <li> <p>umat: File name specifying the location of the user material subroutine.</p> </li> <li> <p>cpus: Number of cores on which to run the Abaqus job.</p> </li> <li> <p>do_load_previous: True if the optimizer should load the previous <code>out_progress</code> file. Currently, reloading requires that all output was strictly within the current bounds specified in :ref:<code>params</code> as <code>params.values()</code>. Note that, for clarity, previous runs are given negative iteration numbers in the new <code>out_progress</code> file. ToDo: automatically filter through output and only reload entries that fall within current parameter bounds.</p> </li> </ul>"},{"location":"input/#plot","title":"plot","text":"<ul> <li> <p>grain_size_name: Deprecated legend key.</p> </li> <li> <p>title: Optional plot title.</p> </li> <li> <p>param_additional_legend: Extra parameters in addition to those in :ref:<code>params</code> that will be plotted in the single stress-strain plots showing the best-fit parameter set and its comparable experimental curve. Useful if one hardening parameter has been manually set in :ref:<code>param_file</code> but is still of interest to the plotted results.</p> </li> </ul>"},{"location":"install/","title":"Installation","text":"<p>The recommended installation method is an editable installation after cloning or copying the repository.  To keep dependencies clean, the use of virtual environments is encouraged.  Here, we will demonstrate the process for conda/mamba and pip.</p> <p>See here for detailed installation instructions for micromamba, a lightweight method to manage both python interpreters and their packages. </p> <p>For example, starting from a unix-like shell, we can download micromamba:</p> <pre><code>cd /path/to/persistent/storage/\n\"${SHELL}\" &lt;(curl -L micro.mamba.pm/install.sh)\n</code></pre> <p>Maybe create a quicker alias for the <code>micromamba</code> binary just installed or add that to a bashrc file if using:</p> <pre><code>alias mamba=$(echo $(pwd)/micromamba/bin/micromamba)\n# or:\necho \"alias mamba=$(echo $(pwd)/micromamba/bin/micromamba)\" &gt;&gt; ~/.bashrc\n</code></pre> <p>Now create a new environment with the project dependencies:</p> <pre><code>cd /path/to/matmdl/\nmamba create -n opt python=3.11 --file requirements.txt\n</code></pre> <p>Then activate the new environement and install this repository in editable mode:</p> <pre><code>mamba activate opt\npip install --no-build-isolation --no-deps -e .\n</code></pre> <p>If you want to build the docs, install the additional dependencies, then build in the <code>documentation</code> folder:</p> <pre><code>pip install -e '.[doc]'\ncd documentation\nmkdocs build\n</code></pre>"},{"location":"objective/","title":"Objective","text":"<p>The optimization procedure relies on a definition of goodness of fit between the experimental and simulated stress-strain curves.  Here, the objective function is defined in <code>objectives/calculate.py</code> , which currently uses values based on both stress differences and slope differences.  These are combined based on the input value <code>slope_weight</code>, with 0.0 being all stress-based and 1.0 being entirely slope-based.</p> <p>The values themselves are root mean square differences/errors (RMSEs) over the entire deformation, although limits can be applied to ignore certain regions. The RMSEs are normalized by the mean of the observations, meaning the average of the interpolated stress or strain values; therefore, these should not depend on the number of experimental data points. Note that something like an elastomer, where the slope of the stress-strain curve is around zero for large strains, would ruin the purpose of this normalization procedure.</p> <p>For multiple samples or single crystal orientations, the errors are combined by taking their mean. So each sample's error value, itself a combination of stress and slope errors, has equal weight during the final combination to a single-valued minimization objective.</p> <p>Unlike changing parameter bounds, a change in the objective function changes the objective manifold itself, meaning the optimization strategy may have an easier or harder time finding minima and that those minima will likely be different than before the change.</p>"},{"location":"output/","title":"Output Files","text":"<p>The optimization script outputs information on each iteration as plaintext in addition to saving stress-strain information as binary numpy arrays.  The plotting script save several plots about the optimization run and the final best-fit parameter set.</p>"},{"location":"output/#run","title":"run","text":"<ul> <li><code>out_progress.txt</code>: csv with 1-line header and columns of unix time in ns, then parameter set values</li> <li><code>out_errors.txt</code>: csv with 1-line header and columns of the error value for each sample and the overall error as the last column</li> <li><code>out_time_disp_force_name.npy</code>: Numpy binary for each orientation indicated by <code>name</code>, the nickname in :ref:<code>orientations</code>.</li> <li><code>temp_expSS.csv</code>: Truncated experimental stress-strain data if cut down by <code>max_strain</code> parameter.</li> <li><code>temp_time_disp_force_name.csv</code>: plaintext version of (simulation) time, displacements, and force data from the run indicated by <code>name</code>, the nickname in the <code>orientations</code> section of the input file.</li> </ul>"},{"location":"output/#plot","title":"plot","text":"<ul> <li><code>out_best_params.txt</code>: Plaintext summary of the best parameter set found in :ref:<code>out_progress.txt</code>.</li> <li><code>res_convergence.png</code>: Optimization convergence behavior: cumulative lowest error value as a function of iteration.</li> <li><code>res_evaluations.png</code>: NxN lower triangular plot (where N is the length of optimizeable parameters in :ref:<code>params</code>) showing the sampling of each parameter to be optimized.</li> <li><code>res_objective.png</code>: NxN lower triangular plot (where N is the length of optimizeable parameters in :ref:<code>params</code>) showing the objective function as predicted by the surrogate model over all of parameter space. Note that this involves grid sampling and averaging that may not be appropriate for the true function to be examined.</li> <li><code>res_opt_name.png</code>: All stress-strain curves for the orientation <code>name</code>, the nickname in :ref:<code>orientations</code>.</li> <li><code>res_single_name.png</code>: The best stress-strain curve for the orientation <code>name</code>, the nickname in :ref:<code>orientations</code>. Also includes a legend with best-fit parameter values.</li> </ul>"},{"location":"theory/","title":"Theory Primer","text":"<p>Optimization and CPFEM/hardening theory primer.</p>"},{"location":"theory/#cpfem","title":"CPFEM","text":"<p>Crystal plasticity finite element (CPFE) methods take a fundamental understanding of microscopic deformation mechanisms, especially slip of dislocations within slip planes, and connect these to macroscopic stress states and deformations.  Often, these models are parameterized based on the stress-strain response of the bulk material of interest, either monocrystal or polycrystal.  While the physical underpinning of CPFE models lends some plausibility to their predictive power in extrapolative situations, careful parameterization is especially critical for such applications.  In the case of single crystal metallic materials, data from a uniaxial deformation experiment along one crystallographic orientation is often used to fit the material-specific parameters of the CPFE model.  Since experimental tests inherently include some slight yet unknown deviation from the nominal loading orientation and computational models do not, a direct comparison of the two for the purposes of determining material properties is fraught. In this optimization framework, such slight deviations can be accounted for by incorporating values describing the tilt away from nominal loading direction as additional parameters to be optimized.</p>"},{"location":"theory/#mesh-types","title":"Mesh Types","text":"<p>While crystal plasticity methods are most useful in their application to realistic microstructures, iterative parameterization methods require that models run efficiently. Therefore, the goal for the geometrical models generated here are to be representative of more complex models while being much faster to run.  There are currently two methods of model generation: those for monocrystal and polycrystal applications. The former consists of a single C3D8 element with complex boundary conditions that allows for lattice rotation on the top and bottom face \u2013 this rotation is crucial to capture the behavior seen in single crystal tensile tests.  For example, see below for a comparison.</p> <p></p> <p>Realistic polycrystal models can be generated using software such as  Dream3D, with some modifications needed to run the resulting Abaqus input files using the crystal plasticity subroutine.  However, such models often take a prohibitively long time to run, and, for equiaxed microstructures, can be replaced with cubic grains without much loss in accuracy.  Therefore, the polycrystal models generated here are orthorhombic and contain orthorhombic grains. The size of grains and overall model are arbitrary so long as the length of the grains along each direction can evenly divide the length of the model in that direction. </p>"},{"location":"theory/#bayesian-optimization","title":"Bayesian Optimization","text":"<p>Due to the nature of complex crystal plasticity models, analytical parameterization is usually impossible. Furthermore, the evaluation of CPFE models to compare to a lab-scale deformation test is expensive and provides no gradient information.  However, Bayseian optimization is a useful and well-developed framework for optimizing such black-box functions. In particular, the library given in sci-kit optimize is here implemented in order to find the best-fitting crystal plasticity material parameters to reproduce experimental stress-strain curves.</p>"},{"location":"theory/#gaussian-process-regression","title":"Gaussian Process Regression","text":"<p>A Gaussian process underlyines the estimates of the loss function between the experimental stress-strain curve in terms of the CPFE hardening parameters and acts as a surrogate model for the CPFE evaluation.  At each evaluated set of parameters, the surrogate model gains an exact solution while updating its estimates over the rest of parameter space.  Since the GPR is made of many functions generated by its kernel, it includes a measure of unvertainty over all of parameter space, which is useful for determining the best parameter set to evaluate next. The \"best\" parameter set is determined by competing contributions from the value estimate over paramter space, with lower errors being more alluring, and from the uncertainty values, with less certain regions containing more potential for low error values.  Thus a weighting factor is a useful hyperparamter to tune the exploitation/exploration tradeoff during optimization. </p>"},{"location":"theory2/","title":"Extra","text":"<p>Potential topics:</p> <ul> <li>non-stationary covariance kernels</li> <li>BW hardening law and FCC interaction matrix</li> </ul>"},{"location":"API/","title":"Other modules","text":"<p>The runnable modules, <code>run</code> and <code>plot</code>, rely on the following modules:</p> <ul> <li>Core: contains modules used for most applications</li> <li>Engines: interfaces with the FEA program</li> <li>Objectives: provides objective functions for the optimization</li> <li>Models: constructs geometric models for use in the FEA</li> </ul>"},{"location":"API/core/","title":"API: Core","text":""},{"location":"API/core/#matmdl.core","title":"<code>matmdl.core</code>","text":""},{"location":"API/core/#matmdl.core.crystalPlasticity","title":"<code>crystalPlasticity</code>","text":"<p>This module contains functions relevant to the application of Huang's crystal plasticity subroutine.</p>"},{"location":"API/core/#matmdl.core.crystalPlasticity.do_orientation_inputs","title":"<code>do_orientation_inputs(next_params, orient, in_opt)</code>","text":"<p>Get and write new orientation information, if necessary.</p> <p>If input file is in orientation structure, uses that.</p> Source code in <code>matmdl/core/crystalPlasticity.py</code> <pre><code>def do_orientation_inputs(next_params, orient, in_opt):\n\t\"\"\"\n\tGet and write new orientation information, if necessary.\n\n\tIf input file is in orientation structure, uses that.\n\t\"\"\"\n\tif not in_opt.has_orient_opt[orient] and \"inp\" not in uset.orientations[orient]:\n\t\treturn\n\n\tif in_opt.has_orient_opt[orient]:\n\t\torient_components = get_orient_info(next_params, orient, in_opt)\n\t\twriter.write_input_params(\n\t\t\t\"mat_orient.inp\", orient_components[\"names\"], orient_components[\"values\"]\n\t\t)\n\telse:\n\t\tif \"inp\" in uset.orientations[orient]:\n\t\t\tif len(uset.orientations[orient][\"inp\"]) &gt; 1:\n\t\t\t\t# if two filenames given, copy one to the other\n\t\t\t\tshutil.copy(\n\t\t\t\t\tuset.orientations[orient][\"inp\"][0], \n\t\t\t\t\tuset.orientations[orient][\"inp\"][1]\n\t\t\t\t)\n\t\t\telse:\n\t\t\t\t# otherwise, copy one filename to the standard orientation file name\n\t\t\t\tshutil.copy(f\"mat_orient_{orient}.inp\", \"mat_orient.inp\")\n</code></pre>"},{"location":"API/core/#matmdl.core.crystalPlasticity.get_offset_angle","title":"<code>get_offset_angle(direction_og, direction_to, angle)</code>","text":"<p>Iterative solution for finding vectors tilted toward other vectors.</p> <p>Parameters:</p> Name Type Description Default <code>direction_og</code> <code>vector</code> <p>Real space vector defining the original direction to be tilted away from.</p> required <code>direction_to</code> <code>vector</code> <p>Real space vector defining the direction to be tilted towards.</p> required <code>angle</code> <code>float</code> <p>The angle, in degrees, by which to tilt.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>a scalar multiplier such that the angle between <code>direction_og</code> and <code>sol.x</code> * <code>direction_to</code> is <code>angle</code>.</p> Source code in <code>matmdl/core/crystalPlasticity.py</code> <pre><code>def get_offset_angle(direction_og: \"vector\", direction_to: \"vector\", angle: float) -&gt; float:\n\t\"\"\"\n\tIterative solution for finding vectors tilted toward other vectors.\n\n\tArgs:\n\t    direction_og: Real space vector defining\n\t        the original direction to be tilted away from.\n\t    direction_to: Real space vector defining\n\t        the direction to be tilted towards.\n\t    angle: The angle, in degrees, by which to tilt.\n\n\tReturns:\n\t    float:\n\t        a scalar multiplier such that the angle between ``direction_og``\n\t        and ``sol.x`` * ``direction_to`` is ``angle``.\n\n\t\"\"\"\n\n\tdef _opt_angle(offset_amt: float, direction_og: \"vector\", direction_to: \"vector\", angle: float):\n\t\t\"\"\"\n\t\tAngle difference between original vector and new vector, which is\n\t\tmade by small offset toward new direction.  Returns zero when offset_amt\n\t\tproduces new vector at desired angle.  Uses higher namespace variables so\n\t\tthat the single argument can be tweaked by optimizer.\n\t\t\"\"\"\n\t\tdirection_new = direction_og + offset_amt * direction_to\n\t\tangle_difference = np.dot(direction_og, direction_new) / (\n\t\t\tnorm(direction_og) * norm(direction_new)\n\t\t) - np.cos(np.deg2rad(angle))\n\t\treturn angle_difference\n\n\tsol = root(_opt_angle, 0.01, args=(direction_og, direction_to, angle), tol=1e-10).x[0]\n\treturn sol\n</code></pre>"},{"location":"API/core/#matmdl.core.crystalPlasticity.get_orient_info","title":"<code>get_orient_info(next_params, orient, in_opt)</code>","text":"<p>Get components of orientation-defining vectors and their names for substitution into the orientation input files.</p> <p>Parameters:</p> Name Type Description Default <code>next_params</code> <code>list</code> <p>Next set of parameters to be evaluated by the optimization scheme.</p> required <code>orient</code> <code>str</code> <p>Index string for dictionary of input orientations specified in :ref:<code>orientations</code>.</p> required Source code in <code>matmdl/core/crystalPlasticity.py</code> <pre><code>def get_orient_info(\n\tnext_params: list,\n\torient: str,\n\tin_opt: object,\n) -&gt; dict:\n\t\"\"\"\n\tGet components of orientation-defining vectors and their names\n\tfor substitution into the orientation input files.\n\n\tArgs:\n\t    next_params: Next set of parameters to be evaluated\n\t        by the optimization scheme.\n\t    orient: Index string for dictionary of input\n\t        orientations specified in :ref:`orientations`.\n\t\"\"\"\n\tdir_load = np.asarray(uset.orientations[orient][\"offset\"][\"dir_load\"])\n\tdir_0deg = np.asarray(uset.orientations[orient][\"offset\"][\"dir_0deg\"])\n\n\tif orient + \"_mag\" in in_opt.params:\n\t\tindex_mag = in_opt.params.index(orient + \"_mag\")\n\t\tangle_mag = next_params[index_mag]\n\telse:\n\t\tangle_mag = in_opt.fixed_vars[orient + \"_mag\"]\n\n\tif orient + \"_deg\" in in_opt.params:\n\t\tindex_deg = in_opt.params.index(orient + \"_deg\")\n\t\tangle_deg = next_params[index_deg]\n\telse:\n\t\tangle_deg = in_opt.fixed_vars[orient + \"_deg\"]\n\n\tcol_load = unit_vector(np.asarray(dir_load))\n\tcol_0deg = unit_vector(np.asarray(dir_0deg))\n\tcol_cross = unit_vector(np.cross(col_load, col_0deg))\n\n\tbasis_og = np.stack((col_load, col_0deg, col_cross), axis=1)\n\trotation = _mk_x_rot(np.deg2rad(angle_deg))\n\tbasis_new = np.matmul(basis_og, rotation)\n\tdir_to = basis_new[:, 1]\n\n\tif __debug__:  # write angle_deg rotation info\n\t\tdir_load = dir_load / norm(dir_load)\n\t\tdir_to = dir_to / norm(dir_to)\n\t\tdir_0deg = dir_0deg / norm(dir_0deg)\n\t\twith open(\"out_debug.txt\", \"a+\") as f:\n\t\t\tf.write(f\"orientation: {orient}\")\n\t\t\tf.write(f\"\\nbasis OG: \\n{basis_og}\")\n\t\t\tf.write(\"\\n\")\n\t\t\tf.write(f\"\\nrotation: \\n{rotation}\")\n\t\t\tf.write(\"\\n\")\n\t\t\tf.write(f\"\\nbasis new: \\n{basis_new}\")\n\t\t\tf.write(\"\\n\\n\")\n\t\t\tf.write(f\"dir_load: {dir_load}\\tdir_to: {dir_to}\\n\")\n\t\t\tf.write(f\"angle_deg_inp: {angle_deg}\\n\")\n\t\t\tf.write(f\"all params: {next_params}\")\n\n\tsol = get_offset_angle(dir_load, dir_to, angle_mag)\n\tdir_tot = dir_load + sol * dir_to\n\tdir_ortho = np.array([1, 0, -dir_tot[0] / dir_tot[2]])\n\n\tif __debug__:  # write final loading orientation info\n\t\tangle_output = (\n\t\t\tnp.arccos(np.dot(dir_tot, dir_load) / (norm(dir_tot) * norm(dir_load))) * 180.0 / np.pi\n\t\t)\n\t\twith open(\"out_debug.txt\", \"a+\") as f:\n\t\t\tf.write(f\"\\ndir_tot: {dir_tot}\")\n\t\t\tf.write(f\"\\ndir_ortho: {dir_ortho}\")\n\t\t\tf.write(f\"\\nangle_mag_input: {angle_mag}\\tangle_mag_output: {angle_output}\")\n\t\t\tf.write(\"\\n\\n\")\n\n\tcomponent_names = [\"x1\", \"y1\", \"z1\", \"u1\", \"v1\", \"w1\"]\n\tcomponent_values = list(dir_ortho) + list(dir_tot)\n\n\treturn {\"names\": component_names, \"values\": component_values}\n</code></pre>"},{"location":"API/core/#matmdl.core.crystalPlasticity.param_check","title":"<code>param_check(param_list)</code>","text":"<p>True if tau0 &gt;= tauS</p> <p>In theory, tau0 should always come before tauS, even though it doesn't make a difference mathematically/practically. Function checks for multiple systems if numbered in the form <code>TauS</code>, <code>TauS1</code>, <code>TauS2</code> and <code>Tau0</code>, <code>Tau01</code>, <code>Tau02</code>.</p> Note <p>Deprecated. Better to do this by mapping whatever hyper-rectangular input bounds to your acceptable parameter space. E.g. optimizing on <code>tauS_shift</code> on [0,10] and adding a derived parameter in the Abaqus inputs: <code>tauS = tau0 + tauS_shift</code>.</p> Source code in <code>matmdl/core/crystalPlasticity.py</code> <pre><code>def param_check(param_list: list[str]):\n\t\"\"\"\n\tTrue if tau0 &gt;= tauS\n\n\tIn theory, tau0 should always come before tauS, even though it doesn't make a difference\n\tmathematically/practically. Function checks for multiple systems if numbered in the form\n\t``TauS``, ``TauS1``, ``TauS2`` and ``Tau0``, ``Tau01``, ``Tau02``.\n\n\tNote:\n\t    Deprecated. Better to do this by mapping whatever hyper-rectangular input bounds\n\t    to your acceptable parameter space. E.g. optimizing on `tauS_shift` on [0,10]\n\t    and adding a derived parameter in the Abaqus inputs: `tauS = tau0 + tauS_shift`.\n\t\"\"\"\n\t# TODO: ck if it's possible to satisfy this based on mat_params and bounds, raise helpful error\n\ttau0_list, tauS_list = [], []\n\tfor sysnum in [\"\", \"1\", \"2\"]:\n\t\tif (\"TauS\" + sysnum in param_list) or (\"Tau0\" + sysnum in param_list):\n\t\t\tf1 = open(uset.param_file, \"r\")\n\t\t\tlines = f1.readlines()\n\t\t\tfor line in lines:\n\t\t\t\tif line.startswith(\"Tau0\" + sysnum):\n\t\t\t\t\ttau0_list.append(float(line[7:]))\n\t\t\t\tif line.startswith(\"TauS\" + sysnum):\n\t\t\t\t\ttauS_list.append(float(line[7:]))\n\t\t\tf1.close()\n\tis_bad = any([(tau0 &gt;= tauS) for tau0, tauS in zip(tau0_list, tauS_list)])\n\treturn is_bad\n</code></pre>"},{"location":"API/core/#matmdl.core.experimental","title":"<code>experimental</code>","text":"<p>Contains the class for extracting and storing experimental data from plain text inputs for comparison to iterative solution attempts.</p>"},{"location":"API/core/#matmdl.core.experimental.ExpData","title":"<code>ExpData</code>","text":"<p>Loads and stores experimental data.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>dict</code> <p>Indexed by orientation name defined in :ref:<code>orientations</code>, with values of max strain (internal: <code>_max_strain</code>) and <code>raw</code>, which houses the experimental stress strain data truncated by max strain.</p> Note <p>Experimental stress-strain data are expected as plaintext in two columns: strain (unitless), and stress (matching the CPFEM inputs, often MPa).</p> Source code in <code>matmdl/core/experimental.py</code> <pre><code>class ExpData:\n\t\"\"\"\n\tLoads and stores experimental data.\n\n\tAttributes:\n\t    data (dict): Indexed by orientation name defined in :ref:`orientations`,\n\t        with values of max strain (internal: ``_max_strain``) and ``raw``,\n\t        which houses the experimental stress strain data truncated by max strain.\n\n\tNote:\n\t    Experimental stress-strain data are expected as plaintext in two columns:\n\t    strain (unitless), and stress (matching the CPFEM inputs, often MPa).\n\n\t\"\"\"\n\n\tdef __init__(self, orientations: dict):\n\t\tself.data = {}\n\t\tfor orient in orientations.keys():\n\t\t\texpname = orientations[orient][\"exp\"]\n\t\t\tmin_strain, max_strain = self._get_bounds(expname, orient)\n\t\t\traw = self._get_SS(expname, min_strain, max_strain)\n\t\t\tself.data[orient] = {\n\t\t\t\t\"max_strain\": max_strain,\n\t\t\t\t\"min_strain\": min_strain,\n\t\t\t\t\"raw\": raw,\n\t\t\t}\n\n\tdef tell_max_strain(self, orient: str):\n\t\t\"\"\"Convience method to forget how data is laid out\"\"\"\n\t\treturn self.data[orient][\"max_strain\"]\n\n\tdef _load(self, fname: str):\n\t\t\"\"\"\n\t\tLoad original experimental stress-strain data and order it by strain.\n\n\t\tArgs:\n\t\t    fname: Filename for experimental stress-strain data\n\t\t\"\"\"\n\t\toriginal_SS = np.loadtxt(fname, skiprows=1, delimiter=\",\")\n\t\torder = -1 if uset.is_compression else 1\n\t\toriginal_SS = original_SS[original_SS[:, 0].argsort()][::order]\n\t\treturn original_SS\n\n\tdef _get_bounds(self, fname: str, orient: str):\n\t\t\"\"\"get limiting bounds\"\"\"\n\t\tmins = []\n\t\tmaxes = []\n\n\t\t# orientation limits:\n\t\tif \"min_strain\" in uset.orientations[orient].keys():\n\t\t\tmins.append(float(uset.orientations[orient][\"min_strain\"]))\n\t\tif \"max_strain\" in uset.orientations[orient].keys():\n\t\t\torient_max_strain = float(uset.orientations[orient][\"max_strain\"])\n\t\t\tif orient_max_strain != 0.0:\n\t\t\t\tmaxes.append(orient_max_strain)\n\n\t\t# global limits\n\t\tif hasattr(uset, \"min_strain\"):\n\t\t\tmins.append(uset.min_strain)\n\t\tif hasattr(uset, \"max_strain\"):\n\t\t\tif float(uset.max_strain) != 0.0:\n\t\t\t\tmaxes.append(uset.max_strain)\n\n\t\t# data limits\n\t\tdata = np.sort(np.loadtxt(fname, skiprows=1, delimiter=\",\")[:, 0])\n\t\tmins.append(data[0])\n\t\tmaxes.append(data[-1])\n\n\t\t# get limiting bounds to use\n\t\tif uset.is_compression:  # negative numbers\n\t\t\tmin_use = min(mins)\n\t\t\tmax_use = max(maxes)\n\t\telse:\n\t\t\tmin_use = max(mins)\n\t\t\tmax_use = min(maxes)\n\n\t\tif False:\n\t\t\tprint(\"dbg bounds: mins:\", mins)\n\t\t\tprint(\"dbg bounds: maxes:\", maxes)\n\t\t\tprint(\"dbg bounds: min:\", min_use)\n\t\t\tprint(\"dbg bounds: max:\", max_use)\n\n\t\treturn min_use, max_use\n\n\tdef _get_max_strain(self, fname: str, orient: str):\n\t\t\"\"\"\n\t\tTake either user max strain or file max strain.\n\n\t\tArgs:\n\t\t    fname: Filename for experimental stress-strain data\n\t\t\"\"\"\n\t\tif float(uset.max_strain) == 0.0:\n\t\t\tif uset.is_compression is True:\n\t\t\t\tmax_strain = min(np.loadtxt(fname, skiprows=1, delimiter=\",\")[:, 0])\n\t\t\telse:\n\t\t\t\tmax_strain = max(np.loadtxt(fname, skiprows=1, delimiter=\",\")[:, 0])\n\t\telse:\n\t\t\tmax_strain = uset.max_strain if not uset.is_compression else (-1 * uset.max_strain)\n\t\treturn max_strain\n\n\tdef _get_min_strain(self, fname: str):\n\t\t\"\"\"\n\t\tTake either user min strain or minimum of experimental strain in file `fname`\n\n\t\tArgs:\n\t\t    fname: Filename for experimental stress-strain data\n\t\t\"\"\"\n\t\tif float(uset.min_strain) == 0.0:\n\t\t\tif uset.is_compression is True:\n\t\t\t\tmin_strain = max(np.loadtxt(fname, skiprows=1, delimiter=\",\")[:, 0])\n\t\t\telse:\n\t\t\t\tmin_strain = min(np.loadtxt(fname, skiprows=1, delimiter=\",\")[:, 0])\n\t\telse:\n\t\t\tmin_strain = uset.min_strain if not uset.is_compression else (-1 * uset.min_strain)\n\t\treturn min_strain\n\n\tdef _get_SS(self, fname: str, _min_strain: float, _max_strain: float):\n\t\t\"\"\"\n\t\tLimit experimental data to within min_strain to max_strain.\n\n\t\tArgs:\n\t\t    fname: Filename for experimental stress-strain data\n\t\t\"\"\"\n\t\texpSS = self._load(fname)\n\n\t\tif not _max_strain == 0.0:\n\t\t\texpSS = expSS[expSS[:, 0] &lt;= _max_strain, :]\n\t\tif not _min_strain == 0.0:\n\t\t\texpSS = expSS[expSS[:, 0] &gt;= _min_strain, :]\n\n\t\tnp.savetxt(\"temp_expSS.csv\", expSS, delimiter=\",\")\n\t\treturn expSS\n</code></pre>"},{"location":"API/core/#matmdl.core.experimental.ExpData.tell_max_strain","title":"<code>tell_max_strain(orient)</code>","text":"<p>Convience method to forget how data is laid out</p> Source code in <code>matmdl/core/experimental.py</code> <pre><code>def tell_max_strain(self, orient: str):\n\t\"\"\"Convience method to forget how data is laid out\"\"\"\n\treturn self.data[orient][\"max_strain\"]\n</code></pre>"},{"location":"API/core/#matmdl.core.optimizer","title":"<code>optimizer</code>","text":"<p>Module for instantiating and updating the optimizer object.</p>"},{"location":"API/core/#matmdl.core.optimizer.InOpt","title":"<code>InOpt</code>","text":"<p>Stores information about the optimization input parameters.</p> <p>Since the hardening parameters and orientation parameters are fundamentally different, this object stores information about both in such a way that they can still be access independently.</p> <p>Parameters:</p> Name Type Description Default <code>orientations</code> <code>dict</code> <p>Orientation information directly from <code>opt_input</code>.</p> required <code>params</code> <code>dict</code> <p>name and bounds of parameters to be optimized.</p> required <p>Attributes:</p> Name Type Description <code>orients</code> <code>list</code> <p>Nickname strings defining orientations, as given in :ref:<code>orientations</code>.</p> <code>material_params</code> <code>list</code> <p>Parameter names to be optimized, as in :ref:<code>orientations</code>.</p> <code>material_bounds</code> <code>list</code> <p>Tuple of floats defining bounds of parameter in the same index of <code>self.params</code>, again given in :ref:<code>orientations</code>.</p> <code>orient_params</code> <code>list</code> <p>Holds orientation parameters to be optimized, or single orientation parameters if not given as a tuple in :ref:<code>orientations</code>. These are labeled <code>orientationNickName_deg</code> for the degree value of the right hand rotation about the loading axis and <code>orientationNickName_mag</code> for the magnitude of the offset.</p> <code>orient_bounds</code> <code>list</code> <p>List of tuples corresponding to the bounds for the parameters stored in <code>self.orient_params</code>.</p> <code>params</code> <code>list</code> <p>Combined list consisting of both <code>self.material_params</code> and <code>self.orient_params</code>.</p> <code>bounds</code> <code>list</code> <p>Combined list consisting of both <code>self.material_bounds</code> and <code>self.orient_bounds</code>.</p> <code>has_orient_opt</code> <code>dict</code> <p>Dictionary with orientation nickname as key and boolean as value indicating whether slight loading offsets should be considered for that orientation.</p> <code>fixed_vars</code> <code>dict</code> <p>Dictionary with orientation nickname as key and any fixed orientation information (<code>_deg</code> or <code>_mag</code>) for that loading orientation that is not going to be optimized.</p> <code>offsets</code> <code>list</code> <p>List of dictionaries containing all information about the offset as given in the input file. Not used/called anymore?</p> <code>num_params_material</code> <code>int</code> <p>Number of material parameters to be optimized.</p> <code>num_params_orient</code> <code>int</code> <p>Number of orientation parameters to be optimized.</p> <code>num_params_total</code> <code>int</code> <p>Number of parameters to be optimized in total.</p> Note <p>Checks if <code>orientations[orient]['offset']['deg_bounds']</code> in :ref:<code>orientations</code> is a tuple to determine whether orientation should also be optimized.</p> Source code in <code>matmdl/core/optimizer.py</code> <pre><code>class InOpt:\n\t\"\"\"\n\tStores information about the optimization input parameters.\n\n\tSince the hardening parameters and orientation parameters are fundamentally\n\tdifferent, this object stores information about both in such a way that they\n\tcan still be access independently.\n\n\tArgs:\n\t    orientations (dict): Orientation information directly from ``opt_input``.\n\t    params (dict): name and bounds of parameters to be optimized.\n\n\n\tAttributes:\n\t    orients (list): Nickname strings defining orientations, as given\n\t        in :ref:`orientations`.\n\t    material_params (list): Parameter names to be optimized, as in :ref:`orientations`.\n\t    material_bounds (list): Tuple of floats defining bounds of parameter in the same\n\t        index of ``self.params``, again given in :ref:`orientations`.\n\t    orient_params (list): Holds orientation parameters to be optimized, or single\n\t        orientation parameters if not given as a tuple in :ref:`orientations`.\n\t        These are labeled ``orientationNickName_deg`` for the degree value of the\n\t        right hand rotation about the loading axis and ``orientationNickName_mag``\n\t        for the magnitude of the offset.\n\t    orient_bounds (list): List of tuples corresponding to the bounds for the parameters\n\t        stored in ``self.orient_params``.\n\t    params (list): Combined list consisting of both ``self.material_params`` and\n\t        ``self.orient_params``.\n\t    bounds (list): Combined list consisting of both ``self.material_bounds`` and\n\t        ``self.orient_bounds``.\n\t    has_orient_opt (dict): Dictionary with orientation nickname as key and boolean\n\t        as value indicating whether slight loading offsets should be considered\n\t        for that orientation.\n\t    fixed_vars (dict): Dictionary with orientation nickname as key and any fixed\n\t        orientation information (``_deg`` or ``_mag``) for that loading orientation\n\t        that is not going to be optimized.\n\t    offsets (list): List of dictionaries containing all information about the offset\n\t        as given in the input file. Not used/called anymore?\n\t    num_params_material (int): Number of material parameters to be optimized.\n\t    num_params_orient (int): Number of orientation parameters to be optimized.\n\t    num_params_total (int): Number of parameters to be optimized in total.\n\n\tNote:\n\t    Checks if ``orientations[orient]['offset']['deg_bounds']``\n\t    in :ref:`orientations` is a tuple to determine whether\n\t    orientation should also be optimized.\n\t\"\"\"\n\n\t# TODO: check if ``offsets`` attribute is still needed.\n\tdef __init__(self, orientations, params):\n\t\t\"\"\"Sorted orientations here defines order for use in single list passed to optimizer.\"\"\"\n\t\tself.orients = sorted(orientations.keys())\n\t\t(\n\t\t\tself.params,\n\t\t\tself.bounds,\n\t\t\tself.material_params,\n\t\t\tself.material_bounds,\n\t\t\tself.orient_params,\n\t\t\tself.orient_bounds,\n\t\t) = ([] for i in range(6))\n\t\tfor param, bound in params.items():\n\t\t\tif type(bound) in (list, tuple):  # pass ranges to optimizer\n\t\t\t\tself.material_params.append(param)\n\t\t\t\tself.material_bounds.append([float(b) for b in bound])\n\t\t\telif type(bound) in (float, int):  # write single values to file\n\t\t\t\twrite_input_params(uset.param_file, param, float(bound))\n\t\t\telse:\n\t\t\t\traise TypeError(\"Incorrect bound type in input file.\")\n\n\t\t# add orientation offset info:\n\t\tself.offsets = []\n\t\tself.has_orient_opt = {}\n\t\tself.fixed_vars = {}\n\t\tfor orient in self.orients:\n\t\t\tif \"offset\" in orientations[orient].keys():\n\t\t\t\tself.has_orient_opt[orient] = True\n\t\t\t\tself.offsets.append({orient: orientations[orient][\"offset\"]})\n\t\t\t\t# ^ saves all info (TODO: check if still needed)\n\n\t\t\t\t# deg rotation *about* loading orientation:\n\t\t\t\tif isinstance(orientations[orient][\"offset\"][\"deg_bounds\"], (tuple, list)):\n\t\t\t\t\tself.orient_params.append(orient + \"_deg\")\n\t\t\t\t\tself.orient_bounds.append(\n\t\t\t\t\t\t[float(f) for f in orientations[orient][\"offset\"][\"deg_bounds\"]]\n\t\t\t\t\t)\n\t\t\t\telse:\n\t\t\t\t\tself.fixed_vars[(orient + \"_deg\")] = orientations[orient][\"offset\"][\n\t\t\t\t\t\t\"deg_bounds\"\n\t\t\t\t\t]\n\n\t\t\t\t# mag rotation *away from* loading:\n\t\t\t\tif isinstance(orientations[orient][\"offset\"][\"mag_bounds\"], (tuple, list)):\n\t\t\t\t\tself.orient_params.append(orient + \"_mag\")\n\t\t\t\t\tself.orient_bounds.append(\n\t\t\t\t\t\t[float(f) for f in orientations[orient][\"offset\"][\"mag_bounds\"]]\n\t\t\t\t\t)\n\t\t\t\telse:\n\t\t\t\t\tself.fixed_vars[(orient + \"_mag\")] = orientations[orient][\"offset\"][\n\t\t\t\t\t\t\"mag_bounds\"\n\t\t\t\t\t]\n\n\t\t\telse:\n\t\t\t\tself.has_orient_opt[orient] = False\n\n\t\t# combine material and orient info into one ordered list:\n\t\tself.params = self.material_params + self.orient_params\n\t\tself.bounds = as_float_tuples(self.material_bounds + self.orient_bounds)\n\n\t\t# descriptive stats on input object:\n\t\tself.num_params_material = len(self.material_params)\n\t\tself.num_params_orient = len(self.orient_params)\n\t\tself.num_params_total = len(self.params)\n</code></pre>"},{"location":"API/core/#matmdl.core.optimizer.InOpt.__init__","title":"<code>__init__(orientations, params)</code>","text":"<p>Sorted orientations here defines order for use in single list passed to optimizer.</p> Source code in <code>matmdl/core/optimizer.py</code> <pre><code>def __init__(self, orientations, params):\n\t\"\"\"Sorted orientations here defines order for use in single list passed to optimizer.\"\"\"\n\tself.orients = sorted(orientations.keys())\n\t(\n\t\tself.params,\n\t\tself.bounds,\n\t\tself.material_params,\n\t\tself.material_bounds,\n\t\tself.orient_params,\n\t\tself.orient_bounds,\n\t) = ([] for i in range(6))\n\tfor param, bound in params.items():\n\t\tif type(bound) in (list, tuple):  # pass ranges to optimizer\n\t\t\tself.material_params.append(param)\n\t\t\tself.material_bounds.append([float(b) for b in bound])\n\t\telif type(bound) in (float, int):  # write single values to file\n\t\t\twrite_input_params(uset.param_file, param, float(bound))\n\t\telse:\n\t\t\traise TypeError(\"Incorrect bound type in input file.\")\n\n\t# add orientation offset info:\n\tself.offsets = []\n\tself.has_orient_opt = {}\n\tself.fixed_vars = {}\n\tfor orient in self.orients:\n\t\tif \"offset\" in orientations[orient].keys():\n\t\t\tself.has_orient_opt[orient] = True\n\t\t\tself.offsets.append({orient: orientations[orient][\"offset\"]})\n\t\t\t# ^ saves all info (TODO: check if still needed)\n\n\t\t\t# deg rotation *about* loading orientation:\n\t\t\tif isinstance(orientations[orient][\"offset\"][\"deg_bounds\"], (tuple, list)):\n\t\t\t\tself.orient_params.append(orient + \"_deg\")\n\t\t\t\tself.orient_bounds.append(\n\t\t\t\t\t[float(f) for f in orientations[orient][\"offset\"][\"deg_bounds\"]]\n\t\t\t\t)\n\t\t\telse:\n\t\t\t\tself.fixed_vars[(orient + \"_deg\")] = orientations[orient][\"offset\"][\n\t\t\t\t\t\"deg_bounds\"\n\t\t\t\t]\n\n\t\t\t# mag rotation *away from* loading:\n\t\t\tif isinstance(orientations[orient][\"offset\"][\"mag_bounds\"], (tuple, list)):\n\t\t\t\tself.orient_params.append(orient + \"_mag\")\n\t\t\t\tself.orient_bounds.append(\n\t\t\t\t\t[float(f) for f in orientations[orient][\"offset\"][\"mag_bounds\"]]\n\t\t\t\t)\n\t\t\telse:\n\t\t\t\tself.fixed_vars[(orient + \"_mag\")] = orientations[orient][\"offset\"][\n\t\t\t\t\t\"mag_bounds\"\n\t\t\t\t]\n\n\t\telse:\n\t\t\tself.has_orient_opt[orient] = False\n\n\t# combine material and orient info into one ordered list:\n\tself.params = self.material_params + self.orient_params\n\tself.bounds = as_float_tuples(self.material_bounds + self.orient_bounds)\n\n\t# descriptive stats on input object:\n\tself.num_params_material = len(self.material_params)\n\tself.num_params_orient = len(self.orient_params)\n\tself.num_params_total = len(self.params)\n</code></pre>"},{"location":"API/core/#matmdl.core.optimizer.get_next_param_set","title":"<code>get_next_param_set(opt, in_opt)</code>","text":"<p>Give next parameter set to try using current optimizer state.</p> <p>Allow to sample bounds exactly, round all else to reasonable precision.</p> Source code in <code>matmdl/core/optimizer.py</code> <pre><code>def get_next_param_set(opt: object, in_opt: object) -&gt; list[float]:\n\t\"\"\"\n\tGive next parameter set to try using current optimizer state.\n\n\tAllow to sample bounds exactly, round all else to reasonable precision.\n\t\"\"\"\n\tif len(state.next_params) &lt; 1:\n\t\traw_param_list = opt.ask(n_points=state.num_paramsets)\n\t\tfor raw_params in raw_param_list:\n\t\t\tnew_params = []\n\t\t\tfor param, bound in zip(raw_params, in_opt.bounds):\n\t\t\t\tif param in bound:\n\t\t\t\t\tnew_params.append(param)\n\t\t\t\telse:\n\t\t\t\t\tnew_params.append(round_sig(param, sig=6))\n\t\t\tstate.next_params.append(new_params)\n\tnew_params = state.next_params.popleft()\n\treturn new_params\n</code></pre>"},{"location":"API/core/#matmdl.core.optimizer.instantiate","title":"<code>instantiate(in_opt, uset)</code>","text":"<p>Define all optimization settings, return optimizer object.</p> <p>Parameters:</p> Name Type Description Default <code>in_opt</code> <code>object</code> <p>Input settings defined in :class:<code>InOpt</code>.</p> required <code>uset</code> <p>User settings from input file.</p> required <p>Returns:</p> Type Description <code>object</code> <p>skopt.Optimize: Instantiated optimization object.</p> Source code in <code>matmdl/core/optimizer.py</code> <pre><code>def instantiate(in_opt: object, uset: object) -&gt; object:\n\t\"\"\"\n\tDefine all optimization settings, return optimizer object.\n\n\tArgs:\n\t    in_opt: Input settings defined in :class:`InOpt`.\n\t    uset : User settings from input file.\n\n\tReturns:\n\t    skopt.Optimize: Instantiated optimization object.\n\t\"\"\"\n\topt = Optimizer(\n\t\tdimensions=in_opt.bounds,\n\t\tbase_estimator=\"gp\",\n\t\tn_initial_points=uset.n_initial_points,\n\t\tinitial_point_generator=\"lhs\",\n\t\tacq_func=\"EI\",\n\t\tacq_func_kwargs={\"xi\": 1.0},  # default is 0.01, higher values favor exploration\n\t)\n\treturn opt\n</code></pre>"},{"location":"API/core/#matmdl.core.optimizer.load_previous","title":"<code>load_previous(opt, search_local=False)</code>","text":"<p>Load input files of previous optimizations to use as initial points in current optimization.</p> <p>Looks for a file named <code>out_progress.txt</code> from which to load previous results. Requires access to global variable <code>opt_progress</code> that stores optimization output. The parameter bounds for the input files must be within current parameter bounds. Renumbers old/loaded results in <code>opt_progress</code> to have negative iteration numbers.</p> <p>Parameters:</p> Name Type Description Default <code>opt</code> <code>object</code> <p>Current instance of the optimizer object.</p> required <code>search_local</code> <code>bool</code> <p>Look in the current directory for files (convenient for plotting from parallel instances).</p> <code>False</code> <p>Returns:</p> Type Description <code>object</code> <p>skopt.Optimizer: Updated instance of the optimizer object.</p> Source code in <code>matmdl/core/optimizer.py</code> <pre><code>def load_previous(opt: object, search_local: bool = False) -&gt; object:\n\t\"\"\"\n\tLoad input files of previous optimizations to use as initial points in current optimization.\n\n\tLooks for a file named ``out_progress.txt`` from which to load previous results.\n\tRequires access to global variable ``opt_progress`` that stores optimization output.\n\tThe parameter bounds for the input files must be within current parameter bounds.\n\tRenumbers old/loaded results in ``opt_progress`` to have negative iteration numbers.\n\n\tArgs:\n\t    opt: Current instance of the optimizer object.\n\t    search_local: Look in the current directory for files\n\t        (convenient for plotting from parallel instances).\n\n\tReturns:\n\t    skopt.Optimizer: Updated instance of the optimizer object.\n\t\"\"\"\n\tfname_params = \"out_progress.txt\"\n\tfname_errors = \"out_errors.txt\"\n\n\tif uset.main_path not in [os.getcwd(), \".\"] and not search_local:\n\t\tfname_params = os.path.join(uset.main_path, fname_params)\n\t\tfname_errors = os.path.join(uset.main_path, fname_errors)\n\n\tparams = np.loadtxt(fname_params, skiprows=1, delimiter=\",\")\n\terrors = np.loadtxt(fname_errors, skiprows=1, delimiter=\",\")\n\tx_in = params[:, 1:].tolist()\n\ty_in = errors[:, -1].tolist()\n\n\tif __debug__:\n\t\twith open(\"out_debug.txt\", \"a+\") as f:\n\t\t\tf.write(\"loading previous results\\n\")\n\t\t\tf.writelines([f\"x_in: {x}\\ty_in: {y}\\n\" for x, y in zip(x_in, y_in)])\n\n\ttic = time.time()\n\tlog(\"Starting to reload previous data\")\n\topt.tell(x_in, y_in)\n\tlog(f\"Finished reloading previous data after {time.time()-tic:.2f} seconds.\")\n\treturn opt\n</code></pre>"},{"location":"API/core/#matmdl.core.optimizer.update_if_needed","title":"<code>update_if_needed(opt, in_params, in_errors)</code>","text":"<p>Give params and errors to state, updating optimizer if needed.</p> <p>Need is determined by state.num_paramsets, which is set by relative timing of the FEA and opt.tell() procedures.</p> <p><code>in_params</code> and <code>state.last_params</code> may contain duplicate updates from parallel instances, but these will be dealt with by opt.tell()</p> Source code in <code>matmdl/core/optimizer.py</code> <pre><code>def update_if_needed(opt, in_params, in_errors):\n\t\"\"\"\n\tGive params and errors to state, updating optimizer if needed.\n\n\tNeed is determined by state.num_paramsets, which is set by relative\n\ttiming of the FEA and opt.tell() procedures.\n\n\t`in_params` and `state.last_params` may contain duplicate updates from\n\tparallel instances, but these will be dealt with by opt.tell()\n\t\"\"\"\n\tif len(state.next_params) &lt; 1:\n\t\t# tell optimizer all accumulated params and errors and clear from state\n\t\tupdate_params = []\n\t\tupdate_errors = []\n\t\t# check for old data stored in state:\n\t\tfor params, errors in zip(state.last_params, state.last_errors):\n\t\t\tupdate_params.append(params)\n\t\t\tupdate_errors.append(errors)\n\t\t# add current information from args:\n\t\tupdate_params.append(in_params[0])\n\t\tupdate_errors.append(in_errors[0])\n\t\t# tell opt and clear state:\n\t\twith state.TimeTell()():\n\t\t\topt.tell(update_params, update_errors)\n\t\tstate.last_params = []\n\t\tstate.last_errors = []\n\telse:\n\t\t# tell state of the params and error value\n\t\tstate.last_params.append(in_params[0])\n\t\tstate.last_errors.append(in_errors[0])\n</code></pre>"},{"location":"API/core/#matmdl.core.parallel","title":"<code>parallel</code>","text":"<p>Module for dealing with the present optimization being one of many simultaneous instances. This is presumed to be the case when the setting <code>main_path</code> has a value. Everything here should be called within a Checkout guard.</p>"},{"location":"API/core/#matmdl.core.parallel.Checkout","title":"<code>Checkout</code>","text":"<p>Checkout shared resource without write collisions.</p> Source code in <code>matmdl/core/parallel.py</code> <pre><code>class Checkout:\n\t\"\"\"Checkout shared resource without write collisions.\"\"\"\n\n\tdef __init__(self, fname, local=False):\n\t\tself.start = time.time()\n\t\tself.fname = fname\n\t\tif local:\n\t\t\tself.fpath = os.path.join(os.getcwd(), fname)\n\t\telse:\n\t\t\tself.source = os.getcwd()\n\t\t\tself.fpath = os.path.join(uset.main_path, fname)\n\n\tdef __enter__(self):\n\t\tcutoff_seconds = 420\n\n\t\twhile True and time.time() - self.start &lt; cutoff_seconds:\n\t\t\tlockfile_exists = os.path.isfile(self.fpath + \".lck\")\n\t\t\tif lockfile_exists:\n\t\t\t\ttry:\n\t\t\t\t\twith open(self.fpath + \".lck\", \"r\") as f:\n\t\t\t\t\t\tsource = f.read()\n\t\t\t\t\tmsg(\n\t\t\t\t\t\tf\"Waiting on Checkout for {time.time()-self.start:.3f} seconds from {source}\"\n\t\t\t\t\t)\n\t\t\t\texcept FileNotFoundError:\n\t\t\t\t\tmsg(f\"Waiting on Checkout for {time.time()-self.start:.3f} seconds\")\n\t\t\t\ttime.sleep(1)\n\t\t\telse:\n\t\t\t\twith open(self.fpath + \".lck\", \"a+\") as f:\n\t\t\t\t\tf.write(f\"{os.getcwd()}\\n\")\n\t\t\t\tself.time_unlocked = time.time()\n\t\t\t\t# check for collisions\n\t\t\t\ttime.sleep(0.010)  # allow potential collision cases to catch up\n\t\t\t\ttry:\n\t\t\t\t\twith open(self.fpath + \".lck\", \"r\") as f:\n\t\t\t\t\t\tlines = f.readlines()\n\t\t\t\texcept FileNotFoundError:\n\t\t\t\t\tlines = []\n\t\t\t\tif len(lines) != 1:\n\t\t\t\t\twarn(\"Warning: collision detected between processes:\", RuntimeWarning)\n\t\t\t\t\tfor line in lines:\n\t\t\t\t\t\tprint(f\"\\t{line}\", flush=True)\n\t\t\t\t\twarn(\"Reattempting to checkout resource\", RuntimeWarning)\n\t\t\t\t\ttry:\n\t\t\t\t\t\tos.remove(self.fpath + \".lck\")\n\t\t\t\t\texcept FileNotFoundError:\n\t\t\t\t\t\tpass  # only one process will successfully remove file\n\t\t\t\t\ttime.sleep(4.0 * random.random())  # wait for a sec before restarting\n\t\t\t\t\tself.__enter__()  # try again\n\n\t\t\t\tmsg(f\"Unlocked after {time.time()-self.start:.3f} seconds\")\n\t\t\t\tbreak\n\t\tif time.time() - self.start &gt; cutoff_seconds:\n\t\t\traise RuntimeError(\n\t\t\t\tf\"Error: waited for resource {self.fname} for longer than {cutoff_seconds}s, exiting.\"\n\t\t\t)\n\n\tdef __exit__(self, exc_type, exc_value, exc_tb):\n\t\tif False:  # debugging\n\t\t\twith open(self.fpath + \".lck\", \"r\") as f:\n\t\t\t\tsource = f.read()\n\t\t\tprint(f\"Exit: rm lock from: {source}\", flush=True)\n\t\tos.remove(self.fpath + \".lck\")\n\t\tmsg(f\"Exiting Checkout after {time.time()-self.time_unlocked:.3f} seconds.\")\n\n\tdef __call__(self, fn):\n\t\t\"\"\"\n\t\tDecorator to use if whole function needs resource checked out.\n\t\t\"\"\"\n\n\t\tdef decorator():\n\t\t\twith self:\n\t\t\t\treturn fn()\n\n\t\treturn decorator\n</code></pre>"},{"location":"API/core/#matmdl.core.parallel.Checkout.__call__","title":"<code>__call__(fn)</code>","text":"<p>Decorator to use if whole function needs resource checked out.</p> Source code in <code>matmdl/core/parallel.py</code> <pre><code>def __call__(self, fn):\n\t\"\"\"\n\tDecorator to use if whole function needs resource checked out.\n\t\"\"\"\n\n\tdef decorator():\n\t\twith self:\n\t\t\treturn fn()\n\n\treturn decorator\n</code></pre>"},{"location":"API/core/#matmdl.core.parallel.assert_db_lengths_match","title":"<code>assert_db_lengths_match()</code>","text":"<p>loads and checks lengths of all output files; used for debugging</p> Source code in <code>matmdl/core/parallel.py</code> <pre><code>def assert_db_lengths_match():\n\t\"\"\"loads and checks lengths of all output files; used for debugging\"\"\"\n\tlengths = []\n\tfor npyfile in [f for f in os.listdir(uset.main_path) if f.endswith(\"npy\")]:\n\t\tdat = np.load(os.path.join(uset.main_path, npyfile))\n\t\tlengths.append(np.shape(dat)[2])\n\tfor outfile in [\n\t\tf for f in os.listdir(uset.main_path) if f.startswith(\"out_\") and f.endswith(\".txt\")\n\t]:\n\t\tdat = np.loadtxt(os.path.join(uset.main_path, outfile), delimiter=\",\", skiprows=1)\n\t\tlengths.append(np.shape(dat)[0])\n\n\tif len(set(lengths)) &gt; 1:\n\t\terror_time = time.time_ns()\n\t\twith open(os.path.join(uset.main_path, \"out_progress.txt\"), \"a+\") as f:\n\t\t\tf.write(f\"{error_time}, ERROR from {os.getcwd()}\")\n\t\traise RuntimeError(f\"mismatch in DB lengths at time: {error_time}\")\n</code></pre>"},{"location":"API/core/#matmdl.core.parallel.check_parallel","title":"<code>check_parallel()</code>","text":"<p>Starts parallel initialization if needed.</p> Note <p>This copies files from <code>uset.main_path</code> but does not reload the input file.</p> Source code in <code>matmdl/core/parallel.py</code> <pre><code>def check_parallel():\n\t\"\"\"\n\tStarts parallel initialization if needed.\n\n\tNote:\n\t\tThis copies files from `uset.main_path` but does not reload the input file.\n\t\"\"\"\n\tif uset.main_path not in [os.getcwd(), \".\"]:\n\t\tmsg(\"Starting as a parallel instance\")\n\t\tcopy_files(file_patterns)\n</code></pre>"},{"location":"API/core/#matmdl.core.parallel.copy_files","title":"<code>copy_files(file_patterns)</code>","text":"<p>copy files from uset.main_path to runner dir</p> Source code in <code>matmdl/core/parallel.py</code> <pre><code>def copy_files(file_patterns):\n\t\"\"\"copy files from uset.main_path to runner dir\"\"\"\n\n\t# exact filenames\n\tflist = [\"input.toml\"]\n\tfor orient in uset.orientations.keys():  # no need for ordering here\n\t\tflist.append(uset.orientations[orient][\"exp\"])\n\t\ttry:\n\t\t\tflist.append(uset.orientations[orient][\"inp\"][0])\n\t\texcept KeyError:\n\t\t\t# orientation generated, no input file needed\n\t\t\tpass\n\n\t# file list defined in engines:\n\tfor f in os.listdir(uset.main_path):\n\t\tfor pattern in file_patterns:\n\t\t\tif re.search(pattern, f):\n\t\t\t\tflist.append(f)\n\n\t# copy files to current directory\n\tfor f in flist:\n\t\tcopy(os.path.join(uset.main_path, f), os.getcwd())\n</code></pre>"},{"location":"API/core/#matmdl.core.parallel.update_parallel","title":"<code>update_parallel()</code>","text":"<p>Update state if needed based on shared database timing information.</p> <p>Returns:</p> Name Type Description <code>params</code> <code>list</code> <p>parameter values (list) of unseen points to be updated</p> <code>errors</code> <code>list</code> <p>error values (scalar) of unseen points to be updated</p> Note <p>Also updates <code>state.last_updated</code> timing information.</p> Source code in <code>matmdl/core/parallel.py</code> <pre><code>def update_parallel():\n\t\"\"\"\n\tUpdate state if needed based on shared database timing information.\n\n\tReturns:\n\t\tparams (list): parameter values (list) of unseen points to be updated\n\t\terrors (list): error values (scalar) of unseen points to be updated\n\n\tNote:\n\t\tAlso updates `state.last_updated` timing information.\n\t\"\"\"\n\tif uset.main_path in [os.getcwd(), \".\"]:\n\t\treturn ([], [])\n\n\tnum_newlines = _get_num_newlines()\n\tif num_newlines &lt; 1:\n\t\treturn ([], [])\n\n\t# update state:\n\tnum_lines = _get_totlines()\n\tstart_line = num_lines - num_newlines + 1\n\tupdate_params = np.loadtxt(\n\t\tos.path.join(uset.main_path, \"out_progress.txt\"),\n\t\tdelimiter=\",\",\n\t\tskiprows=start_line,\n\t)\n\tupdate_errors = np.loadtxt(\n\t\tos.path.join(uset.main_path, \"out_errors.txt\"),\n\t\tdelimiter=\",\",\n\t\tskiprows=start_line,\n\t)\n\n\t# strict output database assertion:\n\t# assert_db_lengths_match()\n\n\t# quick assertion for params and errors only:\n\thas_multiple = len(np.shape(update_params)) == 2\n\tlen_params = np.shape(update_params)[0] if has_multiple else 1\n\tlen_errors = np.shape(update_errors)[0] if has_multiple else 1\n\t# ^ (if shape is 1D then there is only one entry)\n\tassert (\n\t\tlen_params == len_errors\n\t), f\"Error: mismatch in output database size! Found {len_params} params and {len_errors} errors\"\n\n\tupdate_params_pass = []\n\tupdate_errors_pass = []\n\tif has_multiple:\n\t\tfor i in range(np.shape(update_params)[0]):\n\t\t\tupdate_params_pass.append(list(update_params[i, 1:]))  # first value is time\n\t\t\tupdate_errors_pass.append(float(update_errors[i, -1]))  # last value is mean\n\telse:\n\t\tupdate_params_pass.append(list(update_params[1:]))\n\t\tupdate_errors_pass.append(float(update_errors[-1]))\n\n\tstate.update_read()\n\treturn update_params_pass, update_errors_pass\n</code></pre>"},{"location":"API/core/#matmdl.core.parser","title":"<code>parser</code>","text":"<p>Module that loads and checks input file.</p>"},{"location":"API/core/#matmdl.core.parser.UserSettings","title":"<code>UserSettings</code>","text":"<p>Load, check, and store input from the input file.</p> Note <p>Attributes must be written/deleted within an unlock context manager and should not be overwitten during the optimization since changing behavior makes the history harder to follow.</p> Source code in <code>matmdl/core/parser.py</code> <pre><code>class UserSettings:\n\t\"\"\"\n\tLoad, check, and store input from the input file.\n\n\tNote:\n\t\tAttributes must be written/deleted within an unlock context\n\t\tmanager and should not be overwitten during the optimization\n\t\tsince changing behavior makes the history harder to follow.\n\t\"\"\"\n\n\tclass Option:\n\t\t\"\"\"Options that are commonly associated with each input.\"\"\"\n\n\t\tdef __init__(self, **kwargs):\n\t\t\t\"\"\"Defaults for option instances.\"\"\"\n\t\t\tif \"crit\" in kwargs:\n\t\t\t\tself.crit = kwargs.get(\"crit\")\n\t\t\telse:\n\t\t\t\tself.crit = True\n\t\t\tif \"types\" in kwargs:\n\t\t\t\tself.types = kwargs.get(\"types\")\n\t\t\telse:\n\t\t\t\tself.types = []\n\t\t\tif \"lower\" in kwargs:\n\t\t\t\tself.lower = kwargs.get(\"lower\")\n\t\t\telse:\n\t\t\t\tself.lower = None\n\t\t\tif \"upper\" in kwargs:\n\t\t\t\tself.upper = kwargs.get(\"upper\")\n\t\t\telse:\n\t\t\t\tself.upper = None\n\t\t\tif \"default\" in kwargs:\n\t\t\t\tself.default = kwargs.get(\"default\")\n\n\tinput_reqs = {\n\t\t\"run\": {\n\t\t\t\"loop_len\": Option(types=[int], lower=2),\n\t\t\t\"n_initial_points\": Option(types=[int], lower=2),\n\t\t\t\"large_error\": Option(types=[int, float]),\n\t\t\t\"param_file\": Option(types=[str]),\n\t\t\t\"length\": Option(types=[int, float]),\n\t\t\t\"area\": Option(types=[int, float]),\n\t\t\t\"jobname\": Option(types=[str]),\n\t\t\t\"recursion_depth\": Option(types=[int]),\n\t\t\t\"max_strain\": Option(types=[int, float], crit=False, default=0.0),\n\t\t\t\"min_strain\": Option(types=[int, float], crit=False, default=0.0),\n\t\t\t\"i_powerlaw\": Option(types=[int]),\n\t\t\t\"umat\": Option(types=[str, bool], crit=False, default=False),\n\t\t\t\"cpus\": Option(types=[int]),\n\t\t\t\"do_load_previous\": Option(types=[bool, int]),\n\t\t\t\"is_compression\": Option(types=[bool]),\n\t\t\t\"slope_weight\": Option(types=[int, float], crit=False, default=0.4),\n\t\t\t\"main_path\": Option(types=[str], crit=False, default=os.getcwd()),\n\t\t\t\"format\": Option(types=[str], crit=False, default=\"huang\"),\n\t\t\t\"executable_path\": Option(types=[str, bool], crit=False, default=False),\n\t\t\t\"error_deviation_weight\": Option(types=[float], crit=False, default=0.10, lower=0.0, upper=1.0),\n\t\t\t\"do_single\": Option(types=[bool], crit=False, default=False),\n\t\t},\n\t\t\"plot\": {\n\t\t\t\"grain_size_name\": Option(crit=False, types=[str]),\n\t\t\t\"title\": Option(crit=False, types=[str]),\n\t\t\t\"param_additional_legend\": Option(crit=False, types=[str]),\n\t\t},\n\t}\n\n\tdef __init__(self, input_fname=\"input.toml\"):\n\t\tcategories = [\"run\", \"plot\"]\n\t\twith open(input_fname, \"rb\") as f:\n\t\t\tconf = tomllib.load(f)\n\n\t\t# write params:\n\t\twith self.unlock():\n\t\t\tself.params = conf[\"params\"]\n\t\t\tif len(conf[\"orientations\"]) &gt; 0:\n\t\t\t\tself.orientations = {}\n\t\t\t\tfor orient in conf[\"orientations\"]:\n\t\t\t\t\tself.orientations[orient[\"name\"]] = orient\n\n\t\t\t# get all input:\n\t\t\tfor category in categories:\n\t\t\t\tfor key, value in conf[category].items():\n\t\t\t\t\tif key not in self.input_reqs[category].keys():\n\t\t\t\t\t\traise AttributeError(f\"Unknown input: {key}\")\n\t\t\t\t\tself.__dict__[key] = value\n\n\t\t\t# check if defaults needed:\n\t\t\tfor category in categories:\n\t\t\t\tfor key, value in self.input_reqs[category].items():\n\t\t\t\t\tif key not in self.__dict__:\n\t\t\t\t\t\ttry:\n\t\t\t\t\t\t\tprint(\n\t\t\t\t\t\t\t\tf\"Input warning: input {key} not found, using default value of {value.default}\"\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\tself.__dict__[key] = value.default\n\t\t\t\t\t\texcept AttributeError:\n\t\t\t\t\t\t\traise AttributeError(f\"\\nInput: no default found for option {key}\\n\")\n\n\t\t# general checks:\n\t\tfor key, req in self.input_reqs[\"run\"].items():\n\t\t\tif key not in self.__dict__.keys():\n\t\t\t\tif req.crit is True:\n\t\t\t\t\traise AttributeError(f\"Missing critical input: {key}\")\n\t\t\t\telse:\n\t\t\t\t\tcontinue\n\t\t\tvalue = self.__dict__[key]\n\t\t\tif req.types:\n\t\t\t\tinput_type = type(value)\n\t\t\t\tif input_type not in req.types:\n\t\t\t\t\traise AttributeError(f\"Input type of {input_type} not one of {req.types}\")\n\t\t\tif req.lower:\n\t\t\t\tif value &lt; req.lower:\n\t\t\t\t\traise ValueError(\n\t\t\t\t\t\tf\"Input of {value} for `{key}` is below lower bound of {req.lower}\"\n\t\t\t\t\t)\n\t\t\tif req.upper:\n\t\t\t\tvalue = self.__dict__[key]\n\t\t\t\tif value &gt; req.upper:\n\t\t\t\t\traise ValueError(\n\t\t\t\t\t\tf\"Input of {value} for `{key}` is above upper bound of {req.upper}\"\n\t\t\t\t\t)\n\n\t\t# check if this is a single run\n\t\tany_bounds = False\n\t\tfor param_name, param_value in self.params.items():\n\t\t\tif type(param_value) in [list, tuple]:\n\t\t\t\tany_bounds = True\n\t\twith self.unlock():\n\t\t\tif not any_bounds:\n\t\t\t\tself.do_single = True\n\t\t\t\tlog(\"Warning: parser: no bounded parameters in input file, running single.\")\n\t\t\telse:\n\t\t\t\tself.do_single = False\n\n\t\t# individual checks:\n\t\tif self.i_powerlaw not in [0, 1]:\n\t\t\traise NotImplementedError(f\"No known option for i_powerlaw: {self.i_powerlaw}\")\n\t\tif self.n_initial_points &gt; self.loop_len:\n\t\t\traise ValueError(\n\t\t\t\tf\"Input initial points ({self.n_initial_points}) greater than total iterations ({self.loop_len})\"\n\t\t\t)\n\t\tif self.format.lower() not in [\"huang\", \"fepx\"]:\n\t\t\traise ValueError(\n\t\t\t\tf\"Unexpected format option {self.format}; should be either huang or fepx.\"\n\t\t\t)\n\t\t# TODO add more individual checks if needed\n\n\t@contextmanager\n\tdef unlock(self):\n\t\tself.is_locked = False\n\t\ttry:\n\t\t\tyield self\n\t\tfinally:\n\t\t\tself.is_locked = True\n\n\tdef __setattr__(self, name, value):\n\t\tif name == \"is_locked\" or self.is_locked is False:\n\t\t\tsuper().__setattr__(name, value)\n\t\telse:\n\t\t\traise AttributeError(self, \"Don't touch my stuff\")\n\n\tdef __delattr__(self, name, value):\n\t\tif self.is_locked is False:\n\t\t\tsuper().__delattr__(name, value)\n\t\telse:\n\t\t\traise AttributeError(self, \"Don't wreck my stuff\")\n</code></pre>"},{"location":"API/core/#matmdl.core.parser.UserSettings.Option","title":"<code>Option</code>","text":"<p>Options that are commonly associated with each input.</p> Source code in <code>matmdl/core/parser.py</code> <pre><code>class Option:\n\t\"\"\"Options that are commonly associated with each input.\"\"\"\n\n\tdef __init__(self, **kwargs):\n\t\t\"\"\"Defaults for option instances.\"\"\"\n\t\tif \"crit\" in kwargs:\n\t\t\tself.crit = kwargs.get(\"crit\")\n\t\telse:\n\t\t\tself.crit = True\n\t\tif \"types\" in kwargs:\n\t\t\tself.types = kwargs.get(\"types\")\n\t\telse:\n\t\t\tself.types = []\n\t\tif \"lower\" in kwargs:\n\t\t\tself.lower = kwargs.get(\"lower\")\n\t\telse:\n\t\t\tself.lower = None\n\t\tif \"upper\" in kwargs:\n\t\t\tself.upper = kwargs.get(\"upper\")\n\t\telse:\n\t\t\tself.upper = None\n\t\tif \"default\" in kwargs:\n\t\t\tself.default = kwargs.get(\"default\")\n</code></pre>"},{"location":"API/core/#matmdl.core.parser.UserSettings.Option.__init__","title":"<code>__init__(**kwargs)</code>","text":"<p>Defaults for option instances.</p> Source code in <code>matmdl/core/parser.py</code> <pre><code>def __init__(self, **kwargs):\n\t\"\"\"Defaults for option instances.\"\"\"\n\tif \"crit\" in kwargs:\n\t\tself.crit = kwargs.get(\"crit\")\n\telse:\n\t\tself.crit = True\n\tif \"types\" in kwargs:\n\t\tself.types = kwargs.get(\"types\")\n\telse:\n\t\tself.types = []\n\tif \"lower\" in kwargs:\n\t\tself.lower = kwargs.get(\"lower\")\n\telse:\n\t\tself.lower = None\n\tif \"upper\" in kwargs:\n\t\tself.upper = kwargs.get(\"upper\")\n\telse:\n\t\tself.upper = None\n\tif \"default\" in kwargs:\n\t\tself.default = kwargs.get(\"default\")\n</code></pre>"},{"location":"API/core/#matmdl.core.runner","title":"<code>runner</code>","text":"<p>Helper module for some abstracted commands used in run.</p>"},{"location":"API/core/#matmdl.core.runner.check_single","title":"<code>check_single()</code>","text":"<p>rough copy of run/single_loop that does not use an optimizer object</p> Source code in <code>matmdl/core/runner.py</code> <pre><code>def check_single():\n\t\"\"\"rough copy of run/single_loop that does not use an optimizer object\"\"\"\n\tif not uset.do_single:\n\t\treturn\n\tprint(\"DBG: starting single run!\")\n\n\t# load options:\n\tin_opt = optimizer.InOpt(uset.orientations, uset.params)\n\tnext_params = []\n\texp_data = ExpData(uset.orientations)  # noqa: F841\n\t# above line to make main input files with correct strain magnitude\n\n\t# ck that there are no ranges in input\n\tfor param_name, param_value in uset.params.items():\n\t\tif type(param_value) in [list, tuple]:\n\t\t\traise TypeError(\n\t\t\t\tf\"Expected prescribed parameters for single run; found parameter bounds for {param_name}\"\n\t\t\t)\n\n\tengine.prepare()\n\tfor orient in in_opt.orients:\n\t\tdo_orientation_inputs(next_params, orient, in_opt)\n\t\ttry:\n\t\t\tshutil.copy(f\"{uset.jobname}_{orient}.inp\", f\"{uset.jobname}.inp\")\n\t\texcept FileNotFoundError:\n\t\t\t# per-orientation inputs not used, could be a single input run\n\t\t\tpass\n\n\t\tengine.run()\n\t\tif not engine.has_completed():\n\t\t\tprint(f\"DBG: refining orient {orient}\")\n\t\t\trefine_run()\n\t\tif not engine.has_completed():\n\t\t\tprint(f\"DBG: not complete with {orient}, exiting...\")\n\t\t\tsys.exit(1)\n\t\telse:\n\t\t\toutput_fname = f\"temp_time_disp_force_{orient}.csv\"\n\t\t\tif os.path.isfile(output_fname):\n\t\t\t\tos.remove(output_fname)\n\t\t\tengine.extract(orient)  # extract data to temp_time_disp_force.csv\n\t\t\tif np.sum(np.loadtxt(output_fname, delimiter=\",\", skiprows=1)[:, 1:2]) == 0:\n\t\t\t\tprint(f\"Warning: incomplete run for {orient}, continuing...\")\n\t\t\t\treturn\n\tprint(\"DBG: exiting single run!\")\n\tsys.exit(0)\n</code></pre>"},{"location":"API/core/#matmdl.core.runner.get_first","title":"<code>get_first(opt, in_opt, exp_data)</code>","text":"<p>Run one simulation so its output dimensions can later inform the shape of output data.</p> Source code in <code>matmdl/core/runner.py</code> <pre><code>def get_first(opt, in_opt, exp_data) -&gt; None:\n\t\"\"\"\n\tRun one simulation so its output dimensions can later inform the shape of output data.\n\t\"\"\"\n\t# test with strain of 0.2%\n\tengine.write_strain(uset.length * 0.002, f\"{uset.jobname}.inp\")\n\twith state.TimeRun()():\n\t\tengine.run()\n\tif not engine.has_completed():\n\t\trefine_run()\n\tengine.extract(\"initial\")\n\t# reset to first max_strain; if multiple samples, will be overwritten anyway\n\tfirst_sample = list(exp_data.data.keys())[0]\n\tengine.write_strain(exp_data.data[first_sample][\"max_strain\"], f\"{uset.jobname}.inp\")\n</code></pre>"},{"location":"API/core/#matmdl.core.runner.refine_run","title":"<code>refine_run(ct=0)</code>","text":"<p>Restart simulation with smaller maximum increment size.</p> <p>Cut max increment size by <code>factor</code> (hardcoded), possibly multiple times up to <code>uset.recursion_depth</code> or until Abaqus finished successfully. After eventual success or failure, rewrites original input file so that the next run starts with the initial, large maximum increment. Recursive calls tracked through <code>ct</code> parameter.</p> <p>Parameters:</p> Name Type Description Default <code>ct</code> <code>int</code> <p>Number of times this function has already been called. Starts at 0 and can go up to <code>uset.recursion_depth</code>.</p> <code>0</code> Source code in <code>matmdl/core/runner.py</code> <pre><code>def refine_run(ct: int = 0):\n\t\"\"\"\n\tRestart simulation with smaller maximum increment size.\n\n\tCut max increment size by ``factor`` (hardcoded), possibly multiple\n\ttimes up to ``uset.recursion_depth`` or until Abaqus finished successfully.\n\tAfter eventual success or failure, rewrites original input file so that the\n\tnext run starts with the initial, large maximum increment.\n\tRecursive calls tracked through ``ct`` parameter.\n\n\tArgs:\n\t    ct: Number of times this function has already been called. Starts\n\t        at 0 and can go up to ``uset.recursion_depth``.\n\t\"\"\"\n\tif uset.format == \"fepx\":\n\t\t# TODO should separate out all engine-specific calls\n\t\t# and raise NotImplemented errors from there if applicable\n\t\treturn\n\tfactor = 5.0\n\tct += 1\n\t# remove old lock file from previous unfinished simulation\n\tsubprocess.run(\"rm *.lck\", shell=True)\n\tfilename = uset.jobname + \".inp\"\n\ttempfile = \"temp_input.txt\"\n\twith open(filename, \"r\") as f:\n\t\tlines = f.readlines()\n\n\t# exit strategy:\n\tif ct == 1:  # need to save original parameters outside of this recursive function\n\t\twith open(tempfile, \"w\") as f:\n\t\t\tf.writelines(lines)\n\n\tdef write_original(filename):\n\t\twith open(tempfile, \"r\") as f:\n\t\t\tlines = f.readlines()\n\t\twith open(filename, \"w\") as f:\n\t\t\tf.writelines(lines)\n\n\t# find line after step line:\n\tstep_line_ind = [i for i, line in enumerate(lines) if line.lower().startswith(\"*static\")][0] + 1\n\tstep_line = [number.strip() for number in lines[step_line_ind].strip().split(\",\")]\n\toriginal_increment = float(step_line[-1])\n\n\t# use original / factor:\n\tnew_step_line = step_line[:-1] + [\"%.4E\" % (original_increment / factor)]\n\tnew_step_line_str = str(new_step_line[0])\n\tfor i in range(1, len(new_step_line)):\n\t\tnew_step_line_str = new_step_line_str + \", \"\n\t\tnew_step_line_str = new_step_line_str + str(new_step_line[i])\n\tnew_step_line_str = new_step_line_str + \"\\n\"\n\twith open(filename, \"w\") as f:\n\t\tf.writelines(lines[:step_line_ind])\n\t\tf.writelines(new_step_line_str)\n\t\tf.writelines(lines[step_line_ind + 1 :])\n\tengine.run()\n\tif engine.has_completed():\n\t\twrite_original(filename)\n\t\treturn\n\telif ct &gt;= uset.recursion_depth:\n\t\twrite_original(filename)\n\t\treturn\n\telse:\n\t\trefine_run(ct)\n</code></pre>"},{"location":"API/core/#matmdl.core.runner.remove_out_files","title":"<code>remove_out_files()</code>","text":"<p>Delete files from previous optimization runs if not reloading results.</p> Source code in <code>matmdl/core/runner.py</code> <pre><code>def remove_out_files():\n\t\"\"\"Delete files from previous optimization runs if not reloading results.\"\"\"\n\tif not uset.do_load_previous:\n\t\tout_files = [\n\t\t\tf\n\t\t\tfor f in os.listdir(os.getcwd())\n\t\t\tif (f.startswith(\"out_\") or f.startswith(\"res_\") or f.startswith(\"temp_\"))\n\t\t]\n\t\tif len(out_files) &gt; 0:\n\t\t\tfor f in out_files:\n\t\t\t\tos.remove(f)\n\tjob_files = [\n\t\tf\n\t\tfor f in os.listdir(os.getcwd())\n\t\tif (f.startswith(uset.jobname)) and not (f.endswith(\".inp\"))\n\t]\n\tfor f in job_files:\n\t\tif os.path.isdir(f):\n\t\t\tos.rmdir(f)\n\t\telse:\n\t\t\tos.remove(f)\n</code></pre>"},{"location":"API/core/#matmdl.core.state","title":"<code>state</code>","text":"<p>Module for optimization state meta-indicators, like iteration number and time.</p>"},{"location":"API/core/#matmdl.core.state.State","title":"<code>State</code>","text":"<p>Contains and updates iteration and timing for each optimization process.</p> <p>Attributes:</p> Name Type Description <code>iterations</code> <code>int</code> <p>number of iterations performed by this process</p> <code>last_updated</code> <code>int</code> <p>time in unix nanoseconds of the last update to the optimizer state from any process</p> <code>tell_time</code> <code>float</code> <p>duration of time in seconds for the opt.tell process</p> <code>run_time</code> <code>float</code> <p>duration of time in seconds for a single iteration of the run process</p> Note <p>Warns when <code>tell_time</code> &gt; <code>run_time</code> but does not change behavior.</p> Source code in <code>matmdl/core/state.py</code> <pre><code>class State:\n\t\"\"\"\n\tContains and updates iteration and timing for each optimization process.\n\n\tAttributes:\n\t    iterations (int): number of iterations performed by this process\n\t    last_updated (int): time in unix nanoseconds of the last update to the\n\t        optimizer state from any process\n\t    tell_time (float): duration of time in seconds for the opt.tell process\n\t    run_time (float): duration of time in seconds for a single iteration of the\n\t        run process\n\n\tNote:\n\t    Warns when `tell_time` &gt; `run_time` but does not change behavior.\n\t\"\"\"\n\n\tdef __init__(self):\n\t\tself.iterations = 0\n\t\tself.last_updated = time.time_ns()\n\t\tself.tell_time = 0.0\n\t\tself.run_time = 0.0\n\t\tself.next_params = deque()\n\t\tself.last_params = []\n\t\tself.last_errors = []\n\t\tself.num_paramsets = 1\n\n\tdef update_write(self):\n\t\tself.iterations += 1\n\t\tself.last_updated = time.time_ns()\n\n\tdef update_read(self):\n\t\tself.last_updated = time.time_ns()\n\n\tdef TimeRun(self):\n\t\tclass TimeRun:\n\t\t\tdef __enter__(innerself):\n\t\t\t\tinnerself.tic = time.time()\n\n\t\t\tdef __exit__(innerself, exc_type, exc_value, exc_tb):\n\t\t\t\tself.run_time = time.time() - innerself.tic\n\n\t\treturn TimeRun\n\n\tdef TimeTell(self):\n\t\tclass TimeTell:\n\t\t\tdef __enter__(innerself):\n\t\t\t\tinnerself.tic = time.time()\n\n\t\t\tdef __exit__(innerself, exc_type, exc_value, exc_tb):\n\t\t\t\tnew_time_tell = time.time() - innerself.tic\n\t\t\t\tif new_time_tell &gt; self.run_time:\n\t\t\t\t\twarn(\n\t\t\t\t\t\tf\"Taking longer to tell than to run: {new_time_tell:.1f} vs {self.run_time:.1f} seconds. Incrementing sequence length from {self.num_paramsets}.\",\n\t\t\t\t\t\tRuntimeWarning,\n\t\t\t\t\t)\n\t\t\t\t\tself.num_paramsets += 1\n\t\t\t\tself.tell_time = new_time_tell\n\n\t\treturn TimeTell\n</code></pre>"},{"location":"API/core/#matmdl.core.utilities","title":"<code>utilities</code>","text":"<p>Utility functions that fit nowhere else. These should have no <code>matmdl</code> dependencies.</p>"},{"location":"API/core/#matmdl.core.utilities.as_float_tuples","title":"<code>as_float_tuples(list_of_tuples)</code>","text":"<p>Make sure tuples contain only floats.</p> <p>Take list of tuples that may include ints and return list of tuples containing only floats. Useful for optimizer param bounds since type of input determines type of param guesses. Skips non-tuple items in list.</p> <p>Parameters:</p> Name Type Description Default <code>list_of_tuples</code> <code>list[tuple[Union[int, float]]]</code> <p>Tuples in this list may contain a mix of floats and ints.</p> required <p>Returns:     The same list of tuples containing only floats.</p> Source code in <code>matmdl/core/utilities.py</code> <pre><code>def as_float_tuples(\n\tlist_of_tuples: list[tuple[Union[int, float]]],\n) -&gt; list[tuple[float]]:\n\t\"\"\"\n\tMake sure tuples contain only floats.\n\n\tTake list of tuples that may include ints and return list of tuples containing only floats. Useful for optimizer param bounds since type of input determines type of param guesses. Skips non-tuple items in list.\n\n\tArgs:\n\t    list_of_tuples: Tuples in this list may contain a mix of\n\t        floats and ints.\n\tReturns:\n\t    The same list of tuples containing only floats.\n\n\t\"\"\"\n\tnew_list = []\n\tprec = 10  # decimal places in scientific notation\n\n\tdef sigfig(val):\n\t\treturn float((\"%.\" + str(prec) + \"e\") % val)\n\n\tfor old_item in list_of_tuples:\n\t\tif isinstance(old_item, tuple):\n\t\t\tnew_item = tuple(map(sigfig, old_item))\n\t\telse:\n\t\t\tnew_item = old_item\n\t\tnew_list.append(new_item)\n\treturn new_list\n</code></pre>"},{"location":"API/core/#matmdl.core.utilities.log","title":"<code>log(message)</code>","text":"<p>append message to local log file with time stamp</p> Source code in <code>matmdl/core/utilities.py</code> <pre><code>def log(message: str):\n\t\"\"\"append message to local log file with time stamp\"\"\"\n\twith open(\"out_log.txt\", \"a+\") as f:\n\t\tf.write(f\"{time.time():.2f}: {message}\\n\")\n</code></pre>"},{"location":"API/core/#matmdl.core.utilities.msg","title":"<code>msg(message)</code>","text":"<p>broadcast message to stdout if not run with -0</p> Source code in <code>matmdl/core/utilities.py</code> <pre><code>def msg(message: str):\n\t\"\"\"broadcast message to stdout if not run with -0\"\"\"\n\tif __debug__:\n\t\tprint(message, flush=True)\n</code></pre>"},{"location":"API/core/#matmdl.core.utilities.unit_vector","title":"<code>unit_vector(vector)</code>","text":"<p>Gives a normalized vector using <code>numpy.linalg.norm</code>.</p> Source code in <code>matmdl/core/utilities.py</code> <pre><code>def unit_vector(vector: \"vector\") -&gt; \"vector\":\n\t\"\"\"Gives a normalized vector using ``numpy.linalg.norm``.\"\"\"\n\treturn vector / norm(vector)\n</code></pre>"},{"location":"API/core/#matmdl.core.utilities.warn","title":"<code>warn(message, warn_type=UserWarning)</code>","text":"<p>Raise warning with consistent formatting</p> Source code in <code>matmdl/core/utilities.py</code> <pre><code>def warn(message: str, warn_type=UserWarning):\n\t\"\"\"Raise warning with consistent formatting\"\"\"\n\twarnings.formatwarning = (\n\t\tlambda msg, warn_type, *args, **kwargs: f\"{warn_type.__name__}: {msg}\\n\"\n\t)\n\twarnings.warn(message, warn_type)\n</code></pre>"},{"location":"API/core/#matmdl.core.writer","title":"<code>writer</code>","text":"<p>Module for writing to files.</p>"},{"location":"API/core/#matmdl.core.writer.combine_SS","title":"<code>combine_SS(zeros, orientation)</code>","text":"<p>Reads npy stress-strain output and appends current results.</p> <p>Loads from <code>temp_time_disp_force_{orientation}.csv</code> and writes to <code>out_time_disp_force_{orientation}.npy</code>. Should only be called after all orientations have run, since <code>zeros==True</code> if any one fails.</p> <p>For parallel, needs to be called within a parallel.Checkout guard.</p> <p>Parameters:</p> Name Type Description Default <code>zeros</code> <code>bool</code> <p>True if the run failed and a sheet of zeros should be written in place of real time-force-displacement data.</p> required <code>orientation</code> <code>str</code> <p>Orientation nickname to keep temporary output files separate.</p> required Source code in <code>matmdl/core/writer.py</code> <pre><code>def combine_SS(zeros: bool, orientation: str) -&gt; None:\n\t\"\"\"\n\tReads npy stress-strain output and appends current results.\n\n\tLoads from ``temp_time_disp_force_{orientation}.csv`` and writes to\n\t``out_time_disp_force_{orientation}.npy``. Should only be called after all\n\torientations have run, since ``zeros==True`` if any one fails.\n\n\tFor parallel, needs to be called within a parallel.Checkout guard.\n\n\tArgs:\n\t    zeros: True if the run failed and a sheet of zeros should be written\n\t        in place of real time-force-displacement data.\n\t    orientation: Orientation nickname to keep temporary output files separate.\n\t\"\"\"\n\tfilename = os.path.join(uset.main_path, f\"out_time_disp_force_{orientation}.npy\")\n\tsheet = np.loadtxt(f\"temp_time_disp_force_{orientation}.csv\", delimiter=\",\", skiprows=1)\n\tif zeros:\n\t\tsheet = np.zeros((np.shape(sheet)))\n\tif os.path.isfile(filename):\n\t\tdat = np.load(filename)\n\t\tdat = np.dstack((dat, sheet))\n\telse:\n\t\tdat = sheet\n\tnp.save(filename, dat)\n</code></pre>"},{"location":"API/core/#matmdl.core.writer.write_error_to_file","title":"<code>write_error_to_file(error_list, orient_list, combination_function)</code>","text":"<p>Write error values separated by orientation, if applicable.</p> <p>Parameters:</p> Name Type Description Default <code>error_list</code> <code>list[float]</code> <p>List of floats indicated error values for each orientation in <code>orient_list</code>, with which this list shares an order.</p> required <code>orient_list</code> <code>list[str]</code> <p>List of strings holding orientation nicknames.</p> required Source code in <code>matmdl/core/writer.py</code> <pre><code>def write_error_to_file(\n\terror_list: list[float], orient_list: list[str], combination_function\n) -&gt; None:\n\t\"\"\"\n\tWrite error values separated by orientation, if applicable.\n\n\tArgs:\n\t    error_list: List of floats indicated error values for each orientation\n\t        in ``orient_list``, with which this list shares an order.\n\t    orient_list: List of strings holding orientation nicknames.\n\t\"\"\"\n\terror_fpath = os.path.join(uset.main_path, \"out_errors.txt\")\n\tif not os.path.isfile(error_fpath):\n\t\twith open(error_fpath, \"w+\") as f:\n\t\t\tf.write(f\"# errors for {orient_list} and combined error\\n\")\n\n\twith open(error_fpath, \"a+\") as f:\n\t\tf.write(\n\t\t\t\",\".join([f\"{err:.8e}\" for err in error_list + [combination_function(error_list)]])\n\t\t\t+ \"\\n\"\n\t\t)\n</code></pre>"},{"location":"API/core/#matmdl.core.writer.write_input_params","title":"<code>write_input_params(fname, param_names, param_values, debug=False)</code>","text":"<p>Write parameter values to file with <code>=</code> as separator.</p> <p>Used for material and orientation input files.</p> <p>Parameters:</p> Name Type Description Default <code>fname</code> <code>str</code> <p>Name of file in which to look for parameters.</p> required <code>param_names</code> <code>Union[list[str], str]</code> <p>List of strings (or single string) describing parameter names. Shares order with <code>param_values</code>.</p> required <code>param_values</code> <code>Union[list[float], float]</code> <p>List of parameter values (or single value) to be written. Shares order with <code>param_names</code>.</p> required Note <p>Finds first match in file, so put derived parameters at end of file.</p> Source code in <code>matmdl/core/writer.py</code> <pre><code>def write_input_params(\n\tfname: str,\n\tparam_names: Union[list[str], str],\n\tparam_values: Union[list[float], float],\n\tdebug=False,\n) -&gt; None:\n\t\"\"\"\n\tWrite parameter values to file with ``=`` as separator.\n\n\tUsed for material and orientation input files.\n\n\tArgs:\n\t    fname: Name of file in which to look for parameters.\n\t    param_names: List of strings (or single string) describing parameter names.\n\t        Shares order with ``param_values``.\n\t    param_values: List of parameter values (or single value) to be written.\n\t        Shares order with ``param_names``.\n\n\tNote:\n\t    Finds first match in file, so put derived parameters at end of file.\n\t\"\"\"\n\tmatch uset.format:\n\t\tcase \"huang\":\n\t\t\tseparator = \" = \"\n\t\tcase \"fepx\":\n\t\t\tseparator = \" \"\n\tif type(param_names) not in (list, tuple) and type(param_values) not in (\n\t\tlist,\n\t\ttuple,\n\t):\n\t\tparam_names = [param_names]\n\t\tparam_values = [param_values]\n\telif len(param_names) != len(param_values):\n\t\traise IndexError(\"Length of names must match length of values.\")\n\n\twith open(fname, \"r\") as f1:\n\t\tlines = f1.readlines()\n\n\tnewlines = lines.copy()\n\tfor param_name, param_value in zip(param_names, param_values):\n\t\tfor i, line in enumerate(lines):\n\t\t\tmatch = re.search(r\"\\b\" + param_name + r\"[ |=]\", line)\n\t\t\tif match:\n\t\t\t\tnewlines[i] = (\n\t\t\t\t\tline[0 : match.start()] + param_name + separator + str(param_value) + \"\\n\"\n\t\t\t\t)\n\t\t\t\tbreak  # go on to next param set\n\n\twith open(\"temp_\" + fname, \"w+\") as f2:\n\t\tf2.writelines(newlines)\n\n\tif not debug:\n\t\tos.remove(fname)\n\t\tos.rename(\"temp_\" + fname, fname)\n</code></pre>"},{"location":"API/core/#matmdl.core.writer.write_params_to_file","title":"<code>write_params_to_file(param_values, param_names)</code>","text":"<p>Appends last iteration params to file <code>out_progress.txt</code>.</p> Source code in <code>matmdl/core/writer.py</code> <pre><code>def write_params_to_file(param_values: list[float], param_names: list[str]) -&gt; None:\n\t\"\"\"Appends last iteration params to file `out_progress.txt`.\"\"\"\n\n\topt_progress_header = [\"time_ns\"] + param_names\n\tout_fpath = os.path.join(uset.main_path, \"out_progress.txt\")\n\n\tadd_header = not os.path.isfile(out_fpath)\n\twith open(out_fpath, \"a+\") as f:\n\t\tif add_header:\n\t\t\theader_padded = [opt_progress_header[0] + 12 * \" \"]\n\t\t\tfor col_name in opt_progress_header[1:]:\n\t\t\t\tnum_spaces = 8 + 6 - len(col_name)\n\t\t\t\t# 8 decimals, 6 other digits\n\t\t\t\theader_padded.append(col_name + num_spaces * \" \")\n\t\t\tf.write(\", \".join(header_padded) + \"\\n\")\n\t\tline_string = \", \".join([f\"{a:.8e}\" for a in param_values]) + \"\\n\"\n\t\tstate.update_write()\n\t\tline_string = str(state.last_updated) + \", \" + line_string\n\t\tf.write(line_string)\n</code></pre>"},{"location":"API/engines/","title":"API: Engines","text":""},{"location":"API/engines/#matmdl.engines","title":"<code>matmdl.engines</code>","text":"<p>Choose the computational engine for running, checking, and extracting finite element job information. Currently only Abaqus exists.</p>"},{"location":"API/engines/#matmdl.engines.abaqus","title":"<code>abaqus</code>","text":"<p>This module contains helper functions for dealing with Abaqus but has no Abaqus-specific imports.</p>"},{"location":"API/engines/#matmdl.engines.abaqus.extract","title":"<code>extract(outname)</code>","text":"<p>Call :py:mod:<code>matmdl.engines.abaqus_extract</code> from new shell to extract force-displacement data.</p> Source code in <code>matmdl/engines/abaqus.py</code> <pre><code>def extract(outname: str):\n\t\"\"\"\n\tCall :py:mod:`matmdl.engines.abaqus_extract` from new shell to extract force-displacement data.\n\t\"\"\"\n\tsrc_dir = os.path.dirname(os.path.abspath(__file__))\n\textractions_script_path = os.path.join(src_dir, \"abaqus_extract.py\")\n\trun_string = f\"abaqus python {extractions_script_path}\"\n\tsubprocess.run(run_string, shell=True)\n\tos.rename(\"temp_time_disp_force.csv\", f\"temp_time_disp_force_{outname}.csv\")\n</code></pre>"},{"location":"API/engines/#matmdl.engines.abaqus.has_completed","title":"<code>has_completed()</code>","text":"<p>Return <code>True</code> if Abaqus has finished sucessfully.</p> Source code in <code>matmdl/engines/abaqus.py</code> <pre><code>def has_completed():\n\t\"\"\"\n\tReturn ``True`` if Abaqus has finished sucessfully.\n\t\"\"\"\n\tstafile = uset.jobname + \".sta\"\n\tif os.path.isfile(stafile):\n\t\tlast_line = str(subprocess.check_output([\"tail\", \"-1\", stafile]))\n\telse:\n\t\tlast_line = \"\"\n\treturn \"SUCCESSFULLY\" in last_line\n</code></pre>"},{"location":"API/engines/#matmdl.engines.abaqus.load_subroutine","title":"<code>load_subroutine()</code>","text":"<p>Compile the user subroutine uset.umat as a shared library in the directory.</p> Source code in <code>matmdl/engines/abaqus.py</code> <pre><code>def load_subroutine():\n\t\"\"\"\n\tCompile the user subroutine uset.umat as a shared library in the directory.\n\t\"\"\"\n\ttry:\n\t\tos.remove(\"libstandardU.so\")\n\texcept FileNotFoundError:\n\t\tpass\n\ttry:\n\t\tos.remove(f'{uset.umat[:uset.umat.find(\".\")]}-std.o')\n\texcept FileNotFoundError:\n\t\tpass\n\n\tsubprocess.run(\"abaqus make library=\" + uset.umat, shell=True)\n</code></pre>"},{"location":"API/engines/#matmdl.engines.abaqus.pre_run","title":"<code>pre_run(next_params, orient, in_opt)</code>","text":"<p>Things to do before each run.</p> Source code in <code>matmdl/engines/abaqus.py</code> <pre><code>def pre_run(next_params, orient, in_opt):\n\t\"\"\"Things to do before each run.\"\"\"\n\tdo_orientation_inputs(next_params, orient, in_opt)\n</code></pre>"},{"location":"API/engines/#matmdl.engines.abaqus.prepare","title":"<code>prepare()</code>","text":"<p>Main call to prepare for all runs.</p> Source code in <code>matmdl/engines/abaqus.py</code> <pre><code>def prepare():\n\t\"\"\"\n\tMain call to prepare for all runs.\n\t\"\"\"\n\tload_subroutine()\n</code></pre>"},{"location":"API/engines/#matmdl.engines.abaqus.run","title":"<code>run()</code>","text":"<p>Run the Abaqus job!</p> Source code in <code>matmdl/engines/abaqus.py</code> <pre><code>def run():\n\t\"\"\"Run the Abaqus job!\"\"\"\n\tsubprocess.run(\n\t\t\"abaqus job=\"\n\t\t+ uset.jobname\n\t\t+ \" user=\"\n\t\t+ uset.umat[: uset.umat.find(\".\")]\n\t\t+ \"-std.o\"\n\t\t+ \" cpus=\"\n\t\t+ str(uset.cpus)\n\t\t+ \" double int ask_delete=OFF\",\n\t\tshell=True,\n\t)\n</code></pre>"},{"location":"API/engines/#matmdl.engines.abaqus.write_strain","title":"<code>write_strain(strain, jobname)</code>","text":"<p>Modify boundary conditions in main Abaqus input file to match max strain.</p> <p>Parameters:</p> Name Type Description Default <code>strain</code> <code>float</code> <p>signed float used to specify axial displacement</p> required <code>jobname</code> <code>str</code> <p>Filename for main Abaqus job -- unique to orientation if applicable.</p> required Note <p>Relies on finding <code>RP-TOP</code> under <code>*Boundary</code> keyword in main input file.</p> Source code in <code>matmdl/engines/abaqus.py</code> <pre><code>def write_strain(strain: float, jobname: str):\n\t\"\"\"\n\tModify boundary conditions in main Abaqus input file to match max strain.\n\n\tArgs:\n\t    strain: signed float used to specify axial displacement\n\t    jobname: Filename for main Abaqus job -- unique to\n\t        orientation if applicable.\n\n\tNote:\n\t    Relies on finding ``RP-TOP`` under ``*Boundary`` keyword in main\n\t    input file.\n\t\"\"\"\n\t# input file:\n\tmax_bound = round(strain * uset.length, 4)  # round to 4 digits\n\n\tif jobname[-4:] == \".inp\":\n\t\tlocal_jobname = jobname\n\telse:\n\t\tlocal_jobname = jobname + \".inp\"\n\n\twith open(local_jobname, \"r\") as f:\n\t\tlines = f.readlines()\n\n\t# find last number after RP-TOP under *Boundary\n\tbound_line_ind = [i for i, line in enumerate(lines) if line.lower().startswith(\"*boundary\")][0]\n\tbound_line_ind += [\n\t\ti\n\t\tfor i, line in enumerate(lines[bound_line_ind:])\n\t\tif line.strip().lower().startswith(\"rp-top\")\n\t][0]\n\tbound_line = [number.strip() for number in lines[bound_line_ind].strip().split(\",\")]\n\n\tnew_bound_line = bound_line[:-1] + [max_bound]\n\tnew_bound_line_str = str(new_bound_line[0])\n\n\tfor i in range(1, len(new_bound_line)):\n\t\tnew_bound_line_str = new_bound_line_str + \", \"\n\t\tnew_bound_line_str = new_bound_line_str + str(new_bound_line[i])\n\tnew_bound_line_str = new_bound_line_str + \"\\n\"\n\n\t# write out\n\twith open(local_jobname, \"w\") as f:\n\t\tf.writelines(lines[:bound_line_ind])\n\t\tf.writelines(new_bound_line_str)\n\t\tf.writelines(lines[bound_line_ind + 1 :])\n</code></pre>"},{"location":"API/engines/#matmdl.engines.abaqus_extract","title":"<code>abaqus_extract</code>","text":"<p>This runnable module requires Abaqus libraries and must be run from Abaqus python. It extracts force-displacement data from pre-defined reference points for use in comparison of model input parameters to reference data.</p>"},{"location":"API/engines/#matmdl.engines.abaqus_extract.GetForceDisplacement","title":"<code>GetForceDisplacement</code>","text":"<p>               Bases: <code>object</code></p> <p>Open ODB file and store force-displacement data from a reference point.</p> <p>Parameters:</p> Name Type Description Default <code>ResultFile</code> <code>str</code> <p>name of odb file without the '.odb'</p> required <p>Attributes:</p> Name Type Description <code>Time</code> <p>simulation time (0-&gt;1)</p> <code>TopU2</code> <p>displacement of reference point</p> <code>TopRF2</code> <p>reaction force of reference point</p> Note <p>Depends on the Abaqus names of loading step, part instance, and reference point. Requires Abaqus-specific libraries, must be called from Abaqus python.</p> Source code in <code>matmdl/engines/abaqus_extract.py</code> <pre><code>class GetForceDisplacement(object):\n\t\"\"\"\n\tOpen ODB file and store force-displacement data from a reference point.\n\n\tArgs:\n\t    ResultFile (str): name of odb file without the '.odb'\n\n\tAttributes:\n\t    Time: simulation time (0-&gt;1)\n\t    TopU2: displacement of reference point\n\t    TopRF2: reaction force of reference point\n\n\tNote:\n\t    Depends on the Abaqus names of loading step, part instance, and reference point.\n\t    Requires Abaqus-specific libraries, must be called from Abaqus python.\n\t\"\"\"\n\n\tdef __init__(self, ResultFile):\n\t\tCurrentPath = os.getcwd()\n\t\tself.ResultFilePath = os.path.join(CurrentPath, ResultFile + \".odb\")\n\n\t\tself.Time = []\n\t\tself.TopU2 = []\n\t\tself.TopRF2 = []\n\n\t\t# Names that need to match the Abaqus simulation:\n\t\tstep = \"Loading\"\n\t\tinstance = \"PART-1-1\"\n\t\tTopRPset = \"RP-TOP\"\n\n\t\todb = openOdb(path=self.ResultFilePath, readOnly=True)\n\t\tsteps = odb.steps[step]\n\t\tframes = odb.steps[step].frames\n\t\tnumFrames = len(frames)\n\n\t\t# if node set is in Part:\n\t\tTopRP = odb.rootAssembly.instances[instance].nodeSets[TopRPset]\n\t\t# if the node set is in Assembly:\n\t\t# TopNodes = odb.rootAssembly.nodeSets[NodeSetTop]\n\n\t\tfor x in range(numFrames):\n\t\t\tFrame = frames[x]\n\t\t\tself.Time.append(Frame.frameValue)\n\t\t\t# Top RP results:\n\t\t\tDisplacement = Frame.fieldOutputs[\"U\"]\n\t\t\tReactionForce = Frame.fieldOutputs[\"RF\"]\n\t\t\tTopU = Displacement.getSubset(region=TopRP).values\n\t\t\tTopRf = ReactionForce.getSubset(region=TopRP).values\n\t\t\t# add to lists:\n\t\t\tself.TopU2 = self.TopU2 + map(lambda x: x.data[1], TopU)\n\t\t\tself.TopRF2 = self.TopRF2 + map(lambda x: x.data[1], TopRf)\n\n\t\todb.close()\n</code></pre>"},{"location":"API/engines/#matmdl.engines.abaqus_extract.write2file","title":"<code>write2file()</code>","text":"<p>Using GetForceDisplacement object, read odb file and write time-displacement-force to csv file.</p> Source code in <code>matmdl/engines/abaqus_extract.py</code> <pre><code>def write2file():\n\t\"\"\"\n\tUsing GetForceDisplacement object, read odb file and write time-displacement-force to csv file.\n\t\"\"\"\n\tjob = [f for f in os.listdir(os.getcwd()) if f.endswith(\".odb\")][0][:-4]\n\tResult_Fd = GetForceDisplacement(job)\n\twith open(\"temp_time_disp_force.csv\", \"w\") as f:\n\t\tf.write(\"Time, U2, RF2\\n\")\n\t\tfor i in range(len(Result_Fd.Time)):\n\t\t\tf.write(\"%.5f,\" % Result_Fd.Time[i])\n\t\t\tf.write(\"%.5f,\" % Result_Fd.TopU2[i])\n\t\t\tf.write(\"%.5f\\n\" % Result_Fd.TopRF2[i])\n</code></pre>"},{"location":"API/engines/#matmdl.engines.fepx","title":"<code>fepx</code>","text":"<p>Functions for dealing with FEPX.</p>"},{"location":"API/engines/#matmdl.engines.fepx.extract","title":"<code>extract(outname)</code>","text":"<p>Get time, displacement, force data from simdir.</p> Note <p>This does extra work to match the Abaqus format... worth a change?</p> Source code in <code>matmdl/engines/fepx.py</code> <pre><code>def extract(outname: str):\n\t\"\"\"\n\tGet time, displacement, force data from simdir.\n\n\tNote:\n\t    This does extra work to match the Abaqus format... worth a change?\n\t\"\"\"\n\t# get loading direction from config\n\tconfig = _parse_config()\n\tloading_dir = config[\"loading_direction\"][0]\n\tstrain = float(config[\"target_strain\"][0])\n\n\t# extract output data:\n\tdata = np.loadtxt(\n\t\tos.path.join(\"simulation.sim\", \"results\", \"forces\", loading_dir + \"1\"),\n\t\tskiprows=2,\n\t)\n\tpossible_dirs = [\"x\", \"y\", \"z\"]\n\tforce = data[:, 2 + possible_dirs.index(loading_dir)]\n\ttime = data[:, -1]\n\ttime = time / max(time)\n\n\t# use uset dimensions if available, fallback to area and assumption of a cube\n\tif uset.length:\n\t\tlength_og = uset.length\n\telse:\n\t\tarea = data[0, 5]\n\t\tlength_og = area ** (0.5)\n\n\tdisplacement = time * strain * length_og\n\n\ttime_disp_force = np.stack(\n\t\t(time.transpose(), displacement.transpose(), force.transpose()), axis=1\n\t)\n\theader = \"time, displacement, force\"\n\ttry:\n\t\tos.remove(f\"temp_time_disp_force_{outname}.csv\")\n\texcept FileNotFoundError:\n\t\tpass  # fine for first run\n\tnp.savetxt(\n\t\tf\"temp_time_disp_force_{outname}.csv\",\n\t\ttime_disp_force,\n\t\theader=header,\n\t\tdelimiter=\",\",\n\t)\n</code></pre>"},{"location":"API/engines/#matmdl.engines.fepx.has_completed","title":"<code>has_completed()</code>","text":"<p>Return <code>True</code> if Abaqus has finished sucessfully.</p> Source code in <code>matmdl/engines/fepx.py</code> <pre><code>def has_completed():\n\t\"\"\"\n\tReturn ``True`` if Abaqus has finished sucessfully.\n\t\"\"\"\n\trunlog = \"temp_run_log\"\n\tif os.path.isfile(runlog):\n\t\ttry:\n\t\t\tcheck_line = subprocess.run(\n\t\t\t\tf\"tail -n2 {runlog} | head -n 1\",\n\t\t\t\tcapture_output=True,\n\t\t\t\tcheck=True,\n\t\t\t\tshell=True,\n\t\t\t).stdout.decode(\"utf-8\")\n\t\texcept subprocess.CalledProcessError:\n\t\t\traise RuntimeError(\"FEPX incomplete run\")\n\telse:\n\t\tcheck_line = \"\"\n\treturn \"Final step terminated. Simulation completed successfully.\" in check_line\n</code></pre>"},{"location":"API/engines/#matmdl.engines.fepx.pre_run","title":"<code>pre_run(next_params, orient, in_opt)</code>","text":"<p>Things to do before each run.</p> Source code in <code>matmdl/engines/fepx.py</code> <pre><code>def pre_run(next_params, orient, in_opt):\n\t\"\"\"Things to do before each run.\"\"\"\n\tpass\n</code></pre>"},{"location":"API/engines/#matmdl.engines.fepx.prepare","title":"<code>prepare()</code>","text":"<p>Main call to prepare for all runs. Nothing to do for FEPX?</p> Source code in <code>matmdl/engines/fepx.py</code> <pre><code>def prepare():\n\t\"\"\"\n\tMain call to prepare for all runs. Nothing to do for FEPX?\n\t\"\"\"\n\tpass\n</code></pre>"},{"location":"API/engines/#matmdl.engines.fepx.run","title":"<code>run()</code>","text":"<p>Starts FEPX, assuming <code>fepx</code> and <code>mpirun</code> are on system's path. Otherwise, give path to <code>fepx</code> as executable_path in input file.</p> Source code in <code>matmdl/engines/fepx.py</code> <pre><code>def run():\n\t\"\"\"\n\tStarts FEPX, assuming `fepx` and `mpirun` are on system's path.\n\tOtherwise, give path to `fepx` as executable_path in input file.\n\t\"\"\"\n\trunlog = \"temp_run_log\"\n\tif uset.executable_path:\n\t\tfepx = uset.executable_path\n\telse:\n\t\tfepx = \"fepx\"\n\tsubprocess.run(f\"mpirun -np ${{SLURM_NTASKS}} {fepx} | tee {runlog}\", shell=True)\n</code></pre>"},{"location":"API/engines/#matmdl.engines.fepx.write_strain","title":"<code>write_strain(strain, jobname=None, debug=False)</code>","text":"<p>Modify boundary conditions in main Abaqus input file to match max strain.</p> <p>Parameters:</p> Name Type Description Default <code>strain</code> <code>float</code> <p>signed float used to specify axial displacement</p> required <code>jobname</code> <code>str</code> <p>ignored, only included to match call signature in abaqus</p> <code>None</code> Note <p>Relies on finding <code>target_strain</code> in simulation.cfg</p> Source code in <code>matmdl/engines/fepx.py</code> <pre><code>def write_strain(strain: float, jobname: str = None, debug=False):\n\t\"\"\"\n\tModify boundary conditions in main Abaqus input file to match max strain.\n\n\tArgs:\n\t    strain: signed float used to specify axial displacement\n\t    jobname: ignored, only included to match call signature in abaqus\n\n\tNote:\n\t    Relies on finding `target_strain` in simulation.cfg\n\t\"\"\"\n\tfname = \"simulation.cfg\"\n\tkey = \"target_strain\"\n\tmax_bound = round(strain, 4)  # round to 4 digits\n\n\tnew_lines = []\n\twith open(fname, \"r+\") as f:\n\t\tfor line in f.readlines():\n\t\t\tif line.strip().startswith(key):\n\t\t\t\told_items = line.strip().split(\" \")\n\t\t\t\t# ^ expecting: target_strain &lt;strainValue&gt; &lt;outputFrequency&gt; print_data\n\t\t\t\tspace = \" \"  # to avoid another set of quotes within the follow f-string\n\t\t\t\tnew_line = (\n\t\t\t\t\tline[0 : line.find(key)]\n\t\t\t\t\t+ f\"{old_items[0]} {strain} {space.join(old_items[2:])}\\n\"\n\t\t\t\t)\n\t\t\t\tnew_lines.append(new_line)\n\t\t\telse:\n\t\t\t\tnew_lines.append(line)\n\n\twith open(f\"temp_{fname}\", \"w+\") as f:\n\t\tf.writelines(new_lines)\n\n\tif not debug:\n\t\tos.remove(fname)\n\t\tos.rename(\"temp_\" + fname, fname)\n</code></pre>"},{"location":"API/models/","title":"API: Models","text":""},{"location":"API/models/#matmdl.models","title":"<code>matmdl.models</code>","text":""},{"location":"API/models/#matmdl.models.mk_orthoModel","title":"<code>mk_orthoModel</code>","text":"<p>Creates input files for polycrystal plasticity models, where each grain and the whole RVE are orthorhombic.</p>"},{"location":"API/models/#matmdl.models.mk_orthoModel.Files","title":"<code>Files</code>","text":"<p>               Bases: <code>object</code></p> <p>A place for filenames and the like. All attributes are filenames (strings).</p> <p>Attributes:</p> Name Type Description <code>main</code> <p>Main job file for Abaqus job with <code>include</code> statements for other files.</p> <code>nodes</code> <p>Node numbers and [x,y,z] locations.</p> <code>nodeset</code> <p>Node sets for faces and reference nodes.</p> <code>elements</code> <p>Defines each C3D8 element in terms of constituent nodes.</p> <code>elset</code> <p>Defines the grains from all elements.</p> <code>sections</code> <p>Assigns material properties (esp. orientation) to each grain, as defined by the element sets.</p> <code>orients</code> <p>Defines crystallographic orientations for each grain.</p> <code>mesh_extra</code> <p>Defines reference nodes and midpoint nodes for more convenient analysis.</p> <code>material</code> <p>Hardening parameters for a single material.</p> <code>slip</code> <p>Formatted crystal plasticity inputs for each grain. Takes orientation and hardening properties from other files.</p> Source code in <code>matmdl/models/mk_orthoModel.py</code> <pre><code>class Files(object):\n\t\"\"\"\n\tA place for filenames and the like. All attributes are filenames (strings).\n\n\tAttributes:\n\t    main: Main job file for Abaqus job with ``include`` statements\n\t        for other files.\n\t    nodes: Node numbers and [x,y,z] locations.\n\t    nodeset: Node sets for faces and reference nodes.\n\t    elements: Defines each C3D8 element in terms of constituent nodes.\n\t    elset: Defines the grains from all elements.\n\t    sections: Assigns material properties (esp. orientation) to each\n\t        grain, as defined by the element sets.\n\t    orients: Defines crystallographic orientations for each grain.\n\t    mesh_extra: Defines reference nodes and midpoint nodes for\n\t        more convenient analysis.\n\t    material: Hardening parameters for a single material.\n\t    slip: Formatted crystal plasticity inputs for each grain. Takes\n\t        orientation and hardening properties from other files.\n\t\"\"\"\n\n\tdef __init__(self):\n\t\tself.main = \"job.inp\"\n\t\tself.nodes = \"Mesh_nodes.inp\"\n\t\tself.nodeset = \"Mesh_nset.inp\"\n\t\tself.elements = \"Mesh_elements.inp\"\n\t\tself.elset = \"Mesh_elset.inp\"\n\t\tself.sections = \"Mat_sects.inp\"\n\t\tself.orients = \"Mat_orient.inp\"\n\t\tself.mesh_extra = \"Mesh_param.inp\"\n\t\tself.material = \"Mat_BW.inp\"\n\t\tself.slip = \"Mat_props.inp\"\n</code></pre>"},{"location":"API/models/#matmdl.models.mk_orthoModel.dim","title":"<code>dim</code>","text":"<p>               Bases: <code>object</code></p> <p>A place to store details of model dimensions.</p> <p>Attributes:</p> Name Type Description <code>edge_i,</code> <code>int</code> <p>Length of model in each direction (i=x,y,z; note that loading is along y)</p> <code>grain_i</code> <code>int</code> <p>Length of grain in in each direction (i=x,y,z; note that loading is along y)</p> <code>eng_strain</code> <code>float</code> <p>Engineering strain to be applied as uniaxial tension</p> <code>disp</code> <code>float</code> <p>Displacement (calculated from strain) to be applied in y-direction</p> <code>num_nodes</code> <code>int</code> <p>Total number of nodes</p> <code>num_elements</code> <code>int</code> <p>Total number of elements in model</p> <code>num_grains</code> <code>int</code> <p>Total number of grains in model</p> <code>ref_node</code> <code>int</code> <p>Beginning number of nodes added as reference points</p> Note <p>Loading is applied in the <code>y</code> direction.</p> Source code in <code>matmdl/models/mk_orthoModel.py</code> <pre><code>class dim(object):\n\t\"\"\"\n\tA place to store details of model dimensions.\n\n\tAttributes:\n\t    edge_i, (int): Length of model in each direction (i=x,y,z; note that loading is along y)\n\t    grain_i (int): Length of grain in in each direction (i=x,y,z; note that loading is along y)\n\t    eng_strain (float): Engineering strain to be applied as uniaxial tension\n\t    disp (float): Displacement (calculated from strain) to be applied in y-direction\n\t    num_nodes (int): Total number of nodes\n\t    num_elements (int): Total number of elements in model\n\t    num_grains (int): Total number of grains in model\n\t    ref_node (int): Beginning number of nodes added as reference points\n\n\tNote:\n\t    Loading is applied in the `y` direction.\n\t\"\"\"\n</code></pre>"},{"location":"API/models/#matmdl.models.mk_orthoModel.mesh","title":"<code>mesh</code>","text":"<p>               Bases: <code>object</code></p> <p>For information about nodes and elements.</p> <p>Attributes:</p> Name Type Description <code>nodes</code> <code>tuple</code> <p>Array of node locations (x,y,z)</p> <code>elements</code> <code>list</code> <p>Array of elements (number of node 1, 2, ..., 8) note that node numbers used in <code>elements</code> are 1-indexed right, left, top, bottom, front, back (list): node sets for face towards +x, -x, +y, -y, +z, -z</p> <code>nodes0,1,2</code> <code>ndarray</code> <p>Column slices of <code>nodes</code> for faster searching</p> <code>rel_nodes</code> <code>ndarray</code> <p>Array of 8 nearest node positions of current marker</p> <code>element_nodes</code> <code>ndarray</code> <p>Element numbers nearest to current marker</p> Source code in <code>matmdl/models/mk_orthoModel.py</code> <pre><code>class mesh(object):\n\t\"\"\"\n\tFor information about nodes and elements.\n\n\tAttributes:\n\t    nodes (tuple): Array of node locations (x,y,z)\n\t    elements (list): Array of elements (number of node 1, 2, ..., 8)\n\t        note that node numbers used in `elements` are 1-indexed\n\t        right, left, top, bottom, front, back (list):\n\t        node sets for face towards +x, -x, +y, -y, +z, -z\n\t    nodes0,1,2 (ndarray): Column slices of `nodes` for faster searching\n\t    rel_nodes (ndarray): Array of 8 nearest node positions of current marker\n\t    element_nodes (ndarray): Element numbers nearest to current marker\n\t\"\"\"\n</code></pre>"},{"location":"API/models/#matmdl.models.mk_orthoModel.orient","title":"<code>orient</code>","text":"<p>               Bases: <code>object</code></p> <p>For orientation information.</p> <p>Attributes:</p> Name Type Description <code>max_index</code> <code>int</code> <p>Maximum Miller index for grain orientations</p> <code>x</code> <code>tuple</code> <p>[x,y,z] directions for local direction</p> <code>y</code> <code>tuple</code> <p>[x,y,z] directions for lab direction</p> Source code in <code>matmdl/models/mk_orthoModel.py</code> <pre><code>class orient(object):\n\t\"\"\"\n\tFor orientation information.\n\n\tAttributes:\n\t    max_index (int): Maximum Miller index for grain orientations\n\t    x (tuple): [x,y,z] directions for local direction\n\t    y (tuple): [x,y,z] directions for lab direction\n\t\"\"\"\n\n\tdef __init__(self):\n\t\tself.max_index = 7\n\n\tdef assign(self, x, y):\n\t\tself.x = x\n\t\tself.y = y\n</code></pre>"},{"location":"API/models/#matmdl.models.mk_orthoModel.ask_dimensions","title":"<code>ask_dimensions()</code>","text":"<p>Get user input for model dimensions.</p> <p>Args:</p> <p>Returns:</p> Name Type Description <code>obj</code> <code>dim</code> <p>Dimensions of the model.</p> Source code in <code>matmdl/models/mk_orthoModel.py</code> <pre><code>def ask_dimensions():\n\t\"\"\"\n\tGet user input for model dimensions.\n\n\tArgs:\n\n\tReturns:\n\t    obj (dim): Dimensions of the model.\n\n\t\"\"\"\n\tdim.edge_x = int(input(\"Enter edge length of cubic model (integer): \"))\n\tdim.edge_y = input(\"If cubic model, hit enter now. Else, enter second edge length (y): \")\n\tif dim.edge_y == \"\":\n\t\tdim.edge_y = dim.edge_x\n\t\tdim.edge_z = dim.edge_x\n\telse:\n\t\tdim.edge_y = int(dim.edge_y)\n\t\tdim.edge_z = int(input(\"Enter third edge length (z): \"))\n\n\tdim.grain_x = int(input(\"Enter the size of the grains in elements (x): \"))\n\tdim.grain_y = input(\"If cubic model, hit enter now. Else, enter second grain dimension (y): \")\n\tif dim.grain_y == \"\":\n\t\tdim.grain_y = dim.grain_x\n\t\tdim.grain_z = dim.grain_x\n\telse:\n\t\tdim.grain_y = int(dim.grain_y)\n\t\tdim.grain_z = int(input(\"Enter third grain dimension (z): \"))\n\tdim.eng_strain = float(input(\"Input Engineering strain [default = 0.2]:  \") or \"0.2\")\n\tdim.disp = dim.edge_y * dim.eng_strain\n\n\treturn dim\n</code></pre>"},{"location":"API/models/#matmdl.models.mk_orthoModel.mk_orthoModel","title":"<code>mk_orthoModel(dim)</code>","text":"<p>Make orthorhombic CPFEM model with orthorhombic grains.</p> <p>Inputs crystal plasticity parameters, assigns random orientations to all grains. Asks for user input for all arguments given here. Input includes option for cubic models.</p> <p>Parameters:</p> Name Type Description Default <code>dim</code> <code>dim</code> <p>Structure containing the dimensions of both the RVE and the constituent grains as well as the maximum engineering strain for uniaxial tension (<code>eng_strain</code>). This object is generated from interactive user input by <code>ask_dimensions</code>.</p> required <p>Returns:</p> Notes <p>Requires (and checks) that `(edge_i % grain_i) == 0`` for each dimension.</p> Source code in <code>matmdl/models/mk_orthoModel.py</code> <pre><code>def mk_orthoModel(dim):\n\t\"\"\"\n\tMake orthorhombic CPFEM model with orthorhombic grains.\n\n\tInputs crystal plasticity parameters, assigns random orientations to all grains.\n\tAsks for user input for all arguments given here. Input includes option for\n\tcubic models.\n\n\tArgs:\n\t    dim (dim): Structure containing the dimensions\n\t        of both the RVE and the constituent grains as well as the maximum\n\t        engineering strain for uniaxial tension (`eng_strain`).\n\t        This object is generated from interactive user input by\n\t        [`ask_dimensions`][matmdl.models.mk_orthoModel.ask_dimensions].\n\n\tReturns:\n\n\tNotes:\n\t    Requires (and checks) that `(edge_i % grain_i) == 0``\n\t    for each dimension.\n\t\"\"\"\n\n\t# instantiate filenames\n\tfiles = Files()\n\t# --------------------------------------------------------------------------------------------------\n\t# check if dimensions are appropriate\n\tassert dim.edge_x % dim.grain_x == 0, \"Dimension mismatch in x-direction\"\n\tassert dim.edge_y % dim.grain_y == 0, \"Dimension mismatch in y-direction\"\n\tassert dim.edge_z % dim.grain_z == 0, \"Dimension mismatch in z-direction\"\n\n\t# --------------------------------------------------------------------------------------------------\n\t## Mesh\n\t# --------------------------------------------------------------------------------------------------\n\t# functions\n\tdef separate(row):\n\t\tstring_list = []\n\t\tfor i in range(len(row)):\n\t\t\tstring_list.append(str(row[i]))\n\t\treturn string_list\n\n\t# --------------------------------------------------------------------------------------------------\n\t# nodes\n\tdim.num_nodes = int((dim.edge_x + 1) * (dim.edge_y + 1) * (dim.edge_z + 1))\n\tmesh.nodes = np.empty((dim.num_nodes, 3), dtype=float)\n\tct = 0\n\tfor z in range(0, dim.edge_z + 1):\n\t\tfor y in range(0, dim.edge_y + 1):\n\t\t\tfor x in range(0, dim.edge_x + 1):\n\t\t\t\tmesh.nodes[ct, :] = [x, y, z]\n\t\t\t\tct += 1\n\t# --------------------------------------------------------------------------------------------------\n\t# elements\n\tmesh.nodes0 = np.asarray(mesh.nodes[:, 0], dtype=int)\n\tmesh.nodes1 = np.asarray(mesh.nodes[:, 1], dtype=int)\n\tmesh.nodes2 = np.asarray(mesh.nodes[:, 2], dtype=int)\n\tdim.num_elements = int(dim.edge_x * dim.edge_y * dim.edge_z)\n\tmesh.elements = np.zeros((dim.num_elements, 8), dtype=int)\n\tct_elements = 0\n\tfor z in range(0, dim.edge_z):\n\t\tfor y in range(0, dim.edge_y):\n\t\t\tfor x in range(0, dim.edge_x):\n\t\t\t\tmarker = 0.5 * np.array([1, 1, 1]) + np.array([x, y, z])\n\t\t\t\tmesh.rel_nodes = marker + 0.5 * np.array(\n\t\t\t\t\t[\n\t\t\t\t\t\t[-1, -1, -1],\n\t\t\t\t\t\t[+1, -1, -1],\n\t\t\t\t\t\t[+1, +1, -1],\n\t\t\t\t\t\t[-1, +1, -1],\n\t\t\t\t\t\t[-1, -1, +1],\n\t\t\t\t\t\t[+1, -1, +1],\n\t\t\t\t\t\t[+1, +1, +1],\n\t\t\t\t\t\t[-1, +1, +1],\n\t\t\t\t\t]\n\t\t\t\t)\n\t\t\t\tmesh.rel_nodes = np.asarray(mesh.rel_nodes, dtype=int)\n\t\t\t\tmesh.element_nodes = []\n\t\t\t\tfor node in mesh.rel_nodes:\n\t\t\t\t\tmesh.element_nodes.append(\n\t\t\t\t\t\tnp.where(\n\t\t\t\t\t\t\t(mesh.nodes0 == node[0])\n\t\t\t\t\t\t\t&amp; (mesh.nodes1 == node[1])\n\t\t\t\t\t\t\t&amp; (mesh.nodes2 == node[2])\n\t\t\t\t\t\t)[0][0]\n\t\t\t\t\t\t+ 1\n\t\t\t\t\t)\n\t\t\t\tmesh.elements[ct_elements, :] = np.asarray(mesh.element_nodes)\n\t\t\t\tct_elements += 1\n\t# --------------------------------------------------------------------------------------------------\n\t# create grains\n\t# --------------------------------------------------------------------------------------------------\n\tmesh.grain_seeds = []\n\tfor z in range(0, dim.edge_z - dim.grain_z + 1, dim.grain_z):\n\t\tfor y in range(0, dim.edge_y - dim.grain_y + 1, dim.grain_y):\n\t\t\tfor x in range(0, dim.edge_x - dim.grain_x + 1, dim.grain_x):\n\t\t\t\tmesh.grain_seeds.append(z * dim.edge_x * dim.edge_y + y * dim.edge_x + x + 1)\n\t\t\t\t# TODO check above line for generality\n\tdim.num_grains = len(mesh.grain_seeds)\n\tmesh.grain_els = {}\n\tfor n, grain_seed in enumerate(mesh.grain_seeds):\n\t\tmesh.grain_list = []\n\t\tfor z in range(0, dim.grain_z):  # 0 to G-1, incl.\n\t\t\t# WARNING:  below only good for case of G=2, right?\n\t\t\tfor y in range(0, dim.grain_y):\n\t\t\t\tfor x in range(0, dim.grain_x):\n\t\t\t\t\tmesh.grain_list += [\n\t\t\t\t\t\tgrain_seed + z * dim.edge_x * dim.edge_y + y * dim.edge_x + x\n\t\t\t\t\t]\n\t\tmesh.grain_els[n] = mesh.grain_list\n\t# --------------------------------------------------------------------------------------------------\n\t# material sections\n\twith open(files.sections, \"a\") as f:\n\t\tfor n in range(len(mesh.grain_seeds)):\n\t\t\tf.write(\n\t\t\t\t\"*Solid Section, elset=Grain\"\n\t\t\t\t+ str(n + 1)\n\t\t\t\t+ \"_set, material=Grain\"\n\t\t\t\t+ str(n + 1)\n\t\t\t\t+ \"_Phase1_mat\\n\"\n\t\t\t)\n\t\tf.write(\"**\")\n\t# --------------------------------------------------------------------------------------------------\n\t# element sets\n\twith open(files.elset, \"w+\") as f:\n\t\tf.write(\n\t\t\t\"** Defines element sets\\n\"\n\t\t\t\"*Elset, elset=cube, generate\\n\"\n\t\t\t\"1, \" + str(dim.num_elements) + \", 1\\n\"\n\t\t)\n\t\tfor i in range(dim.num_grains):\n\t\t\tgrain_list = mesh.grain_els[i]\n\t\t\tif i != 0:\n\t\t\t\tf.write(\"\\n\")\n\t\t\tf.write(\"*Elset, elset=Grain\" + str(i + 1) + \"_set\\n\")\n\t\t\tfor n in range(len(grain_list)):  # TODO make this a function, is used later\n\t\t\t\tif n == len(grain_list) - 1:\n\t\t\t\t\tf.write(str(grain_list[n]))\n\t\t\t\telif (n + 1) % 16 == 0 and n != 0:\n\t\t\t\t\tf.write(str(grain_list[n]) + \",\\n\")\n\t\t\t\telse:\n\t\t\t\t\tf.write(str(grain_list[n]) + \", \")\n\t\t\tif i == dim.num_grains:\n\t\t\t\tf.write(\"**\")\n\t# --------------------------------------------------------------------------------------------------\n\t# write out nodes, elements\n\twith open(files.nodes, \"w+\") as f:  # TODO lowercase filenames\n\t\tf.write(\"*NODE, NSET=ALLNODES\\n\")\n\t\tfor i in range(dim.num_nodes - 1):\n\t\t\tf.write(str(i + 1) + \", \" + \", \".join(separate(mesh.nodes[i, :])) + \"\\n\")\n\t\tf.write(str(dim.num_nodes) + \", \" + \", \".join(separate(mesh.nodes[-1, :])))\n\n\twith open(files.elements, \"w+\") as f:\n\t\tf.write(\"*ELEMENT, TYPE=C3D8, ELSET=ALLELEMENTS\\n\")\n\t\tfor i in range(dim.num_elements - 1):\n\t\t\tf.write(str(i + 1) + \", \" + \", \".join(separate(mesh.elements[i, :])) + \"\\n\")\n\t\tf.write(str(dim.num_elements) + \", \" + \", \".join(separate(mesh.elements[-1, :])))\n\t# --------------------------------------------------------------------------------------------------\n\t# nodesets\n\t# --------------------------------------------------------------------------------------------------\n\t# mesh.right = mesh.left = mesh.top = mesh.bottom = mesh.front = mesh.back = []\n\tmesh.nset_list = [[] for _ in range(6)]\n\tmesh.nset_names = [\"RIGHT\", \"LEFT\", \"TOP\", \"BOTTOM\", \"FRONT\", \"BACK\"]\n\tfor i, node in enumerate(mesh.nodes):\n\t\tif node[0] == dim.edge_x:\n\t\t\tmesh.nset_list[0].append(int(i + 1))\n\t\telif node[0] == 0:\n\t\t\tmesh.nset_list[1].append(int(i + 1))\n\t\tif node[1] == dim.edge_y:\n\t\t\tmesh.nset_list[2].append(int(i + 1))\n\t\telif node[1] == 0:\n\t\t\tmesh.nset_list[3].append(int(i + 1))\n\t\tif node[2] == dim.edge_z:\n\t\t\tmesh.nset_list[4].append(int(i + 1))\n\t\telif node[2] == 0:\n\t\t\tmesh.nset_list[5].append(int(i + 1))\n\t\t# WARNING some nodes in multiple nodesets\n\twith open(files.nodeset, \"w+\") as f:\n\t\tf.write(\"**Defines node sets\")\n\t\tfor i, nset in enumerate(mesh.nset_list):\n\t\t\tf.write(\"\\n*Nset, nset=\" + mesh.nset_names[i] + \"\\n\")\n\t\t\tfor n in range(len(nset)):\n\t\t\t\tif n == len(nset) - 1:\n\t\t\t\t\tf.write(str(nset[n]))\n\t\t\t\telif (n + 1) % 16 == 0 and n != 0:\n\t\t\t\t\tf.write(str(nset[n]) + \",\\n\")\n\t\t\t\telse:\n\t\t\t\t\tf.write(str(nset[n]) + \", \")\n\n\t# --------------------------------------------------------------------------------------------------\n\t# orientation:\n\t# --------------------------------------------------------------------------------------------------\n\t# function to get vectors:\n\tdef rand_orient(orient_obj):\n\t\tdef random_miller(n):\n\t\t\tvector = []\n\t\t\tfor _ in range(n):\n\t\t\t\tvector.append(randrange(-(orient_obj.max_index + 1), orient_obj.max_index + 1))\n\t\t\treturn vector\n\n\t\tx = y = 3 * [0]\n\t\twhile y == 3 * [0]:\n\t\t\ty = random_miller(3)\n\t\tif y[2] == 0:\n\t\t\tx[0] = x[1] = 0\n\t\t\tx[2] = 1\n\t\telse:\n\t\t\tx = [*random_miller(2), 0]\n\t\t\tx[2] = np.round(((x[0] * y[0] + x[1] * y[1]) / (-y[2])), decimals=5)\n\t\torient_obj.assign(x, y)\n\n\t# write vectors to file:\n\twith open(files.orients, \"w+\") as f:\n\t\tf.write(\"*Parameter \\n\")\n\t\torient_obj = orient()\n\t\tfor a in range(1, dim.num_grains + 1):\n\t\t\trand_orient(orient_obj)\n\t\t\tf.write(\"**Local direction of the global x direction \\n\")\n\t\t\tf.write(\"x\" + str(a) + \" = \" + str(orient_obj.x[0]) + \"\\n\")\n\t\t\tf.write(\"y\" + str(a) + \" = \" + str(orient_obj.x[1]) + \"\\n\")\n\t\t\tf.write(\"z\" + str(a) + \" = \" + str(orient_obj.x[2]) + \"\\n\")\n\t\t\tf.write(\"**Local direction of the global y direction \\n\")\n\t\t\tf.write(\"u\" + str(a) + \" = \" + str(orient_obj.y[0]) + \"\\n\")\n\t\t\tf.write(\"v\" + str(a) + \" = \" + str(orient_obj.y[1]) + \"\\n\")\n\t\t\tf.write(\"w\" + str(a) + \" = \" + str(orient_obj.y[2]) + \"\\n\")\n\t\t\tf.write(\"** -------------------------------------------------\")\n\t\t\tif a != dim.num_grains:\n\t\t\t\tf.write(\"\\n\")\n\t# --------------------------------------------------------------------------------------------------\n\t# write all other files\n\t# --------------------------------------------------------------------------------------------------\n\t# parameters\n\twith open(files.mesh_extra, \"w\") as f:\n\t\tdim.ref_node = int(np.ceil(dim.num_nodes / 1e7) * 1e7)\n\t\t# ^ start ref numbering at next 10 millionth node for clear separation from regular nodes\n\t\tf.write(\n\t\t\t\"\"\"** mesh parameters\n*Parameter\nxmax = \"\"\"\n\t\t\t+ str(dim.edge_x)\n\t\t\t+ \"\"\"\nymax = \"\"\"\n\t\t\t+ str(dim.edge_y)\n\t\t\t+ \"\"\"\nzmax = \"\"\"\n\t\t\t+ str(dim.edge_z)\n\t\t\t+ \"\"\"\nxmin = \"\"\"\n\t\t\t+ str(0)\n\t\t\t+ \"\"\"\nymin = \"\"\"\n\t\t\t+ str(0)\n\t\t\t+ \"\"\"\nzmin = \"\"\"\n\t\t\t+ str(0)\n\t\t\t+ \"\"\"\nx_Half = (xmax-xmin)/2\ny_Half = (ymax-ymin)/2\nz_Half = (zmax-zmin)/2\n*Node\n\"\"\"\n\t\t\t+ str(dim.ref_node + 0)\n\t\t\t+ \"\"\",    &lt;x_Half&gt;,      &lt;y_Half&gt;,          &lt;zmin&gt;\n\"\"\"\n\t\t\t+ str(dim.ref_node + 1)\n\t\t\t+ \"\"\",    &lt;x_Half&gt;,      &lt;y_Half&gt;,          &lt;zmax&gt;\n\"\"\"\n\t\t\t+ str(dim.ref_node + 2)\n\t\t\t+ \"\"\",    &lt;x_Half&gt;,        &lt;ymax&gt;,        &lt;z_Half&gt;\n\"\"\"\n\t\t\t+ str(dim.ref_node + 3)\n\t\t\t+ \"\"\",      &lt;xmax&gt;,      &lt;y_Half&gt;,        &lt;z_Half&gt;\n\"\"\"\n\t\t\t+ str(dim.ref_node + 4)\n\t\t\t+ \"\"\",      &lt;xmin&gt;,      &lt;y_Half&gt;,        &lt;z_Half&gt;\n\"\"\"\n\t\t\t+ str(dim.ref_node + 5)\n\t\t\t+ \"\"\",    &lt;x_Half&gt;,        &lt;ymin&gt;,        &lt;z_Half&gt;\n*Nset, nset=RP-Back\n\"\"\"\n\t\t\t+ str(dim.ref_node + 0)\n\t\t\t+ \"\"\"\n*Nset, nset=RP-Front\n\"\"\"\n\t\t\t+ str(dim.ref_node + 1)\n\t\t\t+ \"\"\"\n*Nset, nset=RP-Top\n\"\"\"\n\t\t\t+ str(dim.ref_node + 2)\n\t\t\t+ \"\"\"\n*Nset, nset=RP-Right\n\"\"\"\n\t\t\t+ str(dim.ref_node + 3)\n\t\t\t+ \"\"\"\n*Nset, nset=RP-Left\n\"\"\"\n\t\t\t+ str(dim.ref_node + 4)\n\t\t\t+ \"\"\"\n*Nset, nset=RP-Bottom\n\"\"\"\n\t\t\t+ str(dim.ref_node + 5)\n\t\t\t+ \"\"\"\n**\"\"\"\n\t\t)\n\t# --------------------------------------------------------------------------------------------------\n\t# main input file\n\twith open(files.main, \"w\") as f:\n\t\tf.write(\n\t\t\t\"\"\"** main input file\n*include, input=\"\"\"\n\t\t\t+ files.elements\n\t\t\t+ \"\"\"\n*include, input=\"\"\"\n\t\t\t+ files.elset\n\t\t\t+ \"\"\"\n*include, input=\"\"\"\n\t\t\t+ files.nodes\n\t\t\t+ \"\"\"\n*include, input=\"\"\"\n\t\t\t+ files.nodeset\n\t\t\t+ \"\"\"\n*include, input=\"\"\"\n\t\t\t+ files.mesh_extra\n\t\t\t+ \"\"\"\n*include, input=\"\"\"\n\t\t\t+ files.sections\n\t\t\t+ \"\"\"\n*include, input=\"\"\"\n\t\t\t+ files.orients\n\t\t\t+ \"\"\"\n*include, input=\"\"\"\n\t\t\t+ files.material\n\t\t\t+ \"\"\"\n*include, input=\"\"\"\n\t\t\t+ files.slip\n\t\t\t+ \"\"\"\n**\n*Equation\n2\nTop , 2, -1\nRP-Top, 2,  1\n2\nBottom , 2, -1\nRP-Bottom, 2,  1\n2\nFront , 3, -1\nRP-Front, 3,  1\n2\nBack , 3, -1\nRP-Back, 3,  1\n2\nLeft , 1, -1\nRP-Left, 1,  1\n2\nRight , 1, -1\nRP-Right, 1,  1\n**\n***RESTART,WRITE,FREQUENCY=5\n*STEP, name=Loading, INC=1000000, NLGEOM, unsymm=YES, extrapolation=NO\n*STATIC\n1E-8,1.0,1E-9,0.005\n*Boundary\nRP-Bottom, 2, 2\nRP-Back,   3, 3\nRP-Left,   1, 1\nRP-Top, 2, 2, \"\"\"\n\t\t\t+ str(dim.disp)\n\t\t\t+ \"\"\"\n**\n*Output, field, Number interval=30, Time Marks=No\n*Node output\nRF, U\n*Element Output, directions=YES\nLE, PE, PEEQ, S, SDV\n*END STEP\"\"\"\n\t\t)\n\t# --------------------------------------------------------------------------------------------------\n\t# material definition\n\twith open(files.material, \"w\") as f:\n\t\tf.write(\n\t\t\t\"\"\"** Material hardening parameters in the Bassani-Wu model\n*Parameter\n** Elastic Moduli\n** Unit: MPa\nC11 = 265.e3\nC12 = 161.e3\nC44 = 127.e3\n** Constitutive relation (power law)\nGamma0 = 0.001\n** Unit: s^-1\nn = 50.\n** should be larger than 1 (n = 1/m)\n** Hardening law (hyperbolic function)\n** Unit: MPa\nTau0 = 12.92\nH0   = 40.8\nTauS = 40\nhs = 0.01\ngamma0 = 0.4\nf0 = 1\nq = 1\n**Second slip system family info:\ngamma1 = 1\nf1 = 1\nq1 = 1\"\"\"\n\t\t)\n\t# --------------------------------------------------------------------------------------------------\n\t# material properties for each grain\n\twith open(files.slip, \"w+\") as f:\n\t\tf.write(\"** Material properties for each grain\")\n\tmesh.grain_lines = []\n\tfor n in range(dim.num_grains):\n\t\tmesh.grain_lines.append(\n\t\t\t\"\"\"\n** ----------------------------------------------------------------------------\n*Material, name = Grain\"\"\"\n\t\t\t+ str(n + 1)\n\t\t\t+ \"\"\"_Phase1_mat\n*Depvar\n125\n*User material, Constants=160, unsymm\n&lt;C11&gt; ,  &lt;C12&gt; ,  &lt;C44&gt; ,\n0.   ,\n0.   ,\n1.   ,\n1.   ,   1.   ,   1.   ,   1.   ,   1.   ,   0.   ,\n0.   ,\n0.   ,\n&lt;x\"\"\"\n\t\t\t+ str(n + 1)\n\t\t\t+ \"\"\"&gt;   ,  &lt;y\"\"\"\n\t\t\t+ str(n + 1)\n\t\t\t+ \"\"\"&gt;,    &lt;z\"\"\"\n\t\t\t+ str(n + 1)\n\t\t\t+ \"\"\"&gt;,        1,       0,       0,\n&lt;u\"\"\"\n\t\t\t+ str(n + 1)\n\t\t\t+ \"\"\"&gt;   ,  &lt;v\"\"\"\n\t\t\t+ str(n + 1)\n\t\t\t+ \"\"\"&gt;,    &lt;w\"\"\"\n\t\t\t+ str(n + 1)\n\t\t\t+ \"\"\"&gt;,        0,       1,       0,\n&lt;n&gt;  ,&lt;Gamma0&gt;  ,\n0.   ,   0.\n0.   ,   0.   ,\n&lt;H0&gt;  , &lt;TauS&gt; , &lt;Tau0&gt;,  &lt;hs&gt;,  &lt;gamma0&gt;,  &lt;gamma1&gt;,  &lt;f0&gt;,  &lt;f1&gt; \n&lt;q&gt;   ,  &lt;q1&gt;   ,\n0.   ,\n0.   ,\n0.   ,\n0.   ,\n.5   ,   1.   ,\n1.   ,   10.  , 1.E-5  ,\"\"\"\n\t\t)\n\t# write the rest of the file\n\twith open(files.slip, \"a\") as f:\n\t\tfor line in range(len(mesh.grain_lines)):\n\t\t\tf.write(str(mesh.grain_lines[line]))\n</code></pre>"},{"location":"API/models/#matmdl.models.mk_singleModel","title":"<code>mk_singleModel</code>","text":"<p>Creates input files for multiple vertical elements. Jan 31, 2020.</p>"},{"location":"API/models/#matmdl.models.mk_singleModel.ask_dimensions","title":"<code>ask_dimensions()</code>","text":"<p>Get user input for model dimensions.</p> <p>Args:</p> <p>Returns:</p> Name Type Description <code>number_of_elements</code> <code>int</code> <p>Length of model in the y (loading) direction</p> Source code in <code>matmdl/models/mk_singleModel.py</code> <pre><code>def ask_dimensions():\n\t\"\"\"\n\tGet user input for model dimensions.\n\n\tArgs:\n\n\tReturns:\n\t    number_of_elements (int): Length of model in the y (loading) direction\n\n\t\"\"\"\n\tnumber_of_elements = int(input(\"Number of elements: \"))\n\treturn number_of_elements\n</code></pre>"},{"location":"API/models/#matmdl.models.mk_singleModel.mk_singleModel","title":"<code>mk_singleModel(number_of_elements)</code>","text":"<p>Make a chain of elements for single crystal modeling.</p> <p>Parameters:</p> Name Type Description Default <code>number_of_elements</code> <code>int</code> <p>Length of chain model along loading direction, which is y</p> required <p>Returns:</p> Source code in <code>matmdl/models/mk_singleModel.py</code> <pre><code>def mk_singleModel(number_of_elements):\n\t\"\"\"\n\tMake a chain of elements for single crystal modeling.\n\n\tArgs:\n\t\tnumber_of_elements (int): Length of chain model along loading\n\t\t\tdirection, which is y\n\n\tReturns:\n\n\t\"\"\"\n\n\t# name = 'Mesh_' + str(number_of_elements) + '_elements.inp'\n\tname = \"Mesh_Xelement.inp\"\n\ttry:\n\t\tos.remove(name)\n\texcept:\n\t\tpass\n\n\tf = open(name, \"w+\")\n\n\t# write nodes\n\tf.write(\n\t\t\"*Node, nset=All\\n\"\n\t\t+ \"\\t1,\\t0.,\\t0.,\\t0.\\n\"\n\t\t+ \"\\t2,\\t1.,\\t0.,\\t0.\\n\"\n\t\t+ \"\\t3,\\t1.,\\t1.,\\t0.\\n\"\n\t\t+ \"\\t4,\\t0.,\\t1.,\\t0.\\n\"\n\t\t+ \"\\t5,\\t0.,\\t0.,\\t1.\\n\"\n\t\t+ \"\\t6,\\t1.,\\t0.,\\t1.\\n\"\n\t\t+ \"\\t7,\\t1.,\\t1.,\\t1.\\n\"\n\t\t+ \"\\t8,\\t0.,\\t1.,\\t1.\\n\"\n\t)\n\t# n is each additional layer\n\tfor n in range(2, number_of_elements + 1):\n\t\tif n == number_of_elements:\n\t\t\tf.write(\n\t\t\t\t\"\\t\"\n\t\t\t\t+ str(n * 4 + 1)\n\t\t\t\t+ \",\\t1.,\\t\"\n\t\t\t\t+ str(n)\n\t\t\t\t+ \".,\\t0.\\n\"\n\t\t\t\t+ \"\\t\"\n\t\t\t\t+ str(n * 4 + 2)\n\t\t\t\t+ \",\\t0.,\\t\"\n\t\t\t\t+ str(n)\n\t\t\t\t+ \".,\\t0.\\n\"\n\t\t\t\t+ \"\\t\"\n\t\t\t\t+ str(n * 4 + 3)\n\t\t\t\t+ \",\\t1.,\\t\"\n\t\t\t\t+ str(n)\n\t\t\t\t+ \".,\\t1.\\n\"\n\t\t\t\t+ \"\\t\"\n\t\t\t\t+ str(n * 4 + 4)\n\t\t\t\t+ \",\\t0.,\\t\"\n\t\t\t\t+ str(n)\n\t\t\t\t+ \".,\\t1.\"\n\t\t\t)\n\t\telse:\n\t\t\tf.write(\n\t\t\t\t\"\\t\"\n\t\t\t\t+ str(n * 4 + 1)\n\t\t\t\t+ \",\\t1.,\\t\"\n\t\t\t\t+ str(n)\n\t\t\t\t+ \".,\\t0.\\n\"\n\t\t\t\t+ \"\\t\"\n\t\t\t\t+ str(n * 4 + 2)\n\t\t\t\t+ \",\\t0.,\\t\"\n\t\t\t\t+ str(n)\n\t\t\t\t+ \".,\\t0.\\n\"\n\t\t\t\t+ \"\\t\"\n\t\t\t\t+ str(n * 4 + 3)\n\t\t\t\t+ \",\\t1.,\\t\"\n\t\t\t\t+ str(n)\n\t\t\t\t+ \".,\\t1.\\n\"\n\t\t\t\t+ \"\\t\"\n\t\t\t\t+ str(n * 4 + 4)\n\t\t\t\t+ \",\\t0.,\\t\"\n\t\t\t\t+ str(n)\n\t\t\t\t+ \".,\\t1.\\n\"\n\t\t\t)\n\tif number_of_elements == 1:\n\t\tf.write(\"**\")\n\n\t# get correct ordering of nodes\n\tdef order_next(prev_order, element_number):\n\t\tmax_nodes = 8 + 4 * (element_number - 1)\n\t\tnext_order = [\n\t\t\tprev_order[3],\n\t\t\tprev_order[2],\n\t\t\tmax_nodes - 3,\n\t\t\tmax_nodes - 2,\n\t\t\tprev_order[7],\n\t\t\tprev_order[6],\n\t\t\tmax_nodes - 1,\n\t\t\tmax_nodes - 0,\n\t\t]\n\t\treturn next_order\n\n\t# order of first element:\n\torder = [1, 2, 3, 4, 5, 6, 7, 8]\n\n\t# initiate nodesets with nodes from the bottom of the first element\n\tnset_left = [1, 5]\n\tnset_right = [2, 6]\n\tnset_front = [5, 6]\n\tnset_back = [1, 2]\n\n\t# write elements in terms of nodes, in correct order:\n\tfor n in range(1, number_of_elements + 1):\n\t\t# write heading for element\n\t\tf.write(\"\\n*Element, type=C3D8, elset=All\\n\" + str(n) + \", \")\n\n\t\t# write out node order\n\t\tfor i in range(0, 7):\n\t\t\tf.write(str(order[i]) + \", \")\n\t\tf.write(str(order[7]))\n\n\t\t# add top nodes to appropriate nodesets\n\t\tnset_left.append(order[3])\n\t\tnset_left.append(order[7])\n\n\t\tnset_right.append(order[2])\n\t\tnset_right.append(order[6])\n\n\t\tnset_front.append(order[6])\n\t\tnset_front.append(order[7])\n\n\t\tnset_back.append(order[2])\n\t\tnset_back.append(order[3])\n\n\t\t# update node order\n\t\torder = order_next(order, n + 1)\n\n\t# modification to consider only top and bottom elements\n\t# in nset definitions (following 4 lines):\n\tnset_left = nset_left[:2] + nset_left[-2:]\n\tnset_right = nset_right[:2] + nset_right[-2:]\n\tnset_front = nset_front[:2] + nset_front[-2:]\n\tnset_back = nset_back[:2] + nset_back[-2:]\n\n\t## write node sets for faces\n\tdef write16perLine(items):\n\t\tlength = len(items)\n\t\tfor i in range(length):\n\t\t\tif i == length - 1:\n\t\t\t\tf.write(str(items[i]))\n\t\t\telif ((i + 1) % 16 == 0) and (i != 0):\n\t\t\t\tf.write(str(items[i]) + \",\\n\")\n\t\t\telse:\n\t\t\t\tf.write(str(items[i]) + \", \")\n\n\t# left\n\tf.write(\"\\n*Nset, nset=Left\\n\")\n\twrite16perLine(nset_left)\n\n\t# right\n\tf.write(\"\\n*Nset, nset=Right\\n\")\n\twrite16perLine(nset_right)\n\n\t# front\n\tf.write(\"\\n*Nset, nset=Front\\n\")\n\twrite16perLine(nset_front)\n\n\t# back\n\tf.write(\"\\n*Nset, nset=Back\\n\")\n\twrite16perLine(nset_back)\n\n\t# top\n\tif number_of_elements == 1:\n\t\tnset_top = [3, 4, 7, 8]\n\telse:\n\t\ttotal_nodes = 8 + 4 * (number_of_elements - 1)\n\t\tnset_top = [total_nodes, total_nodes - 1, total_nodes - 2, total_nodes - 3]\n\tf.write(\"\\n*Nset, nset=Top\\n\")\n\tfor i in range(4):\n\t\tf.write(str(nset_top[i]) + \", \")\n\n\t# bottom\n\tf.write(\"\\n*Nset, nset=Bottom\\n\" + \"1, 2, 5, 6\")\n\n\t## write end matter\n\tf.write(\n\t\t\"\\n**\\n\"\n\t\t+ \"*Parameter\\n\"\n\t\t+ \"x=1.\\n\"\n\t\t+ \"y=\"\n\t\t+ str(number_of_elements)\n\t\t+ \".\\n\"\n\t\t+ \"z=1.\\n\"\n\t\t+ \"x_Half=x/2\\n\"\n\t\t+ \"y_Half=y/2\\n\"\n\t\t+ \"z_Half=z/2\\n\"\n\t\t+ \"*Node\\n\"\n\t\t+ \"20000000,\\t&lt;x_Half&gt;,\\t&lt;y_Half&gt;,\\t0.\\n\"\n\t\t+ \"20000001,\\t&lt;x_Half&gt;,\\t&lt;y_Half&gt;,\\t&lt;z_Half&gt;\\n\"\n\t\t+ \"20000002,\\t&lt;x_Half&gt;,\\t&lt;y&gt;,\\t\\t0.\\n\"\n\t\t+ \"20000003,\\t&lt;x&gt;,\\t\\t&lt;y_Half&gt;,\\t0.\\n\"\n\t\t+ \"20000004,\\t0.,\\t\\t&lt;y_Half&gt;,\\t0.\\n\"\n\t\t+ \"20000005,\\t&lt;x_Half&gt;,\\t0.,\\t\\t0.\\n\"\n\t\t+ \"*Nset, nset=RP-Back\\n\"\n\t\t+ \"20000000\\n\"\n\t\t+ \"*Nset, nset=RP-Front\\n\"\n\t\t+ \"20000001\\n\"\n\t\t+ \"*Nset, nset=RP-Top\\n\"\n\t\t+ \"20000002\\n\"\n\t\t+ \"*Nset, nset=RP-Right\\n\"\n\t\t+ \"20000003\\n\"\n\t\t+ \"*Nset, nset=RP-Left\\n\"\n\t\t+ \"20000004\\n\"\n\t\t+ \"*Nset, nset=RP-Bottom\\n\"\n\t\t+ \"20000005\\n\"\n\t)\n\tf.close()\n</code></pre>"},{"location":"API/objectives/","title":"API: Objectives","text":""},{"location":"API/objectives/#matmdl.objectives","title":"<code>matmdl.objectives</code>","text":"<p>Choose the objective function form. Currently only rmse exists.</p>"},{"location":"API/objectives/#matmdl.objectives.best_rmse","title":"<code>best_rmse</code>","text":"<p>Calculate the RMSE for the best parameter set.</p> <p>Best parameters determined by objective function that wrote to out_errors.txt. Use root mean squared error so that error value is more interpretable.</p>"},{"location":"API/objectives/#matmdl.objectives.calculate","title":"<code>calculate</code>","text":""},{"location":"API/objectives/#matmdl.objectives.calculate.calc_error","title":"<code>calc_error(exp_data, orientation, sim_data=None)</code>","text":"<p>Give error value for run compared to experimental data.</p> <p>Calculates relative (%) root mean squared error between experimental and calculated stress-strain curves. Interpolation of experimental data depends on :ref:<code>i_powerlaw</code>.</p> <p>Parameters:</p> Name Type Description Default <code>exp_data</code> <code>'Nx2 matrix'</code> <p>Array of experimental strain-stress, as from <code>exp_data.data[orientation]['raw']</code>.</p> required <code>orientation</code> <code>str</code> <p>Orientation nickname.</p> required Source code in <code>matmdl/objectives/calculate.py</code> <pre><code>def calc_error(exp_data: \"Nx2 matrix\", orientation: str, sim_data=None) -&gt; float:\n\t\"\"\"\n\tGive error value for run compared to experimental data.\n\n\tCalculates relative (%) root mean squared error between experimental and calculated\n\tstress-strain curves. Interpolation of experimental data depends on :ref:`i_powerlaw`.\n\n\tArgs:\n\t    exp_data: Array of experimental strain-stress, as from\n\t        ``exp_data.data[orientation]['raw']``.\n\t    orientation: Orientation nickname.\n\t\"\"\"\n\tif sim_data is None:\n\t\tsimSS = np.loadtxt(f\"temp_time_disp_force_{orientation}.csv\", delimiter=\",\", skiprows=1)[\n\t\t\t1:, 1:\n\t\t]\n\t\t# if loading force-displacement from file, normalize to engineering stress-strain:\n\t\tsimSS[:, 0] = simSS[:, 0] / uset.length\n\t\tsimSS[:, 1] = simSS[:, 1] / uset.area\n\telse:\n\t\t# TODO do checks for sim_data format/types\n\t\tsimSS = sim_data\n\t# TODO get simulation dimensions at beginning of running this file, pass to this function\n\n\texpSS = deepcopy(exp_data)\n\n\tif uset.is_compression:\n\t\texpSS *= -1.0\n\t\tsimSS *= -1.0\n\n\t# deal with unequal data lengths\n\tif simSS[-1, 0] &gt; expSS[-1, 0]:\n\t\t# chop off simSS\n\t\tcutoff = np.where(simSS[:, 0] &gt; expSS[-1, 0])[0][0] - 1\n\t\tsimSS = simSS[:cutoff, :]\n\t\tcutoff_strain = simSS[-1, 0]\n\telif simSS[-1, 0] &lt; expSS[-1, 0]:\n\t\t# chop off expSS\n\t\tcutoff = np.where(simSS[-1, 0] &lt; expSS[:, 0])[0][0] - 1\n\t\texpSS = expSS[:cutoff, :]\n\t\tcutoff_strain = expSS[-1, 0]\n\telse:\n\t\tcutoff_strain = simSS[-1, 0]\n\tbegin_strain = max(min(expSS[:, 0]), min(simSS[:, 0]))\n\n\tdef powerlaw(x, k, n):\n\t\ty = k * x**n\n\t\treturn y\n\n\tdef fit_powerlaw(x, y):\n\t\tpopt, _ = curve_fit(powerlaw, x, y)\n\t\treturn popt\n\n\t# interpolate points in both curves\n\tnum_error_eval_pts = 1000\n\tx_error_eval_pts = np.linspace(begin_strain, cutoff_strain, num=num_error_eval_pts)\n\tinterpSim = interp1d(simSS[:, 0], simSS[:, 1])\n\tif not uset.i_powerlaw:\n\t\tinterpExp = interp1d(expSS[:, 0], expSS[:, 1])\n\telse:\n\t\tpopt = fit_powerlaw(expSS[:, 0], expSS[:, 1])\n\n\t\tdef interpExp(x):\n\t\t\treturn powerlaw(x, *popt)\n\n\t# strictly limit to interpolation\n\twhile x_error_eval_pts[-1] &gt;= expSS[-1, 0]:\n\t\tx_error_eval_pts = np.delete(x_error_eval_pts, -1)\n\n\t# error function\n\tstress_error = _stress_diff(x_error_eval_pts, interpSim, interpExp)\n\tslope_error = _slope_diff(x_error_eval_pts, interpSim, interpExp)\n\tw = uset.slope_weight\n\terror = (1 - w) * stress_error + w * slope_error\n\n\treturn error\n</code></pre>"},{"location":"API/objectives/#matmdl.objectives.calculate.ddx_pointwise","title":"<code>ddx_pointwise(curve, x)</code>","text":"<p>Give point-to-point slope values of curve over x</p> Source code in <code>matmdl/objectives/calculate.py</code> <pre><code>def ddx_pointwise(curve, x):\n\t\"\"\"Give point-to-point slope values of curve over x\"\"\"\n\treturn (curve(x[1:]) - curve(x[:-1])) / (x[1:] - x[:-1])\n</code></pre>"},{"location":"API/objectives/#matmdl.objectives.calculate.ddx_rolling","title":"<code>ddx_rolling(curve, x, window)</code>","text":"<p>Give rolling window slope of curve</p> Source code in <code>matmdl/objectives/calculate.py</code> <pre><code>def ddx_rolling(curve, x, window):\n\t\"\"\"Give rolling window slope of curve\"\"\"\n\tn = int(window)\n\tassert n &gt; 1, \"Rolling average requires window width of 2 or more points\"\n\tnum_windows = len(x) - window\n\tslopes = np.empty(num_windows)\n\tfor i in range(num_windows):\n\t\tslopes[i] = np.polyfit(x[i : i + n], curve(x[i : i + n]), 1)[0]\n\treturn slopes\n</code></pre>"},{"location":"API/objectives/#matmdl.objectives.recalculate","title":"<code>recalculate</code>","text":"<p>Recalculates error values based on saved stress-strain data.</p> <p>Reloads *.npy files to recalculation of individual error values. Moves current out_errors.txt to dated filename before rewriting. Uses current error settings</p>"},{"location":"API/plot/","title":"Plotting","text":"<p>Plotting is carried out by the <code>plot</code> module, callable by:</p> <pre><code>python -m matmdl.plot\n</code></pre>"},{"location":"API/plot/#matmdl.plot","title":"<code>matmdl.plot</code>","text":"<p>Plots several figures per optimization:</p> <ol> <li>Stress-strain curves of all parameter sets (per orientation, if applicable)</li> <li>Stress-strain curve of best parameter set (per orientation, if applicable)</li> <li>Convergence (lowest error as a function of iteration)</li> <li>Histograms of parameter evaluations</li> <li>Partial dependencies of the objective function</li> </ol> <p>Prints best parameters to file out_best_params.txt</p> <p>TODO: refactor overlap between main() and plot_single()</p>"},{"location":"API/plot/#matmdl.plot.get_rotation_ccw","title":"<code>get_rotation_ccw(degrees)</code>","text":"<p>Takes data, rotates ccw</p> Source code in <code>matmdl/plot.py</code> <pre><code>def get_rotation_ccw(degrees):\n\t\"\"\"Takes data, rotates ccw\"\"\"\n\tradians = degrees / 180.0 * np.pi\n\trot = np.array([[np.cos(radians), np.sin(radians)], [-np.sin(radians), np.cos(radians)]])\n\treturn rot\n</code></pre>"},{"location":"API/plot/#matmdl.plot.plot_error_front","title":"<code>plot_error_front(errors, samples)</code>","text":"<p>plot Pareto frontiers of error from each pair of samples</p> TODO <ul> <li>focus on minimal front?</li> <li>check for convexity of each pairwise cases? e.g. area between hull and front</li> </ul> Source code in <code>matmdl/plot.py</code> <pre><code>def plot_error_front(errors, samples):\n\t\"\"\"plot Pareto frontiers of error from each pair of samples\n\n\tTODO:\n\t\t- focus on minimal front?\n\t\t- check for convexity of each pairwise cases? e.g. area between hull and front\n\t\"\"\"\n\tnum_samples = np.shape(errors)[1] - 1\n\tif num_samples &lt; 2:\n\t\twarn(\"skipping multi-error plot\")\n\t\treturn\n\telse:\n\t\tmsg(\"error fronts\")\n\n\tsize = 2  # size in inches of each suplot here\n\tfig, ax = plt.subplots(\n\t\tnrows=num_samples - 1,\n\t\tncols=num_samples - 1,\n\t\tsqueeze=False,\n\t\tfigsize=(1.6 * size, size)\n\t\tif num_samples == 2\n\t\telse (size * (num_samples - 1), size * (num_samples - 1)),\n\t\tlayout=\"constrained\",\n\t)\n\n\tind_min_error = np.argmin(errors[:, -1])\n\tfor i in range(0, num_samples - 1):  # i horizontal going right\n\t\tfor j in range(0, num_samples - 1):  # j vertical going down\n\t\t\t_ax = ax[j, i]\n\t\t\tif i &gt; j:\n\t\t\t\t_ax.axis(\"off\")\n\t\t\telse:\n\t\t\t\t_ax.scatter(errors[:, i], errors[:, j + 1], c=errors[:, -1], cmap=\"viridis\")\n\t\t\t\t_ax.set_xlabel(f\"{samples[i]} Error\")\n\t\t\t\t_ax.set_ylabel(f\"{samples[j+1]} Error\")\n\n\t\t\t\tif i &gt; 0:\n\t\t\t\t\t_ax.set_yticklabels([])\n\t\t\t\t\t_ax.set_ylabel(\"\")\n\t\t\t\tif j &lt; num_samples - 2:\n\t\t\t\t\t_ax.set_xticklabels([])\n\t\t\t\t\t_ax.set_xlabel(\"\")\n\n\t\t\t\t# global min:\n\t\t\t\t_ax.plot(\n\t\t\t\t\terrors[ind_min_error, i],\n\t\t\t\t\terrors[ind_min_error, j + 1],\n\t\t\t\t\t\"*\",\n\t\t\t\t\tcolor=\"red\",\n\t\t\t\t\tmarkersize=12,\n\t\t\t\t)\n\n\tfig.colorbar(\n\t\tmatplotlib.cm.ScalarMappable(\n\t\t\tnorm=matplotlib.colors.Normalize(\n\t\t\t\tvmin=min(errors[:, -1]),\n\t\t\t\tvmax=max(errors[:, -1]),\n\t\t\t),\n\t\t\tcmap=\"viridis\",\n\t\t),\n\t\tax=ax[0, 0] if num_samples == 2 else ax[0, 1],\n\t\tlabel=\"Mean Error\",\n\t\tpad=0.05 if num_samples == 2 else -1,\n\t\taspect=15,\n\t)\n\tfig.savefig(os.path.join(os.getcwd(), \"res_errors.png\"), bbox_inches=\"tight\", dpi=400)\n\tplt.close(fig)\n</code></pre>"},{"location":"API/plot/#matmdl.plot.plot_error_front_fit","title":"<code>plot_error_front_fit(errors, samples)</code>","text":"<p>Plots Pareto efficient pairwise errors with parabolic fits.</p> <p>Parameters:</p> Name Type Description Default <code>errors</code> <p>matrix of error values (cols iterations, rows samples)</p> required <code>samples</code> <p>names of each sample</p> required Source code in <code>matmdl/plot.py</code> <pre><code>def plot_error_front_fit(errors, samples):\n\t\"\"\"\n\tPlots Pareto efficient pairwise errors with parabolic fits.\n\n\tArgs:\n\t    errors: matrix of error values (cols iterations, rows samples)\n\t    samples: names of each sample\n\t\"\"\"\n\tnum_samples = np.shape(errors)[1] - 1\n\tif num_samples &lt; 2:\n\t\twarn(\"skipping multi-error plot\")\n\t\treturn\n\telse:\n\t\tmsg(\"error front fits\")\n\n\txsize = 2.5\n\tysize = 2\n\tfig, ax = plt.subplots(\n\t\tnrows=num_samples - 1,\n\t\tncols=num_samples - 1,\n\t\tsqueeze=False,\n\t\tfigsize=(xsize * (num_samples - 1), ysize * (num_samples - 1)),\n\t\tlayout=\"constrained\",\n\t)\n\n\trotation = get_rotation_ccw(degrees=45)\n\tcurvatures = {sample: 0.0 for sample in samples}\n\tdiff_xs = {\n\t\tsample: 0.0 for sample in samples\n\t}  # x-shift between parabola center and y=x (equal error)\n\tdiff_ys = {sample: 0.0 for sample in samples}  # y-shift between parabola center and global min\n\tdiff_rs = {\n\t\tsample: 0.0 for sample in samples\n\t}  # height of parabola from line where equal error is 0\n\tglobal_best_ind = np.argmin(errors[:, -1])\n\n\tfor i in range(0, num_samples - 1):  # i horizontal going right\n\t\tfor j in range(0, num_samples - 1):  # j vertical going down\n\t\t\t_ax = ax[j, i]\n\t\t\tif i &gt; j:\n\t\t\t\t_ax.axis(\"off\")\n\t\t\telse:\n\t\t\t\tplt_errors = np.stack((errors[:, i], errors[:, j + 1]), axis=1)\n\n\t\t\t\tis_boundary = np.full((np.shape(plt_errors)[0]), False, dtype=bool)\n\t\t\t\tfor k, error in enumerate(plt_errors):\n\t\t\t\t\tis_boundary[k] = np.invert(\n\t\t\t\t\t\tnp.any(\n\t\t\t\t\t\t\tnp.all(\n\t\t\t\t\t\t\t\tnp.stack(\n\t\t\t\t\t\t\t\t\t(\n\t\t\t\t\t\t\t\t\t\tplt_errors[:, 0] &lt; error[0],\n\t\t\t\t\t\t\t\t\t\tplt_errors[:, 1] &lt; error[1],\n\t\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\t\taxis=1,\n\t\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\t\taxis=1,\n\t\t\t\t\t\t\t),\n\t\t\t\t\t\t\taxis=0,\n\t\t\t\t\t\t)\n\t\t\t\t\t)\n\t\t\t\tboundary_errors = plt_errors[is_boundary, :]\n\n\t\t\t\t_ax.plot(\n\t\t\t\t\tboundary_errors[:, 0],\n\t\t\t\t\tboundary_errors[:, 1],\n\t\t\t\t\t\"o\",\n\t\t\t\t\tcolor=\"blue\",\n\t\t\t\t\tmarkerfacecolor=\"none\",\n\t\t\t\t\tzorder=2.0,\n\t\t\t\t)\n\t\t\t\tmax_boundary_error = max(max(boundary_errors[:, 0]), max(boundary_errors[:, 1]))\n\t\t\t\tmin_boundary_error = min(min(boundary_errors[:, 0]), min(boundary_errors[:, 1]))\n\t\t\t\tspan = max_boundary_error - min_boundary_error\n\t\t\t\tpad = 0.05  # fraction of data span to add to window span\n\t\t\t\t_ax.set_xlim(\n\t\t\t\t\tleft=min_boundary_error - pad * span,\n\t\t\t\t\tright=max_boundary_error + pad * span,\n\t\t\t\t)\n\t\t\t\t_ax.set_ylim(\n\t\t\t\t\tbottom=min_boundary_error - pad * span,\n\t\t\t\t\ttop=max_boundary_error + pad * span,\n\t\t\t\t)\n\t\t\t\t_ax.plot(\n\t\t\t\t\tplt_errors[:, 0],\n\t\t\t\t\tplt_errors[:, 1],\n\t\t\t\t\t\"o\",\n\t\t\t\t\tcolor=\"black\",\n\t\t\t\t\tmarkerfacecolor=\"none\",\n\t\t\t\t\tzorder=1.0,\n\t\t\t\t)\n\t\t\t\t_ax.set_xlabel(f\"{samples[i]}\")\n\t\t\t\t_ax.set_ylabel(f\"{samples[j+1]}\")\n\n\t\t\t\t# add equal error line\n\t\t\t\tline = np.linspace(min_boundary_error, max_boundary_error, 100)\n\t\t\t\t_ax.plot(line, line, \":\", color=\"grey\", zorder=2.5)\n\n\t\t\t\t# check if sufficient points in front\n\t\t\t\tif np.shape(boundary_errors)[0] &lt; 3:\n\t\t\t\t\twarn(\n\t\t\t\t\t\tf\"Warning: insufficient front found for samples {samples[i]} and {samples[j+1]}\",\n\t\t\t\t\t\tRuntimeWarning,\n\t\t\t\t\t)\n\t\t\t\t\tcontinue\n\n\t\t\t\t# fit with parabola in rotated frame\n\t\t\t\tfit_data = boundary_errors @ rotation\n\t\t\t\t# max point of each error becomes (x,y) pair in rotated frame\n\t\t\t\tminmax_rot = (\n\t\t\t\t\tnp.asarray(\n\t\t\t\t\t\t[\n\t\t\t\t\t\t\tboundary_errors[np.argmax(boundary_errors[:, 1])],\n\t\t\t\t\t\t\tboundary_errors[np.argmax(boundary_errors[:, 0])],\n\t\t\t\t\t\t]\n\t\t\t\t\t)\n\t\t\t\t\t@ rotation\n\t\t\t\t)\n\n\t\t\t\t# only want x bounds in new frame for curve fitting\n\t\t\t\tx_rot = np.linspace(minmax_rot[0, 0], minmax_rot[1, 0], 200)\n\n\t\t\t\t# also want location of least error in rotated frame\n\t\t\t\tglobal_best_loc = plt_errors[global_best_ind] @ rotation\n\n\t\t\t\tdef f(x, b, h, k):\n\t\t\t\t\treturn b * (x - h) ** 2 + k\n\n\t\t\t\ttry:\n\t\t\t\t\tsigma = []\n\t\t\t\t\tfor ii in range(len(fit_data[:, 0])):\n\t\t\t\t\t\tsum_j = 0.0\n\t\t\t\t\t\tfor jj in range(len(fit_data[:, 0])):\n\t\t\t\t\t\t\tif jj == ii:\n\t\t\t\t\t\t\t\tcontinue\n\t\t\t\t\t\t\tdist = np.abs(fit_data[jj, 0] - fit_data[ii, 0])\n\t\t\t\t\t\t\tif dist != 0:\n\t\t\t\t\t\t\t\tsum_j += dist\n\t\t\t\t\t\tsigma.append(np.abs(fit_data[ii, 0]) / sum_j)\n\t\t\t\t\tsigma = np.asarray(sigma)\n\n\t\t\t\t\tpopt, _ = curve_fit(\n\t\t\t\t\t\tf,\n\t\t\t\t\t\tfit_data[:, 0],\n\t\t\t\t\t\tfit_data[:, 1],\n\t\t\t\t\t\tp0=(0, 10, 100),\n\t\t\t\t\t\tbounds=((-10, -100, -500), (10, 100, 500)),\n\t\t\t\t\t\tsigma=sigma,\n\t\t\t\t\t)\n\t\t\t\t\ty_rot = f(x_rot, *popt)\n\t\t\t\t\tcurve_reg = np.stack((x_rot, y_rot), axis=1) @ rotation.T\n\t\t\t\t\t_ax.plot(\n\t\t\t\t\t\tcurve_reg[:, 0],\n\t\t\t\t\t\tcurve_reg[:, 1],\n\t\t\t\t\t\t\"--\",\n\t\t\t\t\t\tcolor=\"red\",\n\t\t\t\t\t\tlabel=\"fit\",\n\t\t\t\t\t\tzorder=3.0,\n\t\t\t\t\t)\n\t\t\t\t\tcurvatures[samples[i]] = curvatures[samples[i]] + popt[0]\n\t\t\t\t\tcurvatures[samples[j + 1]] = curvatures[samples[j + 1]] + popt[0]\n\n\t\t\t\t\t# also want difference from global best error:\n\t\t\t\t\tdiff_ys[samples[i]] = diff_ys[samples[i]] + global_best_loc[1] + popt[2]\n\t\t\t\t\tdiff_ys[samples[j + 1]] = diff_ys[samples[j + 1]] + global_best_loc[1] + popt[2]\n\t\t\t\t\t# and x-shift from equal error (let positive favor lower error for that sample):\n\t\t\t\t\tdiff_xs[samples[i]] = diff_xs[samples[i]] + popt[1]\n\t\t\t\t\tdiff_xs[samples[j + 1]] = diff_xs[samples[j + 1]] - popt[1]\n\t\t\t\t\t# overall height of parabola in rotated frame:\n\t\t\t\t\tdiff_rs[samples[i]] = diff_rs[samples[i]] + f(0, *popt)\n\t\t\t\t\tdiff_rs[samples[j + 1]] = diff_rs[samples[j + 1]] + f(0, *popt)\n\t\t\t\texcept RuntimeError:\n\t\t\t\t\twarn(\n\t\t\t\t\t\tf\"Warning: unable to fit Pareto front for samples {samples[i]} and {samples[j+1]}\",\n\t\t\t\t\t\tRuntimeWarning,\n\t\t\t\t\t)\n\n\t\t\t\tif i &gt; 0:\n\t\t\t\t\t_ax.set_ylabel(\"\")\n\t\t\t\tif j &lt; num_samples - 2:\n\t\t\t\t\t_ax.set_xlabel(\"\")\n\n\twith open(\"out_best_params.txt\", \"a+\") as f:\n\t\t# curvatures:\n\t\tf.write(\"Mean pairwise error curvatures:\\n\")\n\t\tfor sample in samples:\n\t\t\tf.write(f\"    {sample}: {curvatures[sample]/num_samples}\\n\")\n\t\tf.write(f\"Mean overall pairwise error curvature:\\n{np.mean(list(curvatures.values()))}\\n\\n\")\n\n\t\t# x-shifts between global min and parabola center:\n\t\tf.write(\"Mean pairwise x-shifts:\\n\")\n\t\tfor sample in samples:\n\t\t\tf.write(f\"    {sample}: {diff_xs[sample]/num_samples}\\n\")\n\t\tf.write(f\"Mean overall pairwise x-shifts:\\n{np.mean(list(diff_xs.values()))}\\n\\n\")\n\n\t\t# y-shifts between global min and parabola center:\n\t\tf.write(\"Mean pairwise y-shifts:\\n\")\n\t\tfor sample in samples:\n\t\t\tf.write(f\"    {sample}: {diff_ys[sample]/num_samples}\\n\")\n\t\tf.write(f\"Mean overall pairwise y-shifts:\\n{np.mean(list(diff_ys.values()))}\\n\\n\")\n\n\t\t# distance from parabola to line of y=-x (so no rotated x-shift included):\n\t\tf.write(\"Mean pairwise heights above 0 error:\\n\")\n\t\tfor sample in samples:\n\t\t\tf.write(f\"    {sample}: {diff_rs[sample]/num_samples}\\n\")\n\t\tf.write(f\"Mean overall pairwise heights:\\n{np.mean(list(diff_rs.values()))}\\n\\n\")\n\n\tfig.savefig(os.path.join(os.getcwd(), \"res_errors_fit.png\"), bbox_inches=\"tight\", dpi=600)\n\tplt.close(fig)\n</code></pre>"},{"location":"API/plot/#matmdl.plot.plot_single","title":"<code>plot_single()</code>","text":"<p>Plot results of single parameter run</p> Source code in <code>matmdl/plot.py</code> <pre><code>@Checkout(\"out\", local=True)\ndef plot_single():\n\t\"\"\"Plot results of single parameter run\"\"\"\n\tmsg(\"\\n# start plotting single\")\n\tfig0, ax0 = plt.subplots()\n\tin_opt = optimizer.InOpt(uset.orientations, uset.params)\n\torients = in_opt.orients\n\tlabels0 = []\n\tcolors0 = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n\tfor ct_orient, orient in enumerate(orients):\n\t\tfig, ax = plt.subplots()\n\t\tmsg(f\"plotting {orient}\")\n\n\t\t# experimental:\n\t\texp_filename = uset.orientations[orient][\"exp\"]\n\t\texp_SS = np.loadtxt(os.path.join(os.getcwd(), exp_filename), skiprows=1, delimiter=\",\")\n\t\tax.plot(\n\t\t\texp_SS[:, 0],\n\t\t\texp_SS[:, 1],\n\t\t\t\"-s\",\n\t\t\tmarkerfacecolor=\"black\",\n\t\t\tcolor=\"black\",\n\t\t\tlabel=\"Experimental \" + uset.grain_size_name,\n\t\t)\n\t\tax0.plot(\n\t\t\texp_SS[:, 0],\n\t\t\texp_SS[:, 1],\n\t\t\t\"s\",\n\t\t\tmarkerfacecolor=colors0[ct_orient],\n\t\t\tcolor=\"black\",\n\t\t\tlabel=\"Experimental \" + uset.grain_size_name,\n\t\t)\n\t\tlabels0.append(f\"Exp. [{orient}]\")\n\n\t\t# simulation:\n\t\tdata = np.loadtxt(f\"temp_time_disp_force_{orient}.csv\", delimiter=\",\", skiprows=1)\n\t\teng_strain = data[:, 1] / uset.length\n\t\teng_stress = data[:, 2] / uset.area\n\t\tax.plot(\n\t\t\teng_strain,\n\t\t\teng_stress,\n\t\t\t\"-o\",\n\t\t\talpha=1.0,\n\t\t\tcolor=\"blue\",\n\t\t\tlabel=\"Best parameter set\",\n\t\t)\n\t\tax0.plot(\n\t\t\teng_strain,\n\t\t\teng_stress,\n\t\t\t\"-\",\n\t\t\talpha=1.0,\n\t\t\tlinewidth=2,\n\t\t\tcolor=colors0[ct_orient],\n\t\t\tlabel=\"Best parameter set\",\n\t\t)\n\t\tlabels0.append(f\"Fit [{orient}]\")\n\n\t\tplot_settings(ax)\n\t\tif uset.max_strain &gt; 0:\n\t\t\tax.set_xlim(right=uset.max_strain)\n\t\tfig.savefig(\n\t\t\tos.path.join(os.getcwd(), \"res_single_\" + orient + \".png\"),\n\t\t\tbbox_inches=\"tight\",\n\t\t\tdpi=400,\n\t\t)\n\t\tplt.close(fig)\n\n\t# finish fig0, the plot of all sims and experimental data\n\tif len(orients) &gt; 1:\n\t\tmsg(\"all stress-strain\")\n\t\tplot_settings(ax0, legend=False)\n\t\tax0.legend(loc=\"best\", labels=labels0, fancybox=False, bbox_to_anchor=(1.02, 1))\n\t\tif uset.max_strain &gt; 0:\n\t\t\tax0.set_xlim(right=uset.max_strain)\n\t\tfig0.savefig(os.path.join(os.getcwd(), \"res_all.png\"), bbox_inches=\"tight\", dpi=400)\n\telse:\n\t\tplt.close(fig0)\n\n\tmsg(\"# stop plotting single\\n\")\n</code></pre>"},{"location":"API/plot/#matmdl.plot.run_fast_plots","title":"<code>run_fast_plots()</code>","text":"<p>Plots all available plot types</p> Source code in <code>matmdl/plot.py</code> <pre><code>@Checkout(\"out\", local=True)\ndef run_fast_plots():\n\t\"\"\"Plots all available plot types\"\"\"\n\tmsg(\"\\n# start plotting\")\n\tglobal in_opt\n\tin_opt = optimizer.InOpt(uset.orientations, uset.params)\n\torients = in_opt.orients\n\tfig0, ax0 = plt.subplots()\n\tlabels0 = []\n\tcolors0 = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n\tfor ct_orient, orient in enumerate(orients):\n\t\tdata = np.load(os.path.join(os.getcwd(), f\"out_time_disp_force_{orient}.npy\"))\n\t\tnum_iter = len(data[0, 0, :])\n\t\t# -----------------------------------------------------------------------------------------------\n\t\t# plot all trials, in order:\n\t\tmsg(f\"{orient}: all curves\")\n\t\tfig, ax = plt.subplots()\n\t\tfor i in range(num_iter):\n\t\t\teng_strain = data[:, 1, i] / uset.length\n\t\t\teng_stress = data[:, 2, i] / uset.area\n\t\t\tax.plot(\n\t\t\t\teng_strain,\n\t\t\t\teng_stress,\n\t\t\t\talpha=0.2 + (i + 1) / num_iter * 0.8,\n\t\t\t\tcolor=\"#696969\",\n\t\t\t)\n\n\t\t# plot experimental results:\n\t\texp_filename = uset.orientations[orient][\"exp\"]\n\t\texp_SS = np.loadtxt(os.path.join(os.getcwd(), exp_filename), skiprows=1, delimiter=\",\")\n\t\tax.plot(\n\t\t\texp_SS[:, 0],\n\t\t\texp_SS[:, 1],\n\t\t\t\"-s\",\n\t\t\tmarkerfacecolor=\"black\",\n\t\t\tcolor=\"black\",\n\t\t\tlabel=\"Experimental \" + uset.grain_size_name,\n\t\t)\n\t\tax0.plot(\n\t\t\texp_SS[:, 0],\n\t\t\texp_SS[:, 1],\n\t\t\t\"s\",\n\t\t\tmarkerfacecolor=colors0[ct_orient],\n\t\t\tcolor=\"black\",\n\t\t\tlabel=\"Experimental \" + uset.grain_size_name,\n\t\t)\n\t\tlabels0.append(f\"Exp. [{orient}]\")\n\n\t\t# plot best guess:\n\t\terrors = np.loadtxt(os.path.join(os.getcwd(), \"out_errors.txt\"), skiprows=1, delimiter=\",\")[\n\t\t\t:, -1\n\t\t]\n\t\tloc_min_error = np.argmin(errors)\n\t\teng_strain_best = data[:, 1, loc_min_error] / uset.length\n\t\teng_stress_best = data[:, 2, loc_min_error] / uset.area\n\t\tax.plot(\n\t\t\teng_strain_best,\n\t\t\teng_stress_best,\n\t\t\t\"-o\",\n\t\t\talpha=1.0,\n\t\t\tcolor=\"blue\",\n\t\t\tlabel=\"Best parameter set\",\n\t\t)\n\t\tax0.plot(\n\t\t\teng_strain_best,\n\t\t\teng_stress_best,\n\t\t\t\"-\",\n\t\t\talpha=1.0,\n\t\t\tlinewidth=2,\n\t\t\tcolor=colors0[ct_orient],\n\t\t\tlabel=\"Best parameter set\",\n\t\t)\n\t\tlabels0.append(f\"Fit [{orient}]\")\n\n\t\t# save best stress-strain data:\n\t\ttemp_ss = np.stack((eng_strain_best, eng_stress_best), axis=1)\n\t\tnp.savetxt(\n\t\t\tf\"out_best_stressStrain_{orient}.csv\",\n\t\t\ttemp_ss,\n\t\t\tdelimiter=\",\",\n\t\t\theader=\"Eng. Strain, Eng. Stress\",\n\t\t)\n\n\t\tplot_settings(ax)\n\t\tif uset.max_strain &gt; 0:\n\t\t\tax.set_xlim(right=uset.max_strain)\n\t\tfig.savefig(\n\t\t\tos.path.join(os.getcwd(), \"res_opt_\" + orient + \".png\"),\n\t\t\tbbox_inches=\"tight\",\n\t\t\tdpi=400,\n\t\t)\n\t\tplt.close(fig)\n\t\t# -----------------------------------------------------------------------------------------------\n\t\t# print best paramters\n\t\tparams = np.loadtxt(\n\t\t\tos.path.join(os.getcwd(), \"out_progress.txt\"), skiprows=1, delimiter=\",\"\n\t\t)[:, 1:]\n\t\t# ^ full list: time, then one param per column\n\t\tbest_params = params[loc_min_error, :]\n\t\twith open(\"out_best_params.txt\", \"w\") as f:\n\t\t\tf.write(\"Total iterations: \" + str(num_iter))\n\t\t\tf.write(\"\\nBest iteration:   \" + str(int(loc_min_error)))\n\t\t\tf.write(\"\\nLowest error:     \" + str(errors[loc_min_error]) + \"\\n\\n\")\n\t\t\tf.write(\"Best parameters:\\n\")  # + \", \".join([str(f) for f in best_params]) + \"\\n\\n\")\n\t\t\tfor name, value in zip(in_opt.params, best_params):\n\t\t\t\tf.write(f\"{name:&lt;10}: {value:&gt;0.2E}\\n\")\n\t\t\tif len(uset.param_additional_legend) &gt; 0:\n\t\t\t\tf.write(\"\\nFixed parameters:\\n\" + \", \".join(uset.param_additional_legend) + \"\\n\")\n\t\t\t\tf.write(\n\t\t\t\t\t\"Fixed parameter values:\\n\"\n\t\t\t\t\t+ \", \".join([str(get_param_value(f)) for f in uset.param_additional_legend])\n\t\t\t\t\t+ \"\\n\\n\"\n\t\t\t\t)\n\t\t\tf.write(\"\\n\")\n\t\t# -----------------------------------------------------------------------------------------------\n\t\t# plot best paramters\n\t\tlegend_info = []\n\t\tfor i, param in enumerate(in_opt.params):\n\t\t\tlegend_info.append(f\"{name_to_sym(param)}={best_params[i]:.1f}\")\n\t\t# also add additional parameters to legend:\n\t\tfor param_name in uset.param_additional_legend:\n\t\t\tlegend_info.append(name_to_sym(param_name) + \"=\" + str(get_param_value(param_name)))\n\t\t# add error value\n\t\tlegend_info.append(\"Error: \" + str(errors[loc_min_error]))\n\t\tlegend_info = \"\\n\".join(legend_info)\n\n\t\tmsg(f\"{orient}: best fit\")\n\t\tfig, ax = plt.subplots()\n\t\tax.plot(\n\t\t\texp_SS[:, 0],\n\t\t\texp_SS[:, 1],\n\t\t\t\"-s\",\n\t\t\tmarkerfacecolor=\"black\",\n\t\t\tcolor=\"black\",\n\t\t\tlabel=\"Experimental \" + uset.grain_size_name,\n\t\t)\n\t\tax.plot(\n\t\t\teng_strain_best,\n\t\t\teng_stress_best,\n\t\t\t\"-o\",\n\t\t\talpha=1.0,\n\t\t\tcolor=\"blue\",\n\t\t\tlabel=legend_info,\n\t\t)\n\t\tplot_settings(ax)\n\t\tif uset.max_strain &gt; 0:\n\t\t\tax.set_xlim(right=uset.max_strain)\n\t\tfig.savefig(\n\t\t\tos.path.join(os.getcwd(), \"res_single_\" + orient + \".png\"),\n\t\t\tbbox_inches=\"tight\",\n\t\t\tdpi=400,\n\t\t)\n\t\tplt.close(fig)\n\n\t# finish fig0, the plot of all sims and experimental data\n\tif len(orients) &gt; 1:\n\t\tmsg(\"all stress-strain\")\n\t\tplot_settings(ax0, legend=False)\n\t\tax0.legend(loc=\"upper left\", bbox_to_anchor=(1.0, 1.02), labels=labels0, fancybox=False)\n\t\tif uset.max_strain &gt; 0:\n\t\t\tax0.set_xlim(right=uset.max_strain)\n\t\tfig0.savefig(os.path.join(os.getcwd(), \"res_all.png\"), bbox_inches=\"tight\", dpi=400)\n\telse:\n\t\tplt.close(fig0)\n\n\t# -----------------------------------------------------------------------------------------------\n\t# plot convergence\n\tmsg(\"convergence information\")\n\tfig, ax = plt.subplots()\n\trunning_min = np.empty((num_iter))\n\trunning_min[0] = errors[0]\n\tfor i in range(1, num_iter):\n\t\tif errors[i] &lt; running_min[i - 1]:\n\t\t\trunning_min[i] = errors[i]\n\t\telse:\n\t\t\trunning_min[i] = running_min[i - 1]\n\tax.plot(list(range(num_iter)), running_min, \"-o\", color=\"blue\")\n\tplot_settings(ax, legend=False)\n\tax.set_xlabel(\"Iteration number\")\n\tax.set_ylabel(\"Lowest RMSE\")\n\tfig.savefig(\"res_convergence.png\", dpi=400, bbox_inches=\"tight\")\n\tplt.close()\n\t# -----------------------------------------------------------------------------------------------\n\tall_errors = np.loadtxt(os.path.join(os.getcwd(), \"out_errors.txt\"), skiprows=1, delimiter=\",\")\n\tplot_error_front(errors=all_errors, samples=in_opt.orients)\n\tplot_error_front_fit(errors=all_errors, samples=in_opt.orients)\n\tmsg(\"Finished fast plots\")\n</code></pre>"},{"location":"API/plot/#matmdl.plot.run_slow_plots","title":"<code>run_slow_plots()</code>","text":"<p>These require retraining and sampling the surrogate model, and can be quite slow.</p> <p>They are separated so that the time spent within the Checkout context can be shortened, allowing easier plotting while simulations are still running.</p> Source code in <code>matmdl/plot.py</code> <pre><code>def run_slow_plots():\n\t\"\"\"\n\tThese require retraining and sampling the surrogate model, and can be quite slow.\n\n\tThey are separated so that the time spent within the Checkout context can be shortened,\n\tallowing easier plotting while simulations are still running.\n\t\"\"\"\n\tmsg(\"Starting slow plots\")\n\tin_opt = optimizer.InOpt(uset.orientations, uset.params)\n\topt = optimizer.instantiate(in_opt, uset)\n\twith Checkout(\"out\", local=True):\n\t\tmsg(\"retraining surrogate model\")\n\t\topt = optimizer.load_previous(opt, search_local=True)\n\t\tif opt._n_initial_points &gt; 0:\n\t\t\tmsg(\n\t\t\t\tf\"warning, found only {opt.n_initial_points_ - opt._n_initial_points} points; training on random points...\"\n\t\t\t)\n\t\t\topt._n_initial_points = 0\n\t\t\tfake_x = opt.Xi[-1]\n\t\t\tfake_y = opt.yi[-1]\n\t\t\topt.Xi = opt.Xi[:-1]\n\t\t\topt.yi = opt.yi[:-1]\n\t\t\topt.tell(fake_x, fake_y)\n\t# plot parameter distribution\n\tmsg(\"parameter evaluations\")\n\tapply_param_labels(plot_evaluations(opt.get_result()), diag_label=\"Freq.\")\n\tplt.savefig(fname=\"res_evaluations.png\", bbox_inches=\"tight\", dpi=600, transparent=False)\n\tplt.close()\n\t# plot partial dependence\n\tmsg(\"partial dependencies\")\n\tapply_param_labels(plot_objective(opt.get_result()), diag_label=\"Objective\")\n\tplt.savefig(fname=\"res_objective.png\", bbox_inches=\"tight\", dpi=600, transparent=False)\n\tplt.close()\n\n\tmsg(\"# stop plotting\\n\")\n</code></pre>"},{"location":"API/run/","title":"Running","text":"<p>Running the optimization is handled by the <code>run</code> module, callable by:</p> <pre><code>python -m matmdl.run\n</code></pre>"},{"location":"API/run/#docstrings","title":"Docstrings:","text":""},{"location":"API/run/#matmdl.run","title":"<code>matmdl.run</code>","text":"<p>Runnable module to start an optimization run. All input should be in an <code>input.toml</code> file in the directory where this is called.</p>"},{"location":"API/run/#matmdl.run.loop","title":"<code>loop(opt, loop_len)</code>","text":"<p>Holds all optimization iteration instructions.</p> Source code in <code>matmdl/run.py</code> <pre><code>def loop(opt, loop_len):\n\t\"\"\"Holds all optimization iteration instructions.\"\"\"\n\n\tdef single_loop(opt):\n\t\t\"\"\"\n\t\tRun single iteration (one parameter set) of the optimization scheme.\n\n\t\tSingle loops need to be separate function calls to allow empty returns to exit one\n\t\tparameter set.\n\t\t\"\"\"\n\t\tnext_params = optimizer.get_next_param_set(opt, in_opt)\n\t\twriter.write_input_params(\n\t\t\tuset.param_file,\n\t\t\tin_opt.material_params,\n\t\t\tnext_params[0 : in_opt.num_params_material],\n\t\t)\n\n\t\twith state.TimeRun()():\n\t\t\tfor orient in in_opt.orients:\n\t\t\t\tengine.pre_run(next_params, orient, in_opt)\n\n\t\t\t\trunner.run(max_strain=exp_data.tell_max_strain(orient))\n\n\t\t\t\tif not engine.has_completed():  # try decreasing max increment size\n\t\t\t\t\trunner.refine_run()\n\t\t\t\tif (\n\t\t\t\t\tnot engine.has_completed()\n\t\t\t\t):  # if it still fails, tell optimizer a large error, continue\n\t\t\t\t\topt.tell(next_params, uset.large_error)\n\t\t\t\t\twarn(\n\t\t\t\t\t\tf\"Warning: early incomplete run for {orient}, skipping to next paramter set\",\n\t\t\t\t\t\tRuntimeWarning,\n\t\t\t\t\t)\n\t\t\t\t\treturn\n\t\t\t\telse:\n\t\t\t\t\toutput_fname = f\"temp_time_disp_force_{orient}.csv\"\n\t\t\t\t\tif os.path.isfile(output_fname):\n\t\t\t\t\t\tos.remove(output_fname)\n\t\t\t\t\tengine.extract(orient)  # extract data to temp_time_disp_force.csv\n\t\t\t\t\tif np.sum(np.loadtxt(output_fname, delimiter=\",\", skiprows=1)[:, 1:2]) == 0:\n\t\t\t\t\t\topt.tell(next_params, uset.large_error)\n\t\t\t\t\t\twarn(\n\t\t\t\t\t\t\tf\"Warning: early incomplete run for {orient}, skipping to next paramter set\",\n\t\t\t\t\t\t\tRuntimeWarning,\n\t\t\t\t\t\t)\n\t\t\t\t\t\treturn\n\n\t\t# write out:\n\t\tupdate_params, update_errors = [], []\n\t\twith parallel.Checkout(\"out\"):\n\t\t\t# check parallel instances:\n\t\t\tupdate_params_par, update_errors_par = parallel.update_parallel()\n\t\t\tif len(update_errors_par) &gt; 0:\n\t\t\t\tupdate_params = update_params + update_params_par\n\t\t\t\tupdate_errors = update_errors + update_errors_par\n\n\t\t\t# this instance:\n\t\t\terrors = []\n\t\t\tfor orient in in_opt.orients:\n\t\t\t\terrors.append(objective.calc_error(exp_data.data[orient][\"raw\"], orient))\n\t\t\t\twriter.combine_SS(zeros=False, orientation=orient)  # save stress-strain data\n\n\t\t\tcombined_error = objective.combine_error(errors)\n\t\t\tupdate_params = update_params + [next_params]\n\t\t\tupdate_errors = update_errors + [combined_error]\n\n\t\t\t# write this instance to file:\n\t\t\twriter.write_error_to_file(errors, in_opt.orients, objective.combine_error)\n\t\t\twriter.write_params_to_file(next_params, in_opt.params)\n\n\t\t# update optimizer outside of Checkout context to lower time using output files:\n\t\toptimizer.update_if_needed(opt, update_params, update_errors)\n\n\trunner.get_first(opt, in_opt, exp_data)\n\tfor _ in range(loop_len):\n\t\tsingle_loop(opt)\n</code></pre>"},{"location":"API/run/#matmdl.run.main","title":"<code>main()</code>","text":"<p>Instantiate data structures, start optimization loop.</p> <p>Checks for single run option, which runs then exits. Checks if current process is part of a parallel pool. Checks if previous output should be reloaded.</p> Source code in <code>matmdl/run.py</code> <pre><code>def main():\n\t\"\"\"\n\tInstantiate data structures, start optimization loop.\n\n\tChecks for single run option, which runs then exits.\n\tChecks if current process is part of a parallel pool.\n\tChecks if previous output should be reloaded.\n\t\"\"\"\n\trunner.check_single()\n\tparallel.check_parallel()\n\trunner.remove_out_files()\n\tglobal exp_data, in_opt\n\texp_data = ExpData(uset.orientations)\n\tin_opt = optimizer.InOpt(uset.orientations, uset.params)\n\topt = optimizer.instantiate(in_opt, uset)\n\tif uset.do_load_previous:\n\t\topt = optimizer.load_previous(opt)\n\tengine.prepare()\n\n\tloop(opt, uset.loop_len)\n</code></pre>"}]}